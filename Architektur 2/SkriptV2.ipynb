{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline\n",
    "\n",
    "%matplotlib notebook  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Skript für CGAN \n",
    "==============\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einleitung\n",
    "============\n",
    "In diesem Skript soll die großteilige Arbeit stattfinden um das Skrpit für die Masterarbeit zu erstellen.\n",
    "Dabei wird vorerst das Tutorial für ein GAN von Pytorch als Vorlage genutzt. \n",
    "\n",
    "\n",
    "benötigte Eigenschaften des CGANs\n",
    "===============================\n",
    "Um den Code für die Masterarbeit nützlich zu machen, müssen einige Dinge angepasst werden:\n",
    "* CGAN für Generierung aus spezifischen Formen\n",
    "* 3D-Meshes als Input fürs Training\n",
    "\n",
    "Des weiteren müssen Architektur und Gewichte mit der Zeit angepasst werden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "from scipy.spatial import Delaunay\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pytorch3d.io import load_objs_as_meshes\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.datasets import collate_batched_meshes\n",
    "\n",
    "import pymeshlab\n",
    "from preprocess import find_neighbor\n",
    "from layers import SpatialDescriptor, StructuralDescriptor, MeshConvolution\n",
    "import open3d as o3d\n",
    "\n",
    "import trimesh\n",
    "from scipy.spatial import KDTree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Data\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, max_faces, max_vertices=40):\n",
    "        \"\"\"\n",
    "        Dataset class to preprocess and load meshes for training.\n",
    "        :param root: Root directory of the dataset (train directory).\n",
    "        :param max_faces: Maximum number of faces to process per mesh.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.max_faces = max_faces\n",
    "        self.max_vertices = max_vertices\n",
    "\n",
    "        # List all mesh files in the train directory\n",
    "        self.mesh_files = [\n",
    "            os.path.join(root, file)\n",
    "            for file in os.listdir(root)\n",
    "            if file.endswith('.obj') or file.endswith('.npz') or file.endswith('.off')\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.mesh_files[idx]\n",
    "        file_name = os.path.basename(path)  # Extract '17.obj'\n",
    "        #file_number = int(os.path.splitext(file_name)[0])\n",
    "        file_number = 0\n",
    "        file_number = torch.tensor(file_number)\n",
    "        \n",
    "        \n",
    "\n",
    "        if path.endswith('.stl'):\n",
    "            vertices, faces = load_stl(path)\n",
    "        \n",
    "        elif path.endswith('.npz'):\n",
    "            # Load preprocessed file\n",
    "            data = numpy.load(path)\n",
    "            face = data['faces']\n",
    "            neighbor_index = data['neighbors']\n",
    "        else:\n",
    "            face, neighbor_index, vertices = self.process_mesh(path)\n",
    "            if face is None:\n",
    "                return self.__getitem__((idx + 1) % len(self.mesh_files))          \n",
    "        num_point = len(face)\n",
    "        num_vertices = vertices.shape[0]\n",
    "       \n",
    "\n",
    "        if num_point < self.max_faces or num_vertices < self.max_vertices:\n",
    "            random_indices_face = numpy.random.randint(0, num_point, self.max_faces - num_point) if num_point < self.max_faces else []\n",
    "            random_indices_vertices = torch.randint(0, num_vertices, (self.max_vertices - num_vertices,), device=vertices.device) if num_vertices < self.max_vertices else []\n",
    "            \n",
    "\n",
    "    # Face padding\n",
    "            if num_point < self.max_faces:\n",
    "                fill_face = face[random_indices_face]\n",
    "                fill_neighbor_index = neighbor_index[random_indices_face]\n",
    "                face = numpy.concatenate((face, fill_face))\n",
    "                neighbor_index = numpy.concatenate((neighbor_index, fill_neighbor_index))\n",
    "\n",
    "    # Vertex padding\n",
    "            if num_vertices < self.max_vertices:\n",
    "               random_vertices = vertices[random_indices_vertices]\n",
    "               vertices = torch.tensor(vertices, dtype=torch.float32)\n",
    "               random_vertices = torch.tensor(random_vertices, dtype=torch.float32)\n",
    "               vertices_t = torch.cat([vertices, random_vertices], dim=0)\n",
    "            else:\n",
    "                vertices_t = torch.tensor(vertices, dtype=torch.float32)\n",
    "        else:\n",
    "             vertices_t = torch.tensor(vertices, dtype=torch.float32)\n",
    "\n",
    "        #print( pad_size, vertices.size(), random_vertices.size(), vertices_t)\n",
    "        # Convert to PyTorch tensors\n",
    "        face = torch.from_numpy(face).float()\n",
    "        neighbor_index = torch.from_numpy(neighbor_index).long()\n",
    "\n",
    "        # Extract features\n",
    "        face = face.permute(1, 0).contiguous()  # (features, num_faces)\n",
    "        centers, corners, normals = face[:3], face[3:12], face[12:]\n",
    "        corners = corners - torch.cat([centers, centers, centers], 0)  # Center corners around face centers\n",
    "\n",
    "        \n",
    "        curve_score = torch.tensor(comp_curve_score(normals, neighbor_index)).to(device)\n",
    "        centers = centers.to(device)\n",
    "        corners = corners.to(device)\n",
    "        normals = normals.to(device)\n",
    "        neighbor_index = neighbor_index.to(device)\n",
    "        \n",
    "        \n",
    "\n",
    "        return centers, corners, normals, neighbor_index, vertices_t, file_number, curve_score\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mesh_files)\n",
    "\n",
    "    def process_mesh(self, path):\n",
    "        \"\"\"\n",
    "        Preprocess a single mesh file.\n",
    "        :param path: Path to the mesh file.\n",
    "        :return: Preprocessed face and neighbor_index arrays.\n",
    "        \"\"\"\n",
    "        \n",
    "        ms = pymeshlab.MeshSet()\n",
    "        ms.load_new_mesh(path)\n",
    "        mesh = ms.current_mesh()       \n",
    "        vertices = mesh.vertex_matrix()\n",
    "        faces = mesh.face_matrix()\n",
    "        obj_verts = vertices\n",
    "\n",
    "        if faces.shape[0] > self.max_faces:\n",
    "            #print(f\"Skipping mesh with more than {self.max_faces} faces: {path}\")\n",
    "            #print(\"num faces: \",faces.shape[0])\n",
    "            return None, None, None\n",
    "\n",
    "        # Normalize mesh\n",
    "        center = (numpy.max(vertices, 0) + numpy.min(vertices, 0)) / 2\n",
    "        vertices -= center\n",
    "        max_len = numpy.max(vertices[:, 0]**2 + vertices[:, 1]**2 + vertices[:, 2]**2)\n",
    "        vertices /= numpy.sqrt(max_len)\n",
    "\n",
    "        \n",
    "        # Compute face normals\n",
    "        ms.clear()\n",
    "        ms.add_mesh(pymeshlab.Mesh(vertices, faces))\n",
    "        face_normals = ms.current_mesh().face_normal_matrix()\n",
    "\n",
    "        # Compute face centers and corners\n",
    "        faces_contain_this_vertex = [set() for _ in range(len(vertices))]\n",
    "        centers = []\n",
    "        corners = []\n",
    "        for i, face in enumerate(faces):\n",
    "            v1, v2, v3 = face\n",
    "            x1, y1, z1 = vertices[v1]\n",
    "            x2, y2, z2 = vertices[v2]\n",
    "            x3, y3, z3 = vertices[v3]\n",
    "            centers.append([(x1 + x2 + x3) / 3, (y1 + y2 + y3) / 3, (z1 + z2 + z3) / 3])\n",
    "            corners.append([x1, y1, z1, x2, y2, z2, x3, y3, z3])\n",
    "            faces_contain_this_vertex[v1].add(i)\n",
    "            faces_contain_this_vertex[v2].add(i)\n",
    "            faces_contain_this_vertex[v3].add(i)\n",
    "\n",
    "        # Find neighbors\n",
    "        neighbors = []\n",
    "        for i, face in enumerate(faces):\n",
    "            v1, v2, v3 = face\n",
    "            n1 = find_neighbor(faces, faces_contain_this_vertex, v1, v2, i)\n",
    "            n2 = find_neighbor(faces, faces_contain_this_vertex, v2, v3, i)\n",
    "            n3 = find_neighbor(faces, faces_contain_this_vertex, v3, v1, i)\n",
    "            neighbors.append([n1, n2, n3])\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        centers = numpy.array(centers)\n",
    "        corners = numpy.array(corners)\n",
    "        faces = numpy.concatenate([centers, corners, face_normals], axis=1)\n",
    "        neighbors = numpy.array(neighbors)\n",
    "\n",
    "        \n",
    "        return faces, neighbors, obj_verts\n",
    "\n",
    "def collate_fn1(batch, max_faces=1700):\n",
    "    centers, corners, normals, neighbor_indices, vertices, file_number, curve_score = zip(*batch)\n",
    "\n",
    "    # Stapeln der Batches zu Tensors\n",
    "    centers = torch.stack(centers)\n",
    "    corners = torch.stack(corners)\n",
    "    normals = torch.stack(normals)\n",
    "    neighbor_indices = torch.stack(neighbor_indices)\n",
    "    vertices = torch.stack(vertices)\n",
    "    file_numbers = torch.stack(file_number)\n",
    "    curve_score = torch.stack(curve_score)\n",
    "    \n",
    "\n",
    "    return centers, corners, normals, neighbor_indices, vertices, file_numbers, curve_score\n",
    "\n",
    "def parse_shapes_list(file_path):\n",
    "    \"\"\"\n",
    "    Parse ShapesList.txt to create a dictionary mapping numbers to shape names.\n",
    "    :param file_path: Path to ShapesList.txt\n",
    "    :return: Dictionary {int: str}\n",
    "    \"\"\"\n",
    "    shape_dict = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse lines in the format \"1 = ShapeName\"\n",
    "            if '=' in line:\n",
    "                number, shape = line.split('=')\n",
    "                shape_dict[int(number.strip())] = shape.strip()\n",
    "    return shape_dict\n",
    "\n",
    "def comp_curve_score(normals, neighbor_index):\n",
    "    \"\"\"\n",
    "    Compute curvature scores for faces based on the angle between neighboring face normals.\n",
    "    :param normals: Tensor of shape (num_faces, 3) - Normal vectors for each face\n",
    "    :param neighbor_index: Tensor of shape (num_faces, k_neighbors) - Neighbor indices for each face\n",
    "    :return: Tensor of shape (num_faces,) - Curvature scores for each face\n",
    "    \"\"\"\n",
    "    # Gather neighboring normals\n",
    "    normals = normals.permute(1,0)\n",
    "    neighbor_normals = normals[neighbor_index]  # Shape: (num_faces, k_neighbors, 3)\n",
    "\n",
    "    # Compute dot product between face normals and their neighbors\n",
    "    dot_products = torch.sum(normals.unsqueeze(1) * neighbor_normals, dim=-1)  # (num_faces, k_neighbors)\n",
    "\n",
    "    # Clamp dot products to [-1, 1] to avoid numerical issues with arccos\n",
    "    dot_products = torch.clamp(dot_products, -1.0, 1.0)\n",
    "\n",
    "    # Compute angles (in radians) between normals\n",
    "    angles = torch.acos(dot_products)  # (num_faces, k_neighbors)\n",
    "\n",
    "    # Average angle across neighbors as the curvature score\n",
    "    scores = torch.mean(angles, dim=-1)  # (num_faces,)\n",
    "    scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Data Processing\n",
    "====\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\pytorch3d\\io\\obj_io.py:550: UserWarning: Mtl file does not exist: 7.mtl\n",
      "  warnings.warn(f\"Mtl file does not exist: {f}\")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mesh = load_objs_as_meshes([\"7.obj\"], device=device)\n",
    "point_cloud = sample_points_from_meshes(mesh, 500).squeeze(0).cpu().numpy()\n",
    "\n",
    "# Convert to Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(point_cloud)\n",
    "\n",
    "pcd.estimate_normals()\n",
    "\n",
    "# Apply Ball Pivoting Algorithm (BPA)\n",
    "radii = [0.005, 0.01, 0.02]  # Adjust radii for better reconstruction\n",
    "mesh_bpa = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(\n",
    "    pcd, o3d.utility.DoubleVector(radii)\n",
    ")\n",
    "\n",
    "# Save and visualize\n",
    "o3d.io.write_triangle_mesh(\"bpa_triangulated_mesh.obj\", mesh_bpa)\n",
    "o3d.visualization.draw_geometries([mesh_bpa])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face-Generator\n",
    "==============\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_generator(point_clouds):\n",
    "    \"\"\"\n",
    "    Konvertiere eine Batch von Punktwolken in eine Batch von PyTorch3D-Meshes.\n",
    "    \n",
    "    Args:\n",
    "        point_clouds: Tensor der Form (batch_size, num_points, 3), die Punktwolken.\n",
    "    \n",
    "    Returns:\n",
    "        meshes: PyTorch3D Meshes-Objekt mit dem Batch an Meshes.\n",
    "    \"\"\"\n",
    "    #print(point_clouds.size())\n",
    "   \n",
    "    batch_size = point_clouds.size(0)\n",
    "    verts_list = []  # Liste für Vertices (pro Mesh)\n",
    "    faces_list = []  # Liste für Faces (pro Mesh)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        points = point_clouds[i].cpu().detach().numpy()  # Konvertiere zu NumPy für SciPy\n",
    "        \n",
    "        # Führe Delaunay-Triangulation durch\n",
    "        tri = Delaunay(points)\n",
    "\n",
    "        # Extrahiere Vertices und Faces\n",
    "        verts = torch.tensor(tri.points, dtype=torch.float32).to(point_clouds.device)  # Shape: (num_vertices, 3)\n",
    "        faces = torch.tensor(tri.convex_hull, dtype=torch.int64).to(point_clouds.device)  # Shape: (num_faces, 3)\n",
    "\n",
    "        # Filtere ungültige Faces\n",
    "        valid_faces = faces[(faces >= 0).all(dim=1)]  # Entferne Faces mit -1\n",
    "\n",
    "        # Speichere die Vertices und gültigen Faces in den Listen\n",
    "        verts_list.append(verts)\n",
    "        faces_list.append(valid_faces)\n",
    "        \n",
    "\n",
    "    # Erstelle PyTorch3D-Meshes\n",
    "    meshes = Meshes(verts=verts_list, faces=faces_list).to(point_clouds.device)\n",
    "    return {\"mesh\": meshes, \"verts\": verts_list, \"faces\": faces_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape Extractor\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeExtractor(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(ShapeExtractor, self).__init__()\n",
    "        self.spatial_descriptor = SpatialDescriptor()\n",
    "        self.structural_descriptor = StructuralDescriptor(cfg['structural_descriptor'])\n",
    "        self.mesh_conv1 = MeshConvolution(cfg['mesh_convolution'], 64, 131, 96, 96)\n",
    "        self.mesh_conv2 = MeshConvolution(cfg['mesh_convolution'], 96, 96, 96, 64)\n",
    "        self.fusion_mlp = nn.Sequential(\n",
    "            nn.Conv1d(160, 96, 1),\n",
    "            nn.BatchNorm1d(96),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.concat_mlp = nn.Sequential(\n",
    "            nn.Conv1d(96 + 96 + 96, 128, 1), \n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, centers, corners, normals, neighbor_index, curvature_scores):\n",
    "        spatial_fea0 = self.spatial_descriptor(centers)\n",
    "        structural_fea0 = self.structural_descriptor(corners, normals, neighbor_index)\n",
    "\n",
    "        spatial_fea1, structural_fea1 = self.mesh_conv1(spatial_fea0, structural_fea0, neighbor_index)\n",
    "        spatial_fea2, structural_fea2 = self.mesh_conv2(spatial_fea1, structural_fea1, neighbor_index)\n",
    "        spatial_fea3 = self.fusion_mlp(torch.cat([spatial_fea2, structural_fea2], 1))\n",
    "\n",
    "        combined_fea = torch.cat([spatial_fea1, spatial_fea2, spatial_fea3], 1)  # b, c, n\n",
    "\n",
    "\n",
    "        curvature_weight = curvature_scores.unsqueeze(1).expand_as(combined_fea)    \n",
    "        combined_fea_with_scores = combined_fea \n",
    "        \n",
    "\n",
    "        # Aggregate global features based on combined features\n",
    "        aggregated_fea = self.concat_mlp(combined_fea_with_scores)  # (batch_size, 512, num_faces)\n",
    "        global_fea = torch.max(aggregated_fea, dim=2)[0]  # Global feature (batch_size, 512)\n",
    "        \n",
    "        return global_fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator\n",
    "==============\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class MeshGenerator(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(MeshGenerator, self).__init__()\n",
    "        self.shape_extractor = ShapeExtractor(cfg)\n",
    "        self.vertex_decoder = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, cfg['num_vertices'] * 3)  # Output shape: (batch_size, num_vertices * 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, centers, corners, normals, neighbor_index, curvature_scores):\n",
    "        global_fea = self.shape_extractor(centers, corners, normals, neighbor_index, curvature_scores)\n",
    "        generated_vertices = self.vertex_decoder(global_fea)\n",
    "        generated_vertices = generated_vertices.view(generated_vertices.size(0), -1, 3)  # Reshape to (batch_size, num_vertices, 3)\n",
    "        generated_vertices = scale_to_unit(generated_vertices)\n",
    "        \n",
    "        return generated_vertices\n",
    "\n",
    "\n",
    "\n",
    "def scale_to_unit(vertices):\n",
    "    \"\"\"\n",
    "    Scale vertices to the range [-1, 1] while preserving the shape.\n",
    "    :param vertices: Tensor of shape (batch_size, num_vertices, 3).\n",
    "    :return: Scaled vertices in the range [-1, 1].\n",
    "    \"\"\"\n",
    "    # Step 1: Center the vertices around the origin\n",
    "    centroid = torch.mean(vertices, dim=1, keepdim=True)  # Compute the centroid (batch_size, 1, 3)\n",
    "    centered_vertices = vertices - centroid               # Center the vertices (batch_size, num_vertices, 3)\n",
    "\n",
    "    # Step 2: Find the maximum absolute value along any axis\n",
    "    max_abs = torch.amax(torch.abs(centered_vertices), dim=(1, 2), keepdim=True)[0]  # (batch_size, 1, 1)\n",
    "\n",
    "    # Step 3: Scale the vertices to fit in the range [-1, 1]\n",
    "    scaled_vertices = centered_vertices / max_abs\n",
    "\n",
    "\n",
    "    return scaled_vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diskriminator\n",
    "==============\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshDiscriminator(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(MeshDiscriminator, self).__init__()\n",
    "        \n",
    "        # Convolutional layers to extract local features\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=32, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=1)\n",
    "\n",
    "        # Batch normalization for stability\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        self.fc1 = nn.Linear(128 * 64, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expecting input shape: (batch_size, num_vertices, 3)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)  # Change to (batch_size, 3, num_vertices) for Conv1d\n",
    "    \n",
    "        # Apply convolutional layers\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "\n",
    "        # Apply adaptive pooling to ensure a fixed output length (64 in this case)\n",
    "        x = F.adaptive_avg_pool1d(x, 64)\n",
    "        \n",
    "\n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Sigmoid for binary classification\n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss-Functions\n",
    "==============\n",
    "\n",
    "Alle speziellen Loss_Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chamfer_distance1(x, y):\n",
    "    x_exp = x.unsqueeze(2)  # (batch_size, num_points, 1, 3)\n",
    "    y_exp = y.unsqueeze(1)  # (batch_size, 1, num_points, 3)\n",
    "    dist = torch.norm(x_exp - y_exp, dim=-1)  # Pairwise distances\n",
    "    min_dist_x, _ = torch.min(dist, dim=2)\n",
    "    min_dist_y, _ = torch.min(dist, dim=1)\n",
    "    return torch.mean(min_dist_x) + torch.mean(min_dist_y)\n",
    "\n",
    "def compute_vertex_density(vertices, k=10):\n",
    "    tree = KDTree(vertices)\n",
    "    density_scores = numpy.zeros(len(vertices))\n",
    "\n",
    "    for i, vertex in enumerate(vertices):\n",
    "        dists, idx = tree.query(vertex, k=k+1)  # +1, weil der Punkt selbst enthalten ist\n",
    "        density_scores[i] = k / (numpy.mean(dists[1:]) + 1e-8)  # Entfernung nutzen, aber den Punkt selbst ausschließen\n",
    "\n",
    "    return density_scores\n",
    "\n",
    "def curve_loss(generated_vertices, corners, curvature_scores):\n",
    "    \"\"\"\n",
    "    Penalize the generator for not placing vertices in high-curvature regions.\n",
    "    :param generated_vertices: Tensor of shape (batch_size, num_generated_vertices, 3)\n",
    "    :param corners: Tensor of shape (batch_size, num_faces, 9) - Real corners\n",
    "    :param curvature_scores: Tensor of shape (batch_size, num_faces) - Real curvature scores\n",
    "    :return: Loss scalar\n",
    "    \"\"\"\n",
    "    corners = corners.permute(0,2,1)\n",
    "    # Compute distances between generated vertices and corners\n",
    "    generated_vertices = generated_vertices.unsqueeze(2)  # (batch_size, num_generated_vertices, 1, 3)\n",
    "    corners = corners.view(corners.size(0), corners.size(1), 3, 3)  # (batch_size, num_faces, 3, 3)\n",
    "    distances = torch.norm(generated_vertices - corners, dim=-1)  # (batch_size, num_generated_vertices, num_faces, 3)\n",
    "\n",
    "    # Weight distances by curvature scores\n",
    "    weighted_distances = distances * curvature_scores.unsqueeze(1).unsqueeze(-1)  # (batch_size, num_generated_vertices, num_faces, 3)\n",
    "\n",
    "    # Minimize the weighted distances\n",
    "    return weighted_distances.mean()\n",
    "    \n",
    "def map_vertices_to_faces(generated_vertices, face_centers):\n",
    "    \"\"\"\n",
    "    Findet für jedes generierte Vertex das nächstgelegene Face anhand seiner Mittelpunkte.\n",
    "\n",
    "    generated_vertices: (N, 3) numpy array der generierten Vertex-Positionen\n",
    "    face_centers: (M, 3) numpy array mit Mittelpunkten der echten Faces\n",
    "    \n",
    "    Return:\n",
    "    vertex_face_map: (N,) numpy array mit dem Index des nächstgelegenen Faces für jedes generierte Vertex\n",
    "    \"\"\"\n",
    "    face_centers = face_centers.T\n",
    "    tree = KDTree(face_centers)  # KDTree für schnellen Nachbarschaftsvergleich\n",
    "    _, closest_face_indices = tree.query(generated_vertices)  # Findet das nächstgelegene Face für jedes Vertex\n",
    "\n",
    "    return closest_face_indices\n",
    "    \n",
    "def compute_face_vertex_density(generated_vertices, face_centers, num_faces):\n",
    "    \"\"\"\n",
    "    Berechnet die Vertex-Dichte für jedes echte Face basierend auf den generierten Vertices.\n",
    "\n",
    "    generated_vertices: (N, 3) numpy array mit generierten Vertex-Positionen\n",
    "    face_centers: (M, 3) numpy array mit Mittelpunkten der echten Faces\n",
    "    num_faces: Anzahl der echten Faces\n",
    "\n",
    "    Return:\n",
    "    face_density: (M,) numpy array mit der Anzahl der generierten Vertices pro Face\n",
    "    \"\"\"\n",
    "    face_density = numpy.zeros(num_faces)\n",
    "\n",
    "    # Bestimme, welches Face zu jedem generierten Vertex gehört\n",
    "    closest_faces = map_vertices_to_faces(generated_vertices, face_centers)\n",
    "\n",
    "    # Zähle, wie viele Vertices pro Face liegen\n",
    "    for face_idx in closest_faces:\n",
    "        face_density[face_idx] += 1\n",
    "    \n",
    "    # Normalisiere die Dichte auf einen Bereich von 0 bis 1\n",
    "    face_density = (face_density - numpy.min(face_density)) / (numpy.max(face_density) - numpy.min(face_density) + 1e-8)\n",
    "\n",
    "    \n",
    "    return face_density\n",
    "\n",
    "def curvature_density_loss(generated_vertices, face_centers, real_curvature_scores):\n",
    "    \"\"\"\n",
    "    Bestraft falsche Vertex-Verteilungen basierend auf dem echten Curvature Score der Faces.\n",
    "\n",
    "    generated_vertices: (B, N, 3) Tensor mit den generierten Vertex-Positionen\n",
    "    face_centers: (B, M, 3) Tensor mit den Mittelpunkten der echten Faces\n",
    "    real_curvature_scores: (B, M) Tensor mit echten Curvature Scores der Faces\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    batch_size = generated_vertices.shape[0]\n",
    "    loss = 0.0\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Konvertiere in NumPy für Berechnungen mit KDTree\n",
    "        verts = generated_vertices[i].detach().cpu().numpy()\n",
    "        centers = face_centers[i].detach().cpu().numpy()\n",
    "        curv_scores = real_curvature_scores[i]\n",
    "\n",
    "        # Berechne die Face-Dichte basierend auf den generierten Vertices\n",
    "        face_vertex_density = compute_face_vertex_density(verts, centers, centers.shape[1])\n",
    "\n",
    "        # Konvertiere in PyTorch Tensor\n",
    "        face_vertex_density = torch.tensor(face_vertex_density, dtype=torch.float32, device=generated_vertices.device)\n",
    "\n",
    "        # Fehler = Differenz zwischen generierter Vertex-Dichte und echtem Curvature Score\n",
    "        density_diff = torch.abs(face_vertex_density - curv_scores)\n",
    "\n",
    "        # Mean Squared Error als Bestrafung\n",
    "        loss += torch.mean(density_diff ** 2)\n",
    "\n",
    "    \n",
    "    return loss / batch_size  # Durchschnitt über den Batch nehmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\AppData\\Local\\Temp\\ipykernel_24152\\1294795523.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"MeshNet_best_9192.pkl\")\n",
      "C:\\Users\\Ben\\AppData\\Local\\Temp\\ipykernel_24152\\1542080103.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  curve_score = torch.tensor(comp_curve_score(normals, neighbor_index)).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [1/1000]  Loss D: 2.5879, Loss Adv_d: 1.3779 ------ Loss G: 1.2780, Curve Loss: 0.1379, Chamfer Loss: 0.4722\n",
      "Epoch [2/1000]  Loss D: 2.4757, Loss Adv_d: 1.3730 ------ Loss G: 1.1926, Curve Loss: 0.1343, Chamfer Loss: 0.3795\n",
      "Epoch [3/1000]  Loss D: 2.4456, Loss Adv_d: 1.3636 ------ Loss G: 1.1954, Curve Loss: 0.1364, Chamfer Loss: 0.3706\n",
      "Epoch [4/1000]  Loss D: 2.4262, Loss Adv_d: 1.3575 ------ Loss G: 1.2010, Curve Loss: 0.1352, Chamfer Loss: 0.3673\n",
      "Epoch [5/1000]  Loss D: 2.3929, Loss Adv_d: 1.3512 ------ Loss G: 1.1924, Curve Loss: 0.1342, Chamfer Loss: 0.3500\n",
      "Epoch [6/1000]  Loss D: 2.3736, Loss Adv_d: 1.3447 ------ Loss G: 1.2002, Curve Loss: 0.1371, Chamfer Loss: 0.3463\n",
      "Epoch [7/1000]  Loss D: 2.3503, Loss Adv_d: 1.3392 ------ Loss G: 1.1982, Curve Loss: 0.1353, Chamfer Loss: 0.3376\n",
      "Epoch [8/1000]  Loss D: 2.3446, Loss Adv_d: 1.3324 ------ Loss G: 1.2141, Curve Loss: 0.1339, Chamfer Loss: 0.3470\n",
      "Epoch [9/1000]  Loss D: 2.3085, Loss Adv_d: 1.3265 ------ Loss G: 1.1996, Curve Loss: 0.1355, Chamfer Loss: 0.3234\n",
      "Epoch [10/1000]  Loss D: 2.3102, Loss Adv_d: 1.3207 ------ Loss G: 1.2200, Curve Loss: 0.1339, Chamfer Loss: 0.3380\n",
      "Epoch [11/1000]  Loss D: 2.3161, Loss Adv_d: 1.3152 ------ Loss G: 1.2455, Curve Loss: 0.1340, Chamfer Loss: 0.3561\n",
      "Epoch [12/1000]  Loss D: 2.2735, Loss Adv_d: 1.3121 ------ Loss G: 1.2210, Curve Loss: 0.1356, Chamfer Loss: 0.3238\n",
      "Epoch [13/1000]  Loss D: 2.2565, Loss Adv_d: 1.3027 ------ Loss G: 1.2265, Curve Loss: 0.1368, Chamfer Loss: 0.3215\n",
      "Epoch [14/1000]  Loss D: 2.2409, Loss Adv_d: 1.2997 ------ Loss G: 1.2234, Curve Loss: 0.1362, Chamfer Loss: 0.3142\n",
      "Epoch [15/1000]  Loss D: 2.2290, Loss Adv_d: 1.2972 ------ Loss G: 1.2212, Curve Loss: 0.1341, Chamfer Loss: 0.3092\n",
      "Epoch [16/1000]  Loss D: 2.3886, Loss Adv_d: 1.2920 ------ Loss G: 1.3991, Curve Loss: 0.1382, Chamfer Loss: 0.4780\n",
      "Epoch [17/1000]  Loss D: 2.2270, Loss Adv_d: 1.2856 ------ Loss G: 1.2542, Curve Loss: 0.1373, Chamfer Loss: 0.3269\n",
      "Epoch [18/1000]  Loss D: 2.2006, Loss Adv_d: 1.2836 ------ Loss G: 1.2412, Curve Loss: 0.1365, Chamfer Loss: 0.3086\n",
      "Epoch [19/1000]  Loss D: 2.1961, Loss Adv_d: 1.2836 ------ Loss G: 1.2475, Curve Loss: 0.1375, Chamfer Loss: 0.3088\n",
      "Epoch [20/1000]  Loss D: 2.1792, Loss Adv_d: 1.2778 ------ Loss G: 1.2441, Curve Loss: 0.1372, Chamfer Loss: 0.3020\n",
      "Epoch [21/1000]  Loss D: 2.1719, Loss Adv_d: 1.2730 ------ Loss G: 1.2487, Curve Loss: 0.1366, Chamfer Loss: 0.3023\n",
      "Epoch [22/1000]  Loss D: 2.1545, Loss Adv_d: 1.2700 ------ Loss G: 1.2446, Curve Loss: 0.1368, Chamfer Loss: 0.2921\n",
      "Epoch [23/1000]  Loss D: 2.1426, Loss Adv_d: 1.2664 ------ Loss G: 1.2438, Curve Loss: 0.1356, Chamfer Loss: 0.2887\n",
      "Epoch [24/1000]  Loss D: 2.1320, Loss Adv_d: 1.2617 ------ Loss G: 1.2441, Curve Loss: 0.1347, Chamfer Loss: 0.2854\n",
      "Epoch [25/1000]  Loss D: 2.1227, Loss Adv_d: 1.2605 ------ Loss G: 1.2463, Curve Loss: 0.1367, Chamfer Loss: 0.2809\n",
      "Epoch [26/1000]  Loss D: 2.1095, Loss Adv_d: 1.2545 ------ Loss G: 1.2487, Curve Loss: 0.1369, Chamfer Loss: 0.2773\n",
      "Epoch [27/1000]  Loss D: 2.0990, Loss Adv_d: 1.2533 ------ Loss G: 1.2503, Curve Loss: 0.1379, Chamfer Loss: 0.2729\n",
      "Epoch [28/1000]  Loss D: 2.0870, Loss Adv_d: 1.2476 ------ Loss G: 1.2523, Curve Loss: 0.1370, Chamfer Loss: 0.2706\n",
      "Epoch [29/1000]  Loss D: 2.0990, Loss Adv_d: 1.2451 ------ Loss G: 1.2738, Curve Loss: 0.1358, Chamfer Loss: 0.2886\n",
      "Epoch [30/1000]  Loss D: 2.0963, Loss Adv_d: 1.2424 ------ Loss G: 1.2831, Curve Loss: 0.1364, Chamfer Loss: 0.2917\n",
      "Epoch [31/1000]  Loss D: 2.3039, Loss Adv_d: 1.2360 ------ Loss G: 1.5087, Curve Loss: 0.1381, Chamfer Loss: 0.5101\n",
      "Epoch [32/1000]  Loss D: 2.1517, Loss Adv_d: 1.2333 ------ Loss G: 1.3692, Curve Loss: 0.1378, Chamfer Loss: 0.3655\n",
      "Epoch [33/1000]  Loss D: 2.0867, Loss Adv_d: 1.2279 ------ Loss G: 1.3208, Curve Loss: 0.1360, Chamfer Loss: 0.3104\n",
      "Epoch [34/1000]  Loss D: 2.0621, Loss Adv_d: 1.2238 ------ Loss G: 1.3103, Curve Loss: 0.1368, Chamfer Loss: 0.2947\n",
      "Epoch [35/1000]  Loss D: 2.0589, Loss Adv_d: 1.2242 ------ Loss G: 1.3132, Curve Loss: 0.1359, Chamfer Loss: 0.2934\n",
      "Epoch [36/1000]  Loss D: 2.1605, Loss Adv_d: 1.2201 ------ Loss G: 1.4280, Curve Loss: 0.1388, Chamfer Loss: 0.4021\n",
      "Epoch [37/1000]  Loss D: 2.0776, Loss Adv_d: 1.2214 ------ Loss G: 1.3482, Curve Loss: 0.1369, Chamfer Loss: 0.3202\n",
      "Epoch [38/1000]  Loss D: 2.0549, Loss Adv_d: 1.2166 ------ Loss G: 1.3386, Curve Loss: 0.1367, Chamfer Loss: 0.3061\n",
      "Epoch [39/1000]  Loss D: 2.0340, Loss Adv_d: 1.2133 ------ Loss G: 1.3281, Curve Loss: 0.1363, Chamfer Loss: 0.2904\n",
      "Epoch [40/1000]  Loss D: 2.0331, Loss Adv_d: 1.2180 ------ Loss G: 1.3319, Curve Loss: 0.1372, Chamfer Loss: 0.2887\n",
      "Epoch [41/1000]  Loss D: 2.0314, Loss Adv_d: 1.2149 ------ Loss G: 1.3393, Curve Loss: 0.1358, Chamfer Loss: 0.2937\n",
      "Epoch [42/1000]  Loss D: 2.0301, Loss Adv_d: 1.2132 ------ Loss G: 1.3496, Curve Loss: 0.1366, Chamfer Loss: 0.2968\n",
      "Epoch [43/1000]  Loss D: 2.0101, Loss Adv_d: 1.2117 ------ Loss G: 1.3412, Curve Loss: 0.1369, Chamfer Loss: 0.2833\n",
      "Epoch [44/1000]  Loss D: 2.0097, Loss Adv_d: 1.2094 ------ Loss G: 1.3517, Curve Loss: 0.1388, Chamfer Loss: 0.2874\n",
      "Epoch [45/1000]  Loss D: 2.0029, Loss Adv_d: 1.2099 ------ Loss G: 1.3518, Curve Loss: 0.1378, Chamfer Loss: 0.2833\n",
      "Epoch [46/1000]  Loss D: 2.0090, Loss Adv_d: 1.2093 ------ Loss G: 1.3654, Curve Loss: 0.1368, Chamfer Loss: 0.2939\n",
      "Epoch [47/1000]  Loss D: 2.0448, Loss Adv_d: 1.2100 ------ Loss G: 1.4098, Curve Loss: 0.1385, Chamfer Loss: 0.3308\n",
      "Epoch [48/1000]  Loss D: 1.9960, Loss Adv_d: 1.2107 ------ Loss G: 1.3704, Curve Loss: 0.1370, Chamfer Loss: 0.2876\n",
      "Epoch [49/1000]  Loss D: 1.9792, Loss Adv_d: 1.2055 ------ Loss G: 1.3669, Curve Loss: 0.1378, Chamfer Loss: 0.2783\n",
      "Epoch [50/1000]  Loss D: 1.9981, Loss Adv_d: 1.2084 ------ Loss G: 1.3890, Curve Loss: 0.1376, Chamfer Loss: 0.2953\n",
      "Epoch [51/1000]  Loss D: 1.9724, Loss Adv_d: 1.2040 ------ Loss G: 1.3754, Curve Loss: 0.1370, Chamfer Loss: 0.2773\n",
      "Epoch [52/1000]  Loss D: 1.9714, Loss Adv_d: 1.2086 ------ Loss G: 1.3785, Curve Loss: 0.1378, Chamfer Loss: 0.2753\n",
      "Epoch [53/1000]  Loss D: 1.9690, Loss Adv_d: 1.2120 ------ Loss G: 1.3768, Curve Loss: 0.1362, Chamfer Loss: 0.2723\n",
      "Epoch [54/1000]  Loss D: 1.9644, Loss Adv_d: 1.2124 ------ Loss G: 1.3804, Curve Loss: 0.1383, Chamfer Loss: 0.2689\n",
      "Epoch [55/1000]  Loss D: 1.9655, Loss Adv_d: 1.2116 ------ Loss G: 1.3883, Curve Loss: 0.1374, Chamfer Loss: 0.2737\n",
      "Epoch [56/1000]  Loss D: 1.9586, Loss Adv_d: 1.2145 ------ Loss G: 1.3844, Curve Loss: 0.1386, Chamfer Loss: 0.2662\n",
      "Epoch [57/1000]  Loss D: 1.9563, Loss Adv_d: 1.2163 ------ Loss G: 1.3844, Curve Loss: 0.1356, Chamfer Loss: 0.2642\n",
      "Epoch [58/1000]  Loss D: 1.9578, Loss Adv_d: 1.2184 ------ Loss G: 1.3925, Curve Loss: 0.1375, Chamfer Loss: 0.2655\n",
      "Epoch [59/1000]  Loss D: 1.9534, Loss Adv_d: 1.2201 ------ Loss G: 1.3928, Curve Loss: 0.1371, Chamfer Loss: 0.2618\n",
      "Epoch [60/1000]  Loss D: 2.0012, Loss Adv_d: 1.2218 ------ Loss G: 1.4459, Curve Loss: 0.1375, Chamfer Loss: 0.3115\n",
      "Epoch [61/1000]  Loss D: 1.9771, Loss Adv_d: 1.2248 ------ Loss G: 1.4239, Curve Loss: 0.1365, Chamfer Loss: 0.2861\n",
      "Epoch [62/1000]  Loss D: 1.9531, Loss Adv_d: 1.2212 ------ Loss G: 1.4098, Curve Loss: 0.1362, Chamfer Loss: 0.2683\n",
      "Epoch [63/1000]  Loss D: 1.9576, Loss Adv_d: 1.2288 ------ Loss G: 1.4129, Curve Loss: 0.1380, Chamfer Loss: 0.2669\n",
      "Epoch [64/1000]  Loss D: 1.9872, Loss Adv_d: 1.2289 ------ Loss G: 1.4473, Curve Loss: 0.1388, Chamfer Loss: 0.2981\n",
      "Epoch [65/1000]  Loss D: 1.9494, Loss Adv_d: 1.2283 ------ Loss G: 1.4183, Curve Loss: 0.1370, Chamfer Loss: 0.2651\n",
      "Epoch [66/1000]  Loss D: 1.9496, Loss Adv_d: 1.2314 ------ Loss G: 1.4204, Curve Loss: 0.1371, Chamfer Loss: 0.2640\n",
      "Epoch [67/1000]  Loss D: 1.9464, Loss Adv_d: 1.2316 ------ Loss G: 1.4188, Curve Loss: 0.1363, Chamfer Loss: 0.2611\n",
      "Epoch [68/1000]  Loss D: 1.9631, Loss Adv_d: 1.2332 ------ Loss G: 1.4385, Curve Loss: 0.1377, Chamfer Loss: 0.2764\n",
      "Epoch [69/1000]  Loss D: 1.9486, Loss Adv_d: 1.2325 ------ Loss G: 1.4333, Curve Loss: 0.1368, Chamfer Loss: 0.2661\n",
      "Epoch [70/1000]  Loss D: 1.9583, Loss Adv_d: 1.2378 ------ Loss G: 1.4462, Curve Loss: 0.1386, Chamfer Loss: 0.2733\n",
      "Epoch [71/1000]  Loss D: 1.9527, Loss Adv_d: 1.2414 ------ Loss G: 1.4390, Curve Loss: 0.1366, Chamfer Loss: 0.2662\n",
      "Epoch [72/1000]  Loss D: 1.9525, Loss Adv_d: 1.2404 ------ Loss G: 1.4452, Curve Loss: 0.1351, Chamfer Loss: 0.2681\n",
      "Epoch [73/1000]  Loss D: 1.9873, Loss Adv_d: 1.2415 ------ Loss G: 1.4888, Curve Loss: 0.1377, Chamfer Loss: 0.3049\n",
      "Epoch [74/1000]  Loss D: 1.9531, Loss Adv_d: 1.2443 ------ Loss G: 1.4566, Curve Loss: 0.1371, Chamfer Loss: 0.2712\n",
      "Epoch [75/1000]  Loss D: 1.9481, Loss Adv_d: 1.2437 ------ Loss G: 1.4563, Curve Loss: 0.1373, Chamfer Loss: 0.2676\n",
      "Epoch [76/1000]  Loss D: 1.9376, Loss Adv_d: 1.2407 ------ Loss G: 1.4529, Curve Loss: 0.1366, Chamfer Loss: 0.2613\n",
      "Epoch [77/1000]  Loss D: 1.9362, Loss Adv_d: 1.2436 ------ Loss G: 1.4520, Curve Loss: 0.1354, Chamfer Loss: 0.2586\n",
      "Epoch [78/1000]  Loss D: 1.9620, Loss Adv_d: 1.2403 ------ Loss G: 1.4886, Curve Loss: 0.1369, Chamfer Loss: 0.2894\n",
      "Epoch [79/1000]  Loss D: 1.9340, Loss Adv_d: 1.2484 ------ Loss G: 1.4559, Curve Loss: 0.1370, Chamfer Loss: 0.2562\n",
      "Epoch [80/1000]  Loss D: 1.9350, Loss Adv_d: 1.2467 ------ Loss G: 1.4627, Curve Loss: 0.1387, Chamfer Loss: 0.2585\n",
      "Epoch [81/1000]  Loss D: 1.9269, Loss Adv_d: 1.2430 ------ Loss G: 1.4631, Curve Loss: 0.1367, Chamfer Loss: 0.2558\n",
      "Epoch [82/1000]  Loss D: 1.9297, Loss Adv_d: 1.2505 ------ Loss G: 1.4654, Curve Loss: 0.1371, Chamfer Loss: 0.2545\n",
      "Epoch [83/1000]  Loss D: 1.9225, Loss Adv_d: 1.2411 ------ Loss G: 1.4719, Curve Loss: 0.1376, Chamfer Loss: 0.2581\n",
      "Epoch [84/1000]  Loss D: 1.9315, Loss Adv_d: 1.2452 ------ Loss G: 1.4802, Curve Loss: 0.1360, Chamfer Loss: 0.2645\n",
      "Epoch [85/1000]  Loss D: 1.9326, Loss Adv_d: 1.2442 ------ Loss G: 1.4897, Curve Loss: 0.1374, Chamfer Loss: 0.2682\n",
      "Epoch [86/1000]  Loss D: 1.9173, Loss Adv_d: 1.2451 ------ Loss G: 1.4768, Curve Loss: 0.1371, Chamfer Loss: 0.2537\n",
      "Epoch [87/1000]  Loss D: 1.9193, Loss Adv_d: 1.2426 ------ Loss G: 1.4838, Curve Loss: 0.1363, Chamfer Loss: 0.2601\n",
      "Epoch [88/1000]  Loss D: 1.9160, Loss Adv_d: 1.2439 ------ Loss G: 1.4826, Curve Loss: 0.1374, Chamfer Loss: 0.2559\n",
      "Epoch [89/1000]  Loss D: 1.9094, Loss Adv_d: 1.2426 ------ Loss G: 1.4827, Curve Loss: 0.1376, Chamfer Loss: 0.2518\n",
      "Epoch [90/1000]  Loss D: 1.9136, Loss Adv_d: 1.2423 ------ Loss G: 1.4913, Curve Loss: 0.1365, Chamfer Loss: 0.2590\n",
      "Epoch [91/1000]  Loss D: 1.9012, Loss Adv_d: 1.2387 ------ Loss G: 1.4908, Curve Loss: 0.1372, Chamfer Loss: 0.2531\n",
      "Epoch [92/1000]  Loss D: 1.8954, Loss Adv_d: 1.2365 ------ Loss G: 1.4907, Curve Loss: 0.1368, Chamfer Loss: 0.2507\n",
      "Epoch [93/1000]  Loss D: 1.8929, Loss Adv_d: 1.2373 ------ Loss G: 1.4897, Curve Loss: 0.1366, Chamfer Loss: 0.2477\n",
      "Epoch [94/1000]  Loss D: 1.8842, Loss Adv_d: 1.2333 ------ Loss G: 1.4864, Curve Loss: 0.1342, Chamfer Loss: 0.2443\n",
      "Epoch [95/1000]  Loss D: 1.8984, Loss Adv_d: 1.2287 ------ Loss G: 1.5134, Curve Loss: 0.1391, Chamfer Loss: 0.2634\n",
      "Epoch [96/1000]  Loss D: 1.8810, Loss Adv_d: 1.2316 ------ Loss G: 1.5021, Curve Loss: 0.1376, Chamfer Loss: 0.2466\n",
      "Epoch [97/1000]  Loss D: 1.8720, Loss Adv_d: 1.2256 ------ Loss G: 1.5054, Curve Loss: 0.1369, Chamfer Loss: 0.2465\n",
      "Epoch [98/1000]  Loss D: 1.8714, Loss Adv_d: 1.2258 ------ Loss G: 1.5066, Curve Loss: 0.1360, Chamfer Loss: 0.2464\n",
      "Epoch [99/1000]  Loss D: 1.8667, Loss Adv_d: 1.2271 ------ Loss G: 1.5057, Curve Loss: 0.1372, Chamfer Loss: 0.2418\n",
      "Epoch [100/1000]  Loss D: 1.9179, Loss Adv_d: 1.2220 ------ Loss G: 1.5655, Curve Loss: 0.1382, Chamfer Loss: 0.2994\n",
      "Epoch [101/1000]  Loss D: 1.8700, Loss Adv_d: 1.2177 ------ Loss G: 1.5315, Curve Loss: 0.1385, Chamfer Loss: 0.2590\n",
      "Epoch [102/1000]  Loss D: 1.8629, Loss Adv_d: 1.2207 ------ Loss G: 1.5249, Curve Loss: 0.1364, Chamfer Loss: 0.2501\n",
      "Epoch [103/1000]  Loss D: 1.8764, Loss Adv_d: 1.2188 ------ Loss G: 1.5441, Curve Loss: 0.1379, Chamfer Loss: 0.2665\n",
      "Epoch [104/1000]  Loss D: 1.8628, Loss Adv_d: 1.2188 ------ Loss G: 1.5305, Curve Loss: 0.1376, Chamfer Loss: 0.2540\n",
      "Epoch [105/1000]  Loss D: 1.8551, Loss Adv_d: 1.2139 ------ Loss G: 1.5294, Curve Loss: 0.1375, Chamfer Loss: 0.2514\n",
      "Epoch [106/1000]  Loss D: 1.8466, Loss Adv_d: 1.2093 ------ Loss G: 1.5275, Curve Loss: 0.1379, Chamfer Loss: 0.2478\n",
      "Epoch [107/1000]  Loss D: 1.8447, Loss Adv_d: 1.2107 ------ Loss G: 1.5258, Curve Loss: 0.1364, Chamfer Loss: 0.2450\n",
      "Epoch [108/1000]  Loss D: 1.8455, Loss Adv_d: 1.2112 ------ Loss G: 1.5290, Curve Loss: 0.1370, Chamfer Loss: 0.2470\n",
      "Epoch [109/1000]  Loss D: 1.8313, Loss Adv_d: 1.2031 ------ Loss G: 1.5242, Curve Loss: 0.1372, Chamfer Loss: 0.2412\n",
      "Epoch [110/1000]  Loss D: 1.8684, Loss Adv_d: 1.2027 ------ Loss G: 1.5639, Curve Loss: 0.1361, Chamfer Loss: 0.2787\n",
      "Epoch [111/1000]  Loss D: 1.8336, Loss Adv_d: 1.2002 ------ Loss G: 1.5367, Curve Loss: 0.1371, Chamfer Loss: 0.2485\n",
      "Epoch [112/1000]  Loss D: 1.8307, Loss Adv_d: 1.1954 ------ Loss G: 1.5388, Curve Loss: 0.1351, Chamfer Loss: 0.2507\n",
      "Epoch [113/1000]  Loss D: 1.8258, Loss Adv_d: 1.1937 ------ Loss G: 1.5402, Curve Loss: 0.1373, Chamfer Loss: 0.2481\n",
      "Epoch [114/1000]  Loss D: 1.8208, Loss Adv_d: 1.1927 ------ Loss G: 1.5424, Curve Loss: 0.1397, Chamfer Loss: 0.2449\n",
      "Epoch [115/1000]  Loss D: 1.8104, Loss Adv_d: 1.1875 ------ Loss G: 1.5372, Curve Loss: 0.1360, Chamfer Loss: 0.2414\n",
      "Epoch [116/1000]  Loss D: 1.8256, Loss Adv_d: 1.1909 ------ Loss G: 1.5516, Curve Loss: 0.1380, Chamfer Loss: 0.2535\n",
      "Epoch [117/1000]  Loss D: 1.8052, Loss Adv_d: 1.1851 ------ Loss G: 1.5418, Curve Loss: 0.1369, Chamfer Loss: 0.2414\n",
      "Epoch [118/1000]  Loss D: 1.8139, Loss Adv_d: 1.1883 ------ Loss G: 1.5478, Curve Loss: 0.1360, Chamfer Loss: 0.2475\n",
      "Epoch [119/1000]  Loss D: 1.7995, Loss Adv_d: 1.1805 ------ Loss G: 1.5408, Curve Loss: 0.1370, Chamfer Loss: 0.2403\n",
      "Epoch [120/1000]  Loss D: 1.7980, Loss Adv_d: 1.1825 ------ Loss G: 1.5367, Curve Loss: 0.1373, Chamfer Loss: 0.2363\n",
      "Epoch [121/1000]  Loss D: 1.7894, Loss Adv_d: 1.1761 ------ Loss G: 1.5331, Curve Loss: 0.1356, Chamfer Loss: 0.2336\n",
      "Epoch [122/1000]  Loss D: 1.7844, Loss Adv_d: 1.1730 ------ Loss G: 1.5339, Curve Loss: 0.1373, Chamfer Loss: 0.2321\n",
      "Epoch [123/1000]  Loss D: 1.7868, Loss Adv_d: 1.1757 ------ Loss G: 1.5370, Curve Loss: 0.1379, Chamfer Loss: 0.2327\n",
      "Epoch [124/1000]  Loss D: 1.7925, Loss Adv_d: 1.1716 ------ Loss G: 1.5512, Curve Loss: 0.1378, Chamfer Loss: 0.2437\n",
      "Epoch [125/1000]  Loss D: 1.7757, Loss Adv_d: 1.1696 ------ Loss G: 1.5360, Curve Loss: 0.1354, Chamfer Loss: 0.2295\n",
      "Epoch [126/1000]  Loss D: 1.7766, Loss Adv_d: 1.1710 ------ Loss G: 1.5380, Curve Loss: 0.1368, Chamfer Loss: 0.2303\n",
      "Epoch [127/1000]  Loss D: 1.7688, Loss Adv_d: 1.1657 ------ Loss G: 1.5360, Curve Loss: 0.1376, Chamfer Loss: 0.2281\n",
      "Epoch [128/1000]  Loss D: 1.7653, Loss Adv_d: 1.1632 ------ Loss G: 1.5341, Curve Loss: 0.1370, Chamfer Loss: 0.2266\n",
      "Epoch [129/1000]  Loss D: 1.7692, Loss Adv_d: 1.1619 ------ Loss G: 1.5394, Curve Loss: 0.1363, Chamfer Loss: 0.2317\n",
      "Epoch [130/1000]  Loss D: 1.7677, Loss Adv_d: 1.1555 ------ Loss G: 1.5558, Curve Loss: 0.1375, Chamfer Loss: 0.2394\n",
      "Epoch [131/1000]  Loss D: 1.7736, Loss Adv_d: 1.1555 ------ Loss G: 1.5634, Curve Loss: 0.1366, Chamfer Loss: 0.2463\n",
      "Epoch [132/1000]  Loss D: 1.7675, Loss Adv_d: 1.1531 ------ Loss G: 1.5548, Curve Loss: 0.1365, Chamfer Loss: 0.2411\n",
      "Epoch [133/1000]  Loss D: 1.7576, Loss Adv_d: 1.1491 ------ Loss G: 1.5558, Curve Loss: 0.1385, Chamfer Loss: 0.2362\n",
      "Epoch [134/1000]  Loss D: 1.7591, Loss Adv_d: 1.1566 ------ Loss G: 1.5534, Curve Loss: 0.1363, Chamfer Loss: 0.2321\n",
      "Epoch [135/1000]  Loss D: 1.7560, Loss Adv_d: 1.1517 ------ Loss G: 1.5580, Curve Loss: 0.1392, Chamfer Loss: 0.2342\n",
      "Epoch [136/1000]  Loss D: 1.7485, Loss Adv_d: 1.1456 ------ Loss G: 1.5538, Curve Loss: 0.1381, Chamfer Loss: 0.2319\n",
      "Epoch [137/1000]  Loss D: 1.7504, Loss Adv_d: 1.1492 ------ Loss G: 1.5531, Curve Loss: 0.1389, Chamfer Loss: 0.2305\n",
      "Epoch [138/1000]  Loss D: 1.7798, Loss Adv_d: 1.1509 ------ Loss G: 1.5781, Curve Loss: 0.1386, Chamfer Loss: 0.2579\n",
      "Epoch [139/1000]  Loss D: 1.7534, Loss Adv_d: 1.1424 ------ Loss G: 1.5695, Curve Loss: 0.1355, Chamfer Loss: 0.2444\n",
      "Epoch [140/1000]  Loss D: 1.7429, Loss Adv_d: 1.1388 ------ Loss G: 1.5657, Curve Loss: 0.1382, Chamfer Loss: 0.2370\n",
      "Epoch [141/1000]  Loss D: 1.7489, Loss Adv_d: 1.1424 ------ Loss G: 1.5605, Curve Loss: 0.1382, Chamfer Loss: 0.2364\n",
      "Epoch [142/1000]  Loss D: 1.7451, Loss Adv_d: 1.1414 ------ Loss G: 1.5497, Curve Loss: 0.1380, Chamfer Loss: 0.2310\n",
      "Epoch [143/1000]  Loss D: 1.7549, Loss Adv_d: 1.1427 ------ Loss G: 1.5536, Curve Loss: 0.1384, Chamfer Loss: 0.2376\n",
      "Epoch [144/1000]  Loss D: 1.7638, Loss Adv_d: 1.1474 ------ Loss G: 1.5536, Curve Loss: 0.1363, Chamfer Loss: 0.2411\n",
      "Epoch [145/1000]  Loss D: 1.7543, Loss Adv_d: 1.1477 ------ Loss G: 1.5462, Curve Loss: 0.1360, Chamfer Loss: 0.2326\n",
      "Epoch [146/1000]  Loss D: 1.7503, Loss Adv_d: 1.1430 ------ Loss G: 1.5483, Curve Loss: 0.1376, Chamfer Loss: 0.2331\n",
      "Epoch [147/1000]  Loss D: 1.7745, Loss Adv_d: 1.1461 ------ Loss G: 1.5700, Curve Loss: 0.1377, Chamfer Loss: 0.2542\n",
      "Epoch [148/1000]  Loss D: 1.7490, Loss Adv_d: 1.1477 ------ Loss G: 1.5510, Curve Loss: 0.1395, Chamfer Loss: 0.2295\n",
      "Epoch [149/1000]  Loss D: 1.7835, Loss Adv_d: 1.1445 ------ Loss G: 1.5861, Curve Loss: 0.1379, Chamfer Loss: 0.2668\n",
      "Epoch [150/1000]  Loss D: 1.7576, Loss Adv_d: 1.1500 ------ Loss G: 1.5467, Curve Loss: 0.1366, Chamfer Loss: 0.2332\n",
      "Epoch [151/1000]  Loss D: 1.7626, Loss Adv_d: 1.1466 ------ Loss G: 1.5573, Curve Loss: 0.1380, Chamfer Loss: 0.2413\n",
      "Epoch [152/1000]  Loss D: 1.7826, Loss Adv_d: 1.1551 ------ Loss G: 1.5663, Curve Loss: 0.1382, Chamfer Loss: 0.2522\n",
      "Epoch [153/1000]  Loss D: 1.7574, Loss Adv_d: 1.1521 ------ Loss G: 1.5486, Curve Loss: 0.1368, Chamfer Loss: 0.2320\n",
      "Epoch [154/1000]  Loss D: 1.7948, Loss Adv_d: 1.1514 ------ Loss G: 1.5887, Curve Loss: 0.1380, Chamfer Loss: 0.2709\n",
      "Epoch [155/1000]  Loss D: 1.7540, Loss Adv_d: 1.1444 ------ Loss G: 1.5636, Curve Loss: 0.1376, Chamfer Loss: 0.2395\n",
      "Epoch [156/1000]  Loss D: 1.7512, Loss Adv_d: 1.1464 ------ Loss G: 1.5605, Curve Loss: 0.1377, Chamfer Loss: 0.2351\n",
      "Epoch [157/1000]  Loss D: 1.7836, Loss Adv_d: 1.1476 ------ Loss G: 1.5872, Curve Loss: 0.1382, Chamfer Loss: 0.2642\n",
      "Epoch [158/1000]  Loss D: 1.7513, Loss Adv_d: 1.1487 ------ Loss G: 1.5525, Curve Loss: 0.1384, Chamfer Loss: 0.2305\n",
      "Epoch [159/1000]  Loss D: 1.7761, Loss Adv_d: 1.1492 ------ Loss G: 1.5756, Curve Loss: 0.1382, Chamfer Loss: 0.2548\n",
      "Epoch [160/1000]  Loss D: 1.7588, Loss Adv_d: 1.1567 ------ Loss G: 1.5489, Curve Loss: 0.1376, Chamfer Loss: 0.2297\n",
      "Epoch [161/1000]  Loss D: 1.7509, Loss Adv_d: 1.1499 ------ Loss G: 1.5467, Curve Loss: 0.1377, Chamfer Loss: 0.2278\n",
      "Epoch [162/1000]  Loss D: 1.7741, Loss Adv_d: 1.1531 ------ Loss G: 1.5686, Curve Loss: 0.1399, Chamfer Loss: 0.2478\n",
      "Epoch [163/1000]  Loss D: 1.7539, Loss Adv_d: 1.1517 ------ Loss G: 1.5540, Curve Loss: 0.1370, Chamfer Loss: 0.2311\n",
      "Epoch [164/1000]  Loss D: 1.7930, Loss Adv_d: 1.1525 ------ Loss G: 1.5997, Curve Loss: 0.1405, Chamfer Loss: 0.2706\n",
      "Epoch [165/1000]  Loss D: 1.7465, Loss Adv_d: 1.1484 ------ Loss G: 1.5607, Curve Loss: 0.1352, Chamfer Loss: 0.2317\n",
      "Epoch [166/1000]  Loss D: 1.7443, Loss Adv_d: 1.1482 ------ Loss G: 1.5599, Curve Loss: 0.1359, Chamfer Loss: 0.2301\n",
      "Epoch [167/1000]  Loss D: 1.7390, Loss Adv_d: 1.1450 ------ Loss G: 1.5553, Curve Loss: 0.1375, Chamfer Loss: 0.2265\n",
      "Epoch [168/1000]  Loss D: 1.8223, Loss Adv_d: 1.1486 ------ Loss G: 1.6350, Curve Loss: 0.1396, Chamfer Loss: 0.3053\n",
      "Epoch [169/1000]  Loss D: 1.7448, Loss Adv_d: 1.1395 ------ Loss G: 1.5774, Curve Loss: 0.1339, Chamfer Loss: 0.2424\n",
      "Epoch [170/1000]  Loss D: 1.7258, Loss Adv_d: 1.1350 ------ Loss G: 1.5714, Curve Loss: 0.1365, Chamfer Loss: 0.2298\n",
      "Epoch [171/1000]  Loss D: 1.7755, Loss Adv_d: 1.1381 ------ Loss G: 1.6167, Curve Loss: 0.1400, Chamfer Loss: 0.2742\n",
      "Epoch [172/1000]  Loss D: 1.7249, Loss Adv_d: 1.1357 ------ Loss G: 1.5686, Curve Loss: 0.1366, Chamfer Loss: 0.2271\n",
      "Epoch [173/1000]  Loss D: 1.7504, Loss Adv_d: 1.1367 ------ Loss G: 1.5906, Curve Loss: 0.1383, Chamfer Loss: 0.2502\n",
      "Epoch [174/1000]  Loss D: 1.7503, Loss Adv_d: 1.1338 ------ Loss G: 1.5943, Curve Loss: 0.1377, Chamfer Loss: 0.2535\n",
      "Epoch [175/1000]  Loss D: 1.7476, Loss Adv_d: 1.1380 ------ Loss G: 1.5914, Curve Loss: 0.1387, Chamfer Loss: 0.2477\n",
      "Epoch [176/1000]  Loss D: 1.7575, Loss Adv_d: 1.1310 ------ Loss G: 1.6114, Curve Loss: 0.1391, Chamfer Loss: 0.2652\n",
      "Epoch [177/1000]  Loss D: 1.7300, Loss Adv_d: 1.1317 ------ Loss G: 1.5782, Curve Loss: 0.1369, Chamfer Loss: 0.2362\n",
      "Epoch [178/1000]  Loss D: 1.7371, Loss Adv_d: 1.1322 ------ Loss G: 1.5845, Curve Loss: 0.1379, Chamfer Loss: 0.2418\n",
      "Epoch [179/1000]  Loss D: 1.7455, Loss Adv_d: 1.1355 ------ Loss G: 1.5858, Curve Loss: 0.1373, Chamfer Loss: 0.2454\n",
      "Epoch [180/1000]  Loss D: 1.7352, Loss Adv_d: 1.1374 ------ Loss G: 1.5730, Curve Loss: 0.1380, Chamfer Loss: 0.2333\n",
      "Epoch [181/1000]  Loss D: 1.7344, Loss Adv_d: 1.1380 ------ Loss G: 1.5687, Curve Loss: 0.1363, Chamfer Loss: 0.2320\n",
      "Epoch [182/1000]  Loss D: 1.7325, Loss Adv_d: 1.1387 ------ Loss G: 1.5678, Curve Loss: 0.1386, Chamfer Loss: 0.2294\n",
      "Epoch [183/1000]  Loss D: 1.7320, Loss Adv_d: 1.1409 ------ Loss G: 1.5638, Curve Loss: 0.1378, Chamfer Loss: 0.2268\n",
      "Epoch [184/1000]  Loss D: 1.7377, Loss Adv_d: 1.1414 ------ Loss G: 1.5691, Curve Loss: 0.1374, Chamfer Loss: 0.2314\n",
      "Epoch [185/1000]  Loss D: 1.7374, Loss Adv_d: 1.1398 ------ Loss G: 1.5734, Curve Loss: 0.1380, Chamfer Loss: 0.2336\n",
      "Epoch [186/1000]  Loss D: 1.7339, Loss Adv_d: 1.1388 ------ Loss G: 1.5793, Curve Loss: 0.1389, Chamfer Loss: 0.2338\n",
      "Epoch [187/1000]  Loss D: 1.7219, Loss Adv_d: 1.1342 ------ Loss G: 1.5738, Curve Loss: 0.1347, Chamfer Loss: 0.2291\n",
      "Epoch [188/1000]  Loss D: 1.7259, Loss Adv_d: 1.1328 ------ Loss G: 1.5745, Curve Loss: 0.1354, Chamfer Loss: 0.2326\n",
      "Epoch [189/1000]  Loss D: 1.7254, Loss Adv_d: 1.1335 ------ Loss G: 1.5704, Curve Loss: 0.1358, Chamfer Loss: 0.2299\n",
      "Epoch [190/1000]  Loss D: 1.8084, Loss Adv_d: 1.1353 ------ Loss G: 1.6556, Curve Loss: 0.1391, Chamfer Loss: 0.3113\n",
      "Epoch [191/1000]  Loss D: 1.7168, Loss Adv_d: 1.1310 ------ Loss G: 1.5774, Curve Loss: 0.1365, Chamfer Loss: 0.2276\n",
      "Epoch [192/1000]  Loss D: 1.7127, Loss Adv_d: 1.1263 ------ Loss G: 1.5807, Curve Loss: 0.1357, Chamfer Loss: 0.2294\n",
      "Epoch [193/1000]  Loss D: 1.7341, Loss Adv_d: 1.1261 ------ Loss G: 1.5996, Curve Loss: 0.1380, Chamfer Loss: 0.2495\n",
      "Epoch [194/1000]  Loss D: 1.7254, Loss Adv_d: 1.1294 ------ Loss G: 1.5902, Curve Loss: 0.1390, Chamfer Loss: 0.2380\n",
      "Epoch [195/1000]  Loss D: 1.7111, Loss Adv_d: 1.1246 ------ Loss G: 1.5826, Curve Loss: 0.1379, Chamfer Loss: 0.2292\n",
      "Epoch [196/1000]  Loss D: 1.7095, Loss Adv_d: 1.1223 ------ Loss G: 1.5834, Curve Loss: 0.1374, Chamfer Loss: 0.2298\n",
      "Epoch [197/1000]  Loss D: 1.7829, Loss Adv_d: 1.1259 ------ Loss G: 1.6526, Curve Loss: 0.1375, Chamfer Loss: 0.2993\n",
      "Epoch [198/1000]  Loss D: 1.7251, Loss Adv_d: 1.1227 ------ Loss G: 1.6108, Curve Loss: 0.1370, Chamfer Loss: 0.2494\n",
      "Epoch [199/1000]  Loss D: 1.7076, Loss Adv_d: 1.1197 ------ Loss G: 1.6050, Curve Loss: 0.1376, Chamfer Loss: 0.2373\n",
      "Epoch [200/1000]  Loss D: 1.7024, Loss Adv_d: 1.1155 ------ Loss G: 1.6025, Curve Loss: 0.1358, Chamfer Loss: 0.2357\n",
      "Epoch [201/1000]  Loss D: 1.7003, Loss Adv_d: 1.1171 ------ Loss G: 1.5992, Curve Loss: 0.1355, Chamfer Loss: 0.2321\n",
      "Epoch [202/1000]  Loss D: 1.7078, Loss Adv_d: 1.1174 ------ Loss G: 1.6068, Curve Loss: 0.1373, Chamfer Loss: 0.2387\n",
      "Epoch [203/1000]  Loss D: 1.6979, Loss Adv_d: 1.1176 ------ Loss G: 1.5959, Curve Loss: 0.1357, Chamfer Loss: 0.2299\n",
      "Epoch [204/1000]  Loss D: 1.7018, Loss Adv_d: 1.1159 ------ Loss G: 1.5992, Curve Loss: 0.1350, Chamfer Loss: 0.2347\n",
      "Epoch [205/1000]  Loss D: 1.7254, Loss Adv_d: 1.1186 ------ Loss G: 1.6208, Curve Loss: 0.1372, Chamfer Loss: 0.2554\n",
      "Epoch [206/1000]  Loss D: 1.7208, Loss Adv_d: 1.1159 ------ Loss G: 1.6169, Curve Loss: 0.1375, Chamfer Loss: 0.2528\n",
      "Epoch [207/1000]  Loss D: 1.6926, Loss Adv_d: 1.1111 ------ Loss G: 1.6008, Curve Loss: 0.1358, Chamfer Loss: 0.2323\n",
      "Epoch [208/1000]  Loss D: 1.6998, Loss Adv_d: 1.1085 ------ Loss G: 1.6156, Curve Loss: 0.1383, Chamfer Loss: 0.2425\n",
      "Epoch [209/1000]  Loss D: 1.6918, Loss Adv_d: 1.1079 ------ Loss G: 1.6091, Curve Loss: 0.1371, Chamfer Loss: 0.2356\n",
      "Epoch [210/1000]  Loss D: 1.6917, Loss Adv_d: 1.1083 ------ Loss G: 1.6066, Curve Loss: 0.1354, Chamfer Loss: 0.2346\n",
      "Epoch [211/1000]  Loss D: 1.7227, Loss Adv_d: 1.1106 ------ Loss G: 1.6412, Curve Loss: 0.1402, Chamfer Loss: 0.2644\n",
      "Epoch [212/1000]  Loss D: 1.6868, Loss Adv_d: 1.1039 ------ Loss G: 1.6059, Curve Loss: 0.1344, Chamfer Loss: 0.2347\n",
      "Epoch [213/1000]  Loss D: 1.7096, Loss Adv_d: 1.1039 ------ Loss G: 1.6262, Curve Loss: 0.1361, Chamfer Loss: 0.2560\n",
      "Epoch [214/1000]  Loss D: 1.6911, Loss Adv_d: 1.1069 ------ Loss G: 1.6059, Curve Loss: 0.1368, Chamfer Loss: 0.2346\n",
      "Epoch [215/1000]  Loss D: 1.6847, Loss Adv_d: 1.1022 ------ Loss G: 1.6041, Curve Loss: 0.1346, Chamfer Loss: 0.2330\n",
      "Epoch [216/1000]  Loss D: 1.6806, Loss Adv_d: 1.1011 ------ Loss G: 1.6072, Curve Loss: 0.1380, Chamfer Loss: 0.2310\n",
      "Epoch [217/1000]  Loss D: 1.6864, Loss Adv_d: 1.1098 ------ Loss G: 1.6010, Curve Loss: 0.1373, Chamfer Loss: 0.2280\n",
      "Epoch [218/1000]  Loss D: 1.6822, Loss Adv_d: 1.1006 ------ Loss G: 1.6049, Curve Loss: 0.1365, Chamfer Loss: 0.2329\n",
      "Epoch [219/1000]  Loss D: 1.6791, Loss Adv_d: 1.1061 ------ Loss G: 1.5989, Curve Loss: 0.1359, Chamfer Loss: 0.2254\n",
      "Epoch [220/1000]  Loss D: 1.6732, Loss Adv_d: 1.1045 ------ Loss G: 1.5971, Curve Loss: 0.1363, Chamfer Loss: 0.2216\n",
      "Epoch [221/1000]  Loss D: 1.6706, Loss Adv_d: 1.1033 ------ Loss G: 1.5922, Curve Loss: 0.1339, Chamfer Loss: 0.2199\n",
      "Epoch [222/1000]  Loss D: 1.7463, Loss Adv_d: 1.1035 ------ Loss G: 1.6707, Curve Loss: 0.1375, Chamfer Loss: 0.2949\n",
      "Epoch [223/1000]  Loss D: 1.7148, Loss Adv_d: 1.0990 ------ Loss G: 1.6502, Curve Loss: 0.1385, Chamfer Loss: 0.2704\n",
      "Epoch [224/1000]  Loss D: 1.6772, Loss Adv_d: 1.1011 ------ Loss G: 1.6100, Curve Loss: 0.1369, Chamfer Loss: 0.2310\n",
      "Epoch [225/1000]  Loss D: 1.6686, Loss Adv_d: 1.0949 ------ Loss G: 1.6044, Curve Loss: 0.1351, Chamfer Loss: 0.2279\n",
      "Epoch [226/1000]  Loss D: 1.6732, Loss Adv_d: 1.0946 ------ Loss G: 1.6089, Curve Loss: 0.1370, Chamfer Loss: 0.2313\n",
      "Epoch [227/1000]  Loss D: 1.6731, Loss Adv_d: 1.0951 ------ Loss G: 1.6095, Curve Loss: 0.1366, Chamfer Loss: 0.2313\n",
      "Epoch [228/1000]  Loss D: 1.6778, Loss Adv_d: 1.0964 ------ Loss G: 1.6104, Curve Loss: 0.1365, Chamfer Loss: 0.2345\n",
      "Epoch [229/1000]  Loss D: 1.7711, Loss Adv_d: 1.0968 ------ Loss G: 1.7093, Curve Loss: 0.1414, Chamfer Loss: 0.3278\n",
      "Epoch [230/1000]  Loss D: 1.6694, Loss Adv_d: 1.0961 ------ Loss G: 1.6025, Curve Loss: 0.1353, Chamfer Loss: 0.2268\n",
      "Epoch [231/1000]  Loss D: 1.6690, Loss Adv_d: 1.0901 ------ Loss G: 1.6116, Curve Loss: 0.1369, Chamfer Loss: 0.2329\n",
      "Epoch [232/1000]  Loss D: 1.6637, Loss Adv_d: 1.0909 ------ Loss G: 1.6015, Curve Loss: 0.1348, Chamfer Loss: 0.2263\n",
      "Epoch [233/1000]  Loss D: 1.6636, Loss Adv_d: 1.0861 ------ Loss G: 1.6044, Curve Loss: 0.1378, Chamfer Loss: 0.2297\n",
      "Epoch [234/1000]  Loss D: 1.7471, Loss Adv_d: 1.0881 ------ Loss G: 1.6889, Curve Loss: 0.1390, Chamfer Loss: 0.3111\n",
      "Epoch [235/1000]  Loss D: 1.6641, Loss Adv_d: 1.0883 ------ Loss G: 1.6125, Curve Loss: 0.1378, Chamfer Loss: 0.2304\n",
      "Epoch [236/1000]  Loss D: 1.6555, Loss Adv_d: 1.0847 ------ Loss G: 1.6076, Curve Loss: 0.1366, Chamfer Loss: 0.2258\n",
      "Epoch [237/1000]  Loss D: 1.6645, Loss Adv_d: 1.0879 ------ Loss G: 1.6096, Curve Loss: 0.1360, Chamfer Loss: 0.2308\n",
      "Epoch [238/1000]  Loss D: 1.6485, Loss Adv_d: 1.0839 ------ Loss G: 1.6038, Curve Loss: 0.1371, Chamfer Loss: 0.2200\n",
      "Epoch [239/1000]  Loss D: 1.6515, Loss Adv_d: 1.0888 ------ Loss G: 1.6004, Curve Loss: 0.1349, Chamfer Loss: 0.2187\n",
      "Epoch [240/1000]  Loss D: 1.7356, Loss Adv_d: 1.0879 ------ Loss G: 1.6860, Curve Loss: 0.1402, Chamfer Loss: 0.3024\n",
      "Epoch [241/1000]  Loss D: 1.6509, Loss Adv_d: 1.0851 ------ Loss G: 1.6056, Curve Loss: 0.1362, Chamfer Loss: 0.2222\n",
      "Epoch [242/1000]  Loss D: 1.7158, Loss Adv_d: 1.0863 ------ Loss G: 1.6723, Curve Loss: 0.1405, Chamfer Loss: 0.2851\n",
      "Epoch [243/1000]  Loss D: 1.6592, Loss Adv_d: 1.0822 ------ Loss G: 1.6168, Curve Loss: 0.1376, Chamfer Loss: 0.2327\n",
      "Epoch [244/1000]  Loss D: 1.6607, Loss Adv_d: 1.0847 ------ Loss G: 1.6146, Curve Loss: 0.1368, Chamfer Loss: 0.2316\n",
      "Epoch [245/1000]  Loss D: 1.6952, Loss Adv_d: 1.0815 ------ Loss G: 1.6513, Curve Loss: 0.1382, Chamfer Loss: 0.2682\n",
      "Epoch [246/1000]  Loss D: 1.6533, Loss Adv_d: 1.0786 ------ Loss G: 1.6140, Curve Loss: 0.1365, Chamfer Loss: 0.2305\n",
      "Epoch [247/1000]  Loss D: 1.6669, Loss Adv_d: 1.0836 ------ Loss G: 1.6209, Curve Loss: 0.1397, Chamfer Loss: 0.2380\n",
      "Epoch [248/1000]  Loss D: 1.6558, Loss Adv_d: 1.0791 ------ Loss G: 1.6152, Curve Loss: 0.1387, Chamfer Loss: 0.2312\n",
      "Epoch [249/1000]  Loss D: 1.6604, Loss Adv_d: 1.0871 ------ Loss G: 1.6091, Curve Loss: 0.1359, Chamfer Loss: 0.2279\n",
      "Epoch [250/1000]  Loss D: 1.6523, Loss Adv_d: 1.0790 ------ Loss G: 1.6097, Curve Loss: 0.1375, Chamfer Loss: 0.2275\n",
      "Epoch [251/1000]  Loss D: 1.6517, Loss Adv_d: 1.0792 ------ Loss G: 1.6109, Curve Loss: 0.1371, Chamfer Loss: 0.2274\n",
      "Epoch [252/1000]  Loss D: 1.6482, Loss Adv_d: 1.0787 ------ Loss G: 1.6091, Curve Loss: 0.1379, Chamfer Loss: 0.2248\n",
      "Epoch [253/1000]  Loss D: 1.6509, Loss Adv_d: 1.0840 ------ Loss G: 1.6042, Curve Loss: 0.1377, Chamfer Loss: 0.2219\n",
      "Epoch [254/1000]  Loss D: 1.6480, Loss Adv_d: 1.0799 ------ Loss G: 1.6001, Curve Loss: 0.1372, Chamfer Loss: 0.2214\n",
      "Epoch [255/1000]  Loss D: 1.6454, Loss Adv_d: 1.0800 ------ Loss G: 1.5949, Curve Loss: 0.1348, Chamfer Loss: 0.2183\n",
      "Epoch [256/1000]  Loss D: 1.6419, Loss Adv_d: 1.0765 ------ Loss G: 1.5969, Curve Loss: 0.1372, Chamfer Loss: 0.2180\n",
      "Epoch [257/1000]  Loss D: 1.6469, Loss Adv_d: 1.0841 ------ Loss G: 1.5938, Curve Loss: 0.1365, Chamfer Loss: 0.2156\n",
      "Epoch [258/1000]  Loss D: 1.6419, Loss Adv_d: 1.0802 ------ Loss G: 1.5957, Curve Loss: 0.1388, Chamfer Loss: 0.2144\n",
      "Epoch [259/1000]  Loss D: 1.6523, Loss Adv_d: 1.0836 ------ Loss G: 1.6027, Curve Loss: 0.1359, Chamfer Loss: 0.2221\n",
      "Epoch [260/1000]  Loss D: 1.6719, Loss Adv_d: 1.0859 ------ Loss G: 1.6267, Curve Loss: 0.1370, Chamfer Loss: 0.2419\n",
      "Epoch [261/1000]  Loss D: 1.7053, Loss Adv_d: 1.0831 ------ Loss G: 1.6739, Curve Loss: 0.1389, Chamfer Loss: 0.2811\n",
      "Epoch [262/1000]  Loss D: 1.6664, Loss Adv_d: 1.0789 ------ Loss G: 1.6338, Curve Loss: 0.1376, Chamfer Loss: 0.2456\n",
      "Epoch [263/1000]  Loss D: 1.6712, Loss Adv_d: 1.0793 ------ Loss G: 1.6377, Curve Loss: 0.1387, Chamfer Loss: 0.2495\n",
      "Epoch [264/1000]  Loss D: 1.6520, Loss Adv_d: 1.0765 ------ Loss G: 1.6164, Curve Loss: 0.1387, Chamfer Loss: 0.2309\n",
      "Epoch [265/1000]  Loss D: 1.6530, Loss Adv_d: 1.0770 ------ Loss G: 1.6120, Curve Loss: 0.1379, Chamfer Loss: 0.2295\n",
      "Epoch [266/1000]  Loss D: 1.6509, Loss Adv_d: 1.0783 ------ Loss G: 1.6068, Curve Loss: 0.1389, Chamfer Loss: 0.2246\n",
      "Epoch [267/1000]  Loss D: 1.6575, Loss Adv_d: 1.0859 ------ Loss G: 1.6041, Curve Loss: 0.1389, Chamfer Loss: 0.2235\n",
      "Epoch [268/1000]  Loss D: 1.6532, Loss Adv_d: 1.0852 ------ Loss G: 1.5986, Curve Loss: 0.1376, Chamfer Loss: 0.2201\n",
      "Epoch [269/1000]  Loss D: 1.6544, Loss Adv_d: 1.0838 ------ Loss G: 1.5983, Curve Loss: 0.1377, Chamfer Loss: 0.2225\n",
      "Epoch [270/1000]  Loss D: 1.6501, Loss Adv_d: 1.0825 ------ Loss G: 1.5949, Curve Loss: 0.1372, Chamfer Loss: 0.2197\n",
      "Epoch [271/1000]  Loss D: 1.6784, Loss Adv_d: 1.0833 ------ Loss G: 1.6215, Curve Loss: 0.1374, Chamfer Loss: 0.2460\n",
      "Epoch [272/1000]  Loss D: 1.6599, Loss Adv_d: 1.0849 ------ Loss G: 1.6098, Curve Loss: 0.1389, Chamfer Loss: 0.2277\n",
      "Epoch [273/1000]  Loss D: 1.6500, Loss Adv_d: 1.0836 ------ Loss G: 1.6041, Curve Loss: 0.1363, Chamfer Loss: 0.2211\n",
      "Epoch [274/1000]  Loss D: 1.6552, Loss Adv_d: 1.0836 ------ Loss G: 1.6095, Curve Loss: 0.1373, Chamfer Loss: 0.2263\n",
      "Epoch [275/1000]  Loss D: 1.6789, Loss Adv_d: 1.0792 ------ Loss G: 1.6348, Curve Loss: 0.1385, Chamfer Loss: 0.2524\n",
      "Epoch [276/1000]  Loss D: 1.6665, Loss Adv_d: 1.0882 ------ Loss G: 1.6199, Curve Loss: 0.1389, Chamfer Loss: 0.2333\n",
      "Epoch [277/1000]  Loss D: 1.6601, Loss Adv_d: 1.0833 ------ Loss G: 1.6219, Curve Loss: 0.1391, Chamfer Loss: 0.2326\n",
      "Epoch [278/1000]  Loss D: 1.6518, Loss Adv_d: 1.0839 ------ Loss G: 1.6083, Curve Loss: 0.1360, Chamfer Loss: 0.2231\n",
      "Epoch [279/1000]  Loss D: 1.6609, Loss Adv_d: 1.0906 ------ Loss G: 1.6055, Curve Loss: 0.1374, Chamfer Loss: 0.2241\n",
      "Epoch [280/1000]  Loss D: 1.6925, Loss Adv_d: 1.0846 ------ Loss G: 1.6429, Curve Loss: 0.1398, Chamfer Loss: 0.2609\n",
      "Epoch [281/1000]  Loss D: 1.6497, Loss Adv_d: 1.0791 ------ Loss G: 1.6166, Curve Loss: 0.1374, Chamfer Loss: 0.2271\n",
      "Epoch [282/1000]  Loss D: 1.6551, Loss Adv_d: 1.0831 ------ Loss G: 1.6163, Curve Loss: 0.1382, Chamfer Loss: 0.2275\n",
      "Epoch [283/1000]  Loss D: 1.6727, Loss Adv_d: 1.0834 ------ Loss G: 1.6255, Curve Loss: 0.1371, Chamfer Loss: 0.2426\n",
      "Epoch [284/1000]  Loss D: 1.6638, Loss Adv_d: 1.0878 ------ Loss G: 1.6164, Curve Loss: 0.1392, Chamfer Loss: 0.2295\n",
      "Epoch [285/1000]  Loss D: 1.6622, Loss Adv_d: 1.0903 ------ Loss G: 1.6113, Curve Loss: 0.1381, Chamfer Loss: 0.2256\n",
      "Epoch [286/1000]  Loss D: 1.6705, Loss Adv_d: 1.0966 ------ Loss G: 1.6109, Curve Loss: 0.1383, Chamfer Loss: 0.2266\n",
      "Epoch [287/1000]  Loss D: 1.6668, Loss Adv_d: 1.0930 ------ Loss G: 1.6093, Curve Loss: 0.1380, Chamfer Loss: 0.2268\n",
      "Epoch [288/1000]  Loss D: 1.6691, Loss Adv_d: 1.0949 ------ Loss G: 1.6080, Curve Loss: 0.1347, Chamfer Loss: 0.2277\n",
      "Epoch [289/1000]  Loss D: 1.6795, Loss Adv_d: 1.0892 ------ Loss G: 1.6222, Curve Loss: 0.1369, Chamfer Loss: 0.2422\n",
      "Epoch [290/1000]  Loss D: 1.6794, Loss Adv_d: 1.0937 ------ Loss G: 1.6157, Curve Loss: 0.1339, Chamfer Loss: 0.2384\n",
      "Epoch [291/1000]  Loss D: 1.6820, Loss Adv_d: 1.1028 ------ Loss G: 1.6049, Curve Loss: 0.1351, Chamfer Loss: 0.2304\n",
      "Epoch [292/1000]  Loss D: 1.6850, Loss Adv_d: 1.0994 ------ Loss G: 1.6097, Curve Loss: 0.1381, Chamfer Loss: 0.2353\n",
      "Epoch [293/1000]  Loss D: 1.6812, Loss Adv_d: 1.0963 ------ Loss G: 1.6147, Curve Loss: 0.1380, Chamfer Loss: 0.2359\n",
      "Epoch [294/1000]  Loss D: 1.6737, Loss Adv_d: 1.0992 ------ Loss G: 1.6082, Curve Loss: 0.1375, Chamfer Loss: 0.2263\n",
      "Epoch [295/1000]  Loss D: 1.6718, Loss Adv_d: 1.0994 ------ Loss G: 1.6044, Curve Loss: 0.1370, Chamfer Loss: 0.2237\n",
      "Epoch [296/1000]  Loss D: 1.7060, Loss Adv_d: 1.0994 ------ Loss G: 1.6399, Curve Loss: 0.1384, Chamfer Loss: 0.2582\n",
      "Epoch [297/1000]  Loss D: 1.6767, Loss Adv_d: 1.1002 ------ Loss G: 1.6220, Curve Loss: 0.1380, Chamfer Loss: 0.2318\n",
      "Epoch [298/1000]  Loss D: 1.6832, Loss Adv_d: 1.1019 ------ Loss G: 1.6284, Curve Loss: 0.1386, Chamfer Loss: 0.2367\n",
      "Epoch [299/1000]  Loss D: 1.6675, Loss Adv_d: 1.0978 ------ Loss G: 1.6212, Curve Loss: 0.1359, Chamfer Loss: 0.2272\n",
      "Epoch [300/1000]  Loss D: 1.6711, Loss Adv_d: 1.1023 ------ Loss G: 1.6184, Curve Loss: 0.1376, Chamfer Loss: 0.2258\n",
      "Epoch [301/1000]  Loss D: 1.6783, Loss Adv_d: 1.1078 ------ Loss G: 1.6128, Curve Loss: 0.1351, Chamfer Loss: 0.2260\n",
      "Epoch [302/1000]  Loss D: 1.6667, Loss Adv_d: 1.1002 ------ Loss G: 1.6066, Curve Loss: 0.1368, Chamfer Loss: 0.2214\n",
      "Epoch [303/1000]  Loss D: 1.6828, Loss Adv_d: 1.1059 ------ Loss G: 1.6141, Curve Loss: 0.1399, Chamfer Loss: 0.2302\n",
      "Epoch [304/1000]  Loss D: 1.6858, Loss Adv_d: 1.1061 ------ Loss G: 1.6181, Curve Loss: 0.1382, Chamfer Loss: 0.2331\n",
      "Epoch [305/1000]  Loss D: 1.6759, Loss Adv_d: 1.1005 ------ Loss G: 1.6232, Curve Loss: 0.1376, Chamfer Loss: 0.2311\n",
      "Epoch [306/1000]  Loss D: 1.6859, Loss Adv_d: 1.1048 ------ Loss G: 1.6285, Curve Loss: 0.1360, Chamfer Loss: 0.2373\n",
      "Epoch [307/1000]  Loss D: 1.6736, Loss Adv_d: 1.1043 ------ Loss G: 1.6190, Curve Loss: 0.1374, Chamfer Loss: 0.2274\n",
      "Epoch [308/1000]  Loss D: 1.6674, Loss Adv_d: 1.0997 ------ Loss G: 1.6114, Curve Loss: 0.1381, Chamfer Loss: 0.2241\n",
      "Epoch [309/1000]  Loss D: 1.6739, Loss Adv_d: 1.1030 ------ Loss G: 1.6028, Curve Loss: 0.1378, Chamfer Loss: 0.2226\n",
      "Epoch [310/1000]  Loss D: 1.6970, Loss Adv_d: 1.1099 ------ Loss G: 1.6124, Curve Loss: 0.1363, Chamfer Loss: 0.2363\n",
      "Epoch [311/1000]  Loss D: 1.6782, Loss Adv_d: 1.1081 ------ Loss G: 1.6022, Curve Loss: 0.1377, Chamfer Loss: 0.2206\n",
      "Epoch [312/1000]  Loss D: 1.6883, Loss Adv_d: 1.1088 ------ Loss G: 1.6171, Curve Loss: 0.1375, Chamfer Loss: 0.2318\n",
      "Epoch [313/1000]  Loss D: 1.6746, Loss Adv_d: 1.1087 ------ Loss G: 1.6112, Curve Loss: 0.1373, Chamfer Loss: 0.2208\n",
      "Epoch [314/1000]  Loss D: 1.6757, Loss Adv_d: 1.1083 ------ Loss G: 1.6132, Curve Loss: 0.1373, Chamfer Loss: 0.2227\n",
      "Epoch [315/1000]  Loss D: 1.6692, Loss Adv_d: 1.1066 ------ Loss G: 1.6130, Curve Loss: 0.1382, Chamfer Loss: 0.2183\n",
      "Epoch [316/1000]  Loss D: 1.6770, Loss Adv_d: 1.1098 ------ Loss G: 1.6160, Curve Loss: 0.1373, Chamfer Loss: 0.2225\n",
      "Epoch [317/1000]  Loss D: 1.6868, Loss Adv_d: 1.1098 ------ Loss G: 1.6248, Curve Loss: 0.1355, Chamfer Loss: 0.2334\n",
      "Epoch [318/1000]  Loss D: 1.6779, Loss Adv_d: 1.1136 ------ Loss G: 1.6103, Curve Loss: 0.1365, Chamfer Loss: 0.2203\n",
      "Epoch [319/1000]  Loss D: 1.6832, Loss Adv_d: 1.1190 ------ Loss G: 1.6040, Curve Loss: 0.1372, Chamfer Loss: 0.2186\n",
      "Epoch [320/1000]  Loss D: 1.6793, Loss Adv_d: 1.1149 ------ Loss G: 1.5986, Curve Loss: 0.1350, Chamfer Loss: 0.2168\n",
      "Epoch [321/1000]  Loss D: 1.6786, Loss Adv_d: 1.1151 ------ Loss G: 1.5999, Curve Loss: 0.1363, Chamfer Loss: 0.2152\n",
      "Epoch [322/1000]  Loss D: 1.6927, Loss Adv_d: 1.1165 ------ Loss G: 1.6198, Curve Loss: 0.1385, Chamfer Loss: 0.2292\n",
      "Epoch [323/1000]  Loss D: 1.6864, Loss Adv_d: 1.1201 ------ Loss G: 1.6057, Curve Loss: 0.1367, Chamfer Loss: 0.2200\n",
      "Epoch [324/1000]  Loss D: 1.6845, Loss Adv_d: 1.1180 ------ Loss G: 1.6062, Curve Loss: 0.1368, Chamfer Loss: 0.2203\n",
      "Epoch [325/1000]  Loss D: 1.7177, Loss Adv_d: 1.1206 ------ Loss G: 1.6359, Curve Loss: 0.1376, Chamfer Loss: 0.2502\n",
      "Epoch [326/1000]  Loss D: 1.6777, Loss Adv_d: 1.1116 ------ Loss G: 1.6190, Curve Loss: 0.1367, Chamfer Loss: 0.2236\n",
      "Epoch [327/1000]  Loss D: 1.6866, Loss Adv_d: 1.1157 ------ Loss G: 1.6257, Curve Loss: 0.1382, Chamfer Loss: 0.2275\n",
      "Epoch [328/1000]  Loss D: 1.6922, Loss Adv_d: 1.1124 ------ Loss G: 1.6374, Curve Loss: 0.1381, Chamfer Loss: 0.2371\n",
      "Epoch [329/1000]  Loss D: 1.6723, Loss Adv_d: 1.1105 ------ Loss G: 1.6272, Curve Loss: 0.1361, Chamfer Loss: 0.2239\n",
      "Epoch [330/1000]  Loss D: 1.6713, Loss Adv_d: 1.1086 ------ Loss G: 1.6161, Curve Loss: 0.1359, Chamfer Loss: 0.2221\n",
      "Epoch [331/1000]  Loss D: 1.6994, Loss Adv_d: 1.1182 ------ Loss G: 1.6224, Curve Loss: 0.1372, Chamfer Loss: 0.2350\n",
      "Epoch [332/1000]  Loss D: 1.6898, Loss Adv_d: 1.1170 ------ Loss G: 1.6123, Curve Loss: 0.1351, Chamfer Loss: 0.2256\n",
      "Epoch [333/1000]  Loss D: 1.6955, Loss Adv_d: 1.1174 ------ Loss G: 1.6223, Curve Loss: 0.1337, Chamfer Loss: 0.2316\n",
      "Epoch [334/1000]  Loss D: 1.7219, Loss Adv_d: 1.1189 ------ Loss G: 1.6620, Curve Loss: 0.1382, Chamfer Loss: 0.2608\n",
      "Epoch [335/1000]  Loss D: 1.6778, Loss Adv_d: 1.1140 ------ Loss G: 1.6314, Curve Loss: 0.1365, Chamfer Loss: 0.2251\n",
      "Epoch [336/1000]  Loss D: 1.6840, Loss Adv_d: 1.1152 ------ Loss G: 1.6332, Curve Loss: 0.1381, Chamfer Loss: 0.2287\n",
      "Epoch [337/1000]  Loss D: 1.6837, Loss Adv_d: 1.1184 ------ Loss G: 1.6271, Curve Loss: 0.1349, Chamfer Loss: 0.2247\n",
      "Epoch [338/1000]  Loss D: 1.6947, Loss Adv_d: 1.1171 ------ Loss G: 1.6433, Curve Loss: 0.1377, Chamfer Loss: 0.2371\n",
      "Epoch [339/1000]  Loss D: 1.6895, Loss Adv_d: 1.1235 ------ Loss G: 1.6263, Curve Loss: 0.1352, Chamfer Loss: 0.2249\n",
      "Epoch [340/1000]  Loss D: 1.7322, Loss Adv_d: 1.1283 ------ Loss G: 1.6684, Curve Loss: 0.1406, Chamfer Loss: 0.2636\n",
      "Epoch [341/1000]  Loss D: 1.6935, Loss Adv_d: 1.1218 ------ Loss G: 1.6421, Curve Loss: 0.1346, Chamfer Loss: 0.2357\n",
      "Epoch [342/1000]  Loss D: 1.6863, Loss Adv_d: 1.1201 ------ Loss G: 1.6323, Curve Loss: 0.1366, Chamfer Loss: 0.2286\n",
      "Epoch [343/1000]  Loss D: 1.6879, Loss Adv_d: 1.1218 ------ Loss G: 1.6191, Curve Loss: 0.1360, Chamfer Loss: 0.2232\n",
      "Epoch [344/1000]  Loss D: 1.6852, Loss Adv_d: 1.1214 ------ Loss G: 1.6153, Curve Loss: 0.1351, Chamfer Loss: 0.2198\n",
      "Epoch [345/1000]  Loss D: 1.6953, Loss Adv_d: 1.1243 ------ Loss G: 1.6273, Curve Loss: 0.1366, Chamfer Loss: 0.2280\n",
      "Epoch [346/1000]  Loss D: 1.6851, Loss Adv_d: 1.1248 ------ Loss G: 1.6248, Curve Loss: 0.1351, Chamfer Loss: 0.2215\n",
      "Epoch [347/1000]  Loss D: 1.6822, Loss Adv_d: 1.1238 ------ Loss G: 1.6216, Curve Loss: 0.1350, Chamfer Loss: 0.2197\n",
      "Epoch [348/1000]  Loss D: 1.6868, Loss Adv_d: 1.1280 ------ Loss G: 1.6141, Curve Loss: 0.1341, Chamfer Loss: 0.2173\n",
      "Epoch [349/1000]  Loss D: 1.7143, Loss Adv_d: 1.1340 ------ Loss G: 1.6404, Curve Loss: 0.1369, Chamfer Loss: 0.2392\n",
      "Epoch [350/1000]  Loss D: 1.7449, Loss Adv_d: 1.1245 ------ Loss G: 1.6979, Curve Loss: 0.1383, Chamfer Loss: 0.2858\n",
      "Epoch [351/1000]  Loss D: 1.6779, Loss Adv_d: 1.1181 ------ Loss G: 1.6419, Curve Loss: 0.1367, Chamfer Loss: 0.2276\n",
      "Epoch [352/1000]  Loss D: 1.7135, Loss Adv_d: 1.1169 ------ Loss G: 1.6665, Curve Loss: 0.1372, Chamfer Loss: 0.2584\n",
      "Epoch [353/1000]  Loss D: 1.6873, Loss Adv_d: 1.1159 ------ Loss G: 1.6461, Curve Loss: 0.1377, Chamfer Loss: 0.2330\n",
      "Epoch [354/1000]  Loss D: 1.6956, Loss Adv_d: 1.1175 ------ Loss G: 1.6527, Curve Loss: 0.1360, Chamfer Loss: 0.2405\n",
      "Epoch [355/1000]  Loss D: 1.6747, Loss Adv_d: 1.1162 ------ Loss G: 1.6446, Curve Loss: 0.1371, Chamfer Loss: 0.2246\n",
      "Epoch [356/1000]  Loss D: 1.6884, Loss Adv_d: 1.1277 ------ Loss G: 1.6384, Curve Loss: 0.1373, Chamfer Loss: 0.2251\n",
      "Epoch [357/1000]  Loss D: 1.6818, Loss Adv_d: 1.1222 ------ Loss G: 1.6288, Curve Loss: 0.1354, Chamfer Loss: 0.2210\n",
      "Epoch [358/1000]  Loss D: 1.7467, Loss Adv_d: 1.1320 ------ Loss G: 1.6803, Curve Loss: 0.1371, Chamfer Loss: 0.2754\n",
      "Epoch [359/1000]  Loss D: 1.6849, Loss Adv_d: 1.1235 ------ Loss G: 1.6326, Curve Loss: 0.1351, Chamfer Loss: 0.2239\n",
      "Epoch [360/1000]  Loss D: 1.6952, Loss Adv_d: 1.1301 ------ Loss G: 1.6377, Curve Loss: 0.1361, Chamfer Loss: 0.2271\n",
      "Epoch [361/1000]  Loss D: 1.6943, Loss Adv_d: 1.1305 ------ Loss G: 1.6350, Curve Loss: 0.1361, Chamfer Loss: 0.2251\n",
      "Epoch [362/1000]  Loss D: 1.7297, Loss Adv_d: 1.1252 ------ Loss G: 1.6818, Curve Loss: 0.1375, Chamfer Loss: 0.2679\n",
      "Epoch [363/1000]  Loss D: 1.6755, Loss Adv_d: 1.1211 ------ Loss G: 1.6465, Curve Loss: 0.1355, Chamfer Loss: 0.2234\n",
      "Epoch [364/1000]  Loss D: 1.6758, Loss Adv_d: 1.1206 ------ Loss G: 1.6416, Curve Loss: 0.1362, Chamfer Loss: 0.2230\n",
      "Epoch [365/1000]  Loss D: 1.7050, Loss Adv_d: 1.1244 ------ Loss G: 1.6603, Curve Loss: 0.1388, Chamfer Loss: 0.2451\n",
      "Epoch [366/1000]  Loss D: 1.6851, Loss Adv_d: 1.1243 ------ Loss G: 1.6338, Curve Loss: 0.1356, Chamfer Loss: 0.2236\n",
      "Epoch [367/1000]  Loss D: 1.7234, Loss Adv_d: 1.1289 ------ Loss G: 1.6713, Curve Loss: 0.1388, Chamfer Loss: 0.2570\n",
      "Epoch [368/1000]  Loss D: 1.6864, Loss Adv_d: 1.1241 ------ Loss G: 1.6475, Curve Loss: 0.1347, Chamfer Loss: 0.2293\n",
      "Epoch [369/1000]  Loss D: 1.7042, Loss Adv_d: 1.1266 ------ Loss G: 1.6679, Curve Loss: 0.1369, Chamfer Loss: 0.2454\n",
      "Epoch [370/1000]  Loss D: 1.6848, Loss Adv_d: 1.1267 ------ Loss G: 1.6416, Curve Loss: 0.1383, Chamfer Loss: 0.2235\n",
      "Epoch [371/1000]  Loss D: 1.6867, Loss Adv_d: 1.1256 ------ Loss G: 1.6388, Curve Loss: 0.1356, Chamfer Loss: 0.2258\n",
      "Epoch [372/1000]  Loss D: 1.6828, Loss Adv_d: 1.1243 ------ Loss G: 1.6351, Curve Loss: 0.1319, Chamfer Loss: 0.2237\n",
      "Epoch [373/1000]  Loss D: 1.7269, Loss Adv_d: 1.1238 ------ Loss G: 1.6920, Curve Loss: 0.1395, Chamfer Loss: 0.2689\n",
      "Epoch [374/1000]  Loss D: 1.7121, Loss Adv_d: 1.1235 ------ Loss G: 1.6769, Curve Loss: 0.1377, Chamfer Loss: 0.2552\n",
      "Epoch [375/1000]  Loss D: 1.6854, Loss Adv_d: 1.1253 ------ Loss G: 1.6485, Curve Loss: 0.1350, Chamfer Loss: 0.2270\n",
      "Epoch [376/1000]  Loss D: 1.7254, Loss Adv_d: 1.1204 ------ Loss G: 1.6997, Curve Loss: 0.1396, Chamfer Loss: 0.2720\n",
      "Epoch [377/1000]  Loss D: 1.6765, Loss Adv_d: 1.1193 ------ Loss G: 1.6571, Curve Loss: 0.1353, Chamfer Loss: 0.2279\n",
      "Epoch [378/1000]  Loss D: 1.7014, Loss Adv_d: 1.1276 ------ Loss G: 1.6748, Curve Loss: 0.1390, Chamfer Loss: 0.2444\n",
      "Epoch [379/1000]  Loss D: 1.6893, Loss Adv_d: 1.1171 ------ Loss G: 1.6733, Curve Loss: 0.1375, Chamfer Loss: 0.2437\n",
      "Epoch [380/1000]  Loss D: 1.6866, Loss Adv_d: 1.1244 ------ Loss G: 1.6702, Curve Loss: 0.1372, Chamfer Loss: 0.2354\n",
      "Epoch [381/1000]  Loss D: 1.6741, Loss Adv_d: 1.1194 ------ Loss G: 1.6574, Curve Loss: 0.1351, Chamfer Loss: 0.2262\n",
      "Epoch [382/1000]  Loss D: 1.6872, Loss Adv_d: 1.1193 ------ Loss G: 1.6582, Curve Loss: 0.1383, Chamfer Loss: 0.2344\n",
      "Epoch [383/1000]  Loss D: 1.6777, Loss Adv_d: 1.1207 ------ Loss G: 1.6493, Curve Loss: 0.1370, Chamfer Loss: 0.2237\n",
      "Epoch [384/1000]  Loss D: 1.6856, Loss Adv_d: 1.1262 ------ Loss G: 1.6526, Curve Loss: 0.1358, Chamfer Loss: 0.2263\n",
      "Epoch [385/1000]  Loss D: 1.6781, Loss Adv_d: 1.1262 ------ Loss G: 1.6522, Curve Loss: 0.1354, Chamfer Loss: 0.2208\n",
      "Epoch [386/1000]  Loss D: 1.6830, Loss Adv_d: 1.1324 ------ Loss G: 1.6518, Curve Loss: 0.1366, Chamfer Loss: 0.2199\n",
      "Epoch [387/1000]  Loss D: 1.6842, Loss Adv_d: 1.1349 ------ Loss G: 1.6497, Curve Loss: 0.1382, Chamfer Loss: 0.2188\n",
      "Epoch [388/1000]  Loss D: 1.6824, Loss Adv_d: 1.1300 ------ Loss G: 1.6509, Curve Loss: 0.1361, Chamfer Loss: 0.2217\n",
      "Epoch [389/1000]  Loss D: 1.6769, Loss Adv_d: 1.1288 ------ Loss G: 1.6540, Curve Loss: 0.1386, Chamfer Loss: 0.2189\n",
      "Epoch [390/1000]  Loss D: 1.6819, Loss Adv_d: 1.1384 ------ Loss G: 1.6473, Curve Loss: 0.1364, Chamfer Loss: 0.2148\n",
      "Epoch [391/1000]  Loss D: 1.6715, Loss Adv_d: 1.1298 ------ Loss G: 1.6444, Curve Loss: 0.1356, Chamfer Loss: 0.2126\n",
      "Epoch [392/1000]  Loss D: 1.7223, Loss Adv_d: 1.1333 ------ Loss G: 1.6952, Curve Loss: 0.1373, Chamfer Loss: 0.2612\n",
      "Epoch [393/1000]  Loss D: 1.6904, Loss Adv_d: 1.1315 ------ Loss G: 1.6730, Curve Loss: 0.1353, Chamfer Loss: 0.2331\n",
      "Epoch [394/1000]  Loss D: 1.6692, Loss Adv_d: 1.1265 ------ Loss G: 1.6693, Curve Loss: 0.1350, Chamfer Loss: 0.2201\n",
      "Epoch [395/1000]  Loss D: 1.6891, Loss Adv_d: 1.1265 ------ Loss G: 1.6822, Curve Loss: 0.1349, Chamfer Loss: 0.2393\n",
      "Epoch [396/1000]  Loss D: 1.6807, Loss Adv_d: 1.1290 ------ Loss G: 1.6727, Curve Loss: 0.1360, Chamfer Loss: 0.2287\n",
      "Epoch [397/1000]  Loss D: 1.6794, Loss Adv_d: 1.1253 ------ Loss G: 1.6673, Curve Loss: 0.1376, Chamfer Loss: 0.2271\n",
      "Epoch [398/1000]  Loss D: 1.6802, Loss Adv_d: 1.1286 ------ Loss G: 1.6582, Curve Loss: 0.1355, Chamfer Loss: 0.2226\n",
      "Epoch [399/1000]  Loss D: 1.6765, Loss Adv_d: 1.1235 ------ Loss G: 1.6589, Curve Loss: 0.1359, Chamfer Loss: 0.2230\n",
      "Epoch [400/1000]  Loss D: 1.6685, Loss Adv_d: 1.1232 ------ Loss G: 1.6606, Curve Loss: 0.1364, Chamfer Loss: 0.2188\n",
      "Epoch [401/1000]  Loss D: 1.6904, Loss Adv_d: 1.1283 ------ Loss G: 1.6674, Curve Loss: 0.1363, Chamfer Loss: 0.2335\n",
      "Epoch [402/1000]  Loss D: 1.6923, Loss Adv_d: 1.1337 ------ Loss G: 1.6608, Curve Loss: 0.1371, Chamfer Loss: 0.2289\n",
      "Epoch [403/1000]  Loss D: 1.7002, Loss Adv_d: 1.1227 ------ Loss G: 1.6866, Curve Loss: 0.1369, Chamfer Loss: 0.2499\n",
      "Epoch [404/1000]  Loss D: 1.6769, Loss Adv_d: 1.1284 ------ Loss G: 1.6671, Curve Loss: 0.1353, Chamfer Loss: 0.2245\n",
      "Epoch [405/1000]  Loss D: 1.6683, Loss Adv_d: 1.1215 ------ Loss G: 1.6575, Curve Loss: 0.1358, Chamfer Loss: 0.2196\n",
      "Epoch [406/1000]  Loss D: 1.6744, Loss Adv_d: 1.1242 ------ Loss G: 1.6609, Curve Loss: 0.1366, Chamfer Loss: 0.2216\n",
      "Epoch [407/1000]  Loss D: 1.6866, Loss Adv_d: 1.1296 ------ Loss G: 1.6701, Curve Loss: 0.1363, Chamfer Loss: 0.2291\n",
      "Epoch [408/1000]  Loss D: 1.6867, Loss Adv_d: 1.1340 ------ Loss G: 1.6725, Curve Loss: 0.1354, Chamfer Loss: 0.2272\n",
      "Epoch [409/1000]  Loss D: 1.7026, Loss Adv_d: 1.1285 ------ Loss G: 1.6986, Curve Loss: 0.1376, Chamfer Loss: 0.2508\n",
      "Epoch [410/1000]  Loss D: 1.6692, Loss Adv_d: 1.1282 ------ Loss G: 1.6692, Curve Loss: 0.1376, Chamfer Loss: 0.2192\n",
      "Epoch [411/1000]  Loss D: 1.6691, Loss Adv_d: 1.1272 ------ Loss G: 1.6648, Curve Loss: 0.1372, Chamfer Loss: 0.2185\n",
      "Epoch [412/1000]  Loss D: 1.6789, Loss Adv_d: 1.1307 ------ Loss G: 1.6657, Curve Loss: 0.1363, Chamfer Loss: 0.2227\n",
      "Epoch [413/1000]  Loss D: 1.6744, Loss Adv_d: 1.1327 ------ Loss G: 1.6655, Curve Loss: 0.1365, Chamfer Loss: 0.2175\n",
      "Epoch [414/1000]  Loss D: 1.6933, Loss Adv_d: 1.1245 ------ Loss G: 1.6921, Curve Loss: 0.1370, Chamfer Loss: 0.2441\n",
      "Epoch [415/1000]  Loss D: 1.6956, Loss Adv_d: 1.1302 ------ Loss G: 1.7020, Curve Loss: 0.1400, Chamfer Loss: 0.2445\n",
      "Epoch [416/1000]  Loss D: 1.6869, Loss Adv_d: 1.1272 ------ Loss G: 1.6988, Curve Loss: 0.1368, Chamfer Loss: 0.2398\n",
      "Epoch [417/1000]  Loss D: 1.6727, Loss Adv_d: 1.1263 ------ Loss G: 1.6913, Curve Loss: 0.1367, Chamfer Loss: 0.2297\n",
      "Epoch [418/1000]  Loss D: 1.6634, Loss Adv_d: 1.1217 ------ Loss G: 1.6790, Curve Loss: 0.1370, Chamfer Loss: 0.2221\n",
      "Epoch [419/1000]  Loss D: 1.6672, Loss Adv_d: 1.1236 ------ Loss G: 1.6642, Curve Loss: 0.1349, Chamfer Loss: 0.2184\n",
      "Epoch [420/1000]  Loss D: 1.6784, Loss Adv_d: 1.1290 ------ Loss G: 1.6658, Curve Loss: 0.1362, Chamfer Loss: 0.2221\n",
      "Epoch [421/1000]  Loss D: 1.6721, Loss Adv_d: 1.1274 ------ Loss G: 1.6660, Curve Loss: 0.1356, Chamfer Loss: 0.2191\n",
      "Epoch [422/1000]  Loss D: 1.6632, Loss Adv_d: 1.1219 ------ Loss G: 1.6644, Curve Loss: 0.1336, Chamfer Loss: 0.2167\n",
      "Epoch [423/1000]  Loss D: 1.6720, Loss Adv_d: 1.1329 ------ Loss G: 1.6644, Curve Loss: 0.1343, Chamfer Loss: 0.2147\n",
      "Epoch [424/1000]  Loss D: 1.6727, Loss Adv_d: 1.1293 ------ Loss G: 1.6691, Curve Loss: 0.1341, Chamfer Loss: 0.2195\n",
      "Epoch [425/1000]  Loss D: 1.6765, Loss Adv_d: 1.1379 ------ Loss G: 1.6755, Curve Loss: 0.1374, Chamfer Loss: 0.2165\n",
      "Epoch [426/1000]  Loss D: 1.6698, Loss Adv_d: 1.1333 ------ Loss G: 1.6720, Curve Loss: 0.1360, Chamfer Loss: 0.2153\n",
      "Epoch [427/1000]  Loss D: 1.6871, Loss Adv_d: 1.1356 ------ Loss G: 1.6858, Curve Loss: 0.1365, Chamfer Loss: 0.2305\n",
      "Epoch [428/1000]  Loss D: 1.6947, Loss Adv_d: 1.1324 ------ Loss G: 1.7026, Curve Loss: 0.1370, Chamfer Loss: 0.2428\n",
      "Epoch [429/1000]  Loss D: 1.6626, Loss Adv_d: 1.1238 ------ Loss G: 1.6913, Curve Loss: 0.1373, Chamfer Loss: 0.2233\n",
      "Epoch [430/1000]  Loss D: 1.6838, Loss Adv_d: 1.1333 ------ Loss G: 1.6986, Curve Loss: 0.1355, Chamfer Loss: 0.2343\n",
      "Epoch [431/1000]  Loss D: 1.6742, Loss Adv_d: 1.1268 ------ Loss G: 1.6896, Curve Loss: 0.1367, Chamfer Loss: 0.2294\n",
      "Epoch [432/1000]  Loss D: 1.6674, Loss Adv_d: 1.1269 ------ Loss G: 1.6818, Curve Loss: 0.1379, Chamfer Loss: 0.2212\n",
      "Epoch [433/1000]  Loss D: 1.6599, Loss Adv_d: 1.1221 ------ Loss G: 1.6743, Curve Loss: 0.1361, Chamfer Loss: 0.2173\n",
      "Epoch [434/1000]  Loss D: 1.6708, Loss Adv_d: 1.1325 ------ Loss G: 1.6649, Curve Loss: 0.1357, Chamfer Loss: 0.2141\n",
      "Epoch [435/1000]  Loss D: 1.6692, Loss Adv_d: 1.1306 ------ Loss G: 1.6662, Curve Loss: 0.1366, Chamfer Loss: 0.2137\n",
      "Epoch [436/1000]  Loss D: 1.6698, Loss Adv_d: 1.1333 ------ Loss G: 1.6656, Curve Loss: 0.1350, Chamfer Loss: 0.2127\n",
      "Epoch [437/1000]  Loss D: 1.6754, Loss Adv_d: 1.1350 ------ Loss G: 1.6745, Curve Loss: 0.1369, Chamfer Loss: 0.2176\n",
      "Epoch [438/1000]  Loss D: 1.6896, Loss Adv_d: 1.1378 ------ Loss G: 1.6933, Curve Loss: 0.1366, Chamfer Loss: 0.2319\n",
      "Epoch [439/1000]  Loss D: 1.6694, Loss Adv_d: 1.1341 ------ Loss G: 1.6818, Curve Loss: 0.1337, Chamfer Loss: 0.2183\n",
      "Epoch [440/1000]  Loss D: 1.6749, Loss Adv_d: 1.1401 ------ Loss G: 1.6750, Curve Loss: 0.1363, Chamfer Loss: 0.2159\n",
      "Epoch [441/1000]  Loss D: 1.6690, Loss Adv_d: 1.1349 ------ Loss G: 1.6657, Curve Loss: 0.1349, Chamfer Loss: 0.2131\n",
      "Epoch [442/1000]  Loss D: 1.6941, Loss Adv_d: 1.1402 ------ Loss G: 1.6832, Curve Loss: 0.1371, Chamfer Loss: 0.2316\n",
      "Epoch [443/1000]  Loss D: 1.6732, Loss Adv_d: 1.1391 ------ Loss G: 1.6713, Curve Loss: 0.1367, Chamfer Loss: 0.2136\n",
      "Epoch [444/1000]  Loss D: 1.6686, Loss Adv_d: 1.1339 ------ Loss G: 1.6690, Curve Loss: 0.1348, Chamfer Loss: 0.2139\n",
      "Epoch [445/1000]  Loss D: 1.7013, Loss Adv_d: 1.1310 ------ Loss G: 1.7084, Curve Loss: 0.1370, Chamfer Loss: 0.2495\n",
      "Epoch [446/1000]  Loss D: 1.6625, Loss Adv_d: 1.1342 ------ Loss G: 1.6784, Curve Loss: 0.1365, Chamfer Loss: 0.2115\n",
      "Epoch [447/1000]  Loss D: 1.6780, Loss Adv_d: 1.1373 ------ Loss G: 1.6860, Curve Loss: 0.1356, Chamfer Loss: 0.2238\n",
      "Epoch [448/1000]  Loss D: 1.6641, Loss Adv_d: 1.1337 ------ Loss G: 1.6752, Curve Loss: 0.1364, Chamfer Loss: 0.2130\n",
      "Epoch [449/1000]  Loss D: 1.6840, Loss Adv_d: 1.1293 ------ Loss G: 1.6949, Curve Loss: 0.1392, Chamfer Loss: 0.2339\n",
      "Epoch [450/1000]  Loss D: 1.6672, Loss Adv_d: 1.1322 ------ Loss G: 1.6741, Curve Loss: 0.1354, Chamfer Loss: 0.2142\n",
      "Epoch [451/1000]  Loss D: 1.6758, Loss Adv_d: 1.1354 ------ Loss G: 1.6782, Curve Loss: 0.1366, Chamfer Loss: 0.2191\n",
      "Epoch [452/1000]  Loss D: 1.6677, Loss Adv_d: 1.1371 ------ Loss G: 1.6751, Curve Loss: 0.1361, Chamfer Loss: 0.2123\n",
      "Epoch [453/1000]  Loss D: 1.6966, Loss Adv_d: 1.1301 ------ Loss G: 1.7051, Curve Loss: 0.1368, Chamfer Loss: 0.2465\n",
      "Epoch [454/1000]  Loss D: 1.6543, Loss Adv_d: 1.1257 ------ Loss G: 1.6753, Curve Loss: 0.1355, Chamfer Loss: 0.2114\n",
      "Epoch [455/1000]  Loss D: 1.6642, Loss Adv_d: 1.1341 ------ Loss G: 1.6791, Curve Loss: 0.1363, Chamfer Loss: 0.2136\n",
      "Epoch [456/1000]  Loss D: 1.6586, Loss Adv_d: 1.1305 ------ Loss G: 1.6763, Curve Loss: 0.1363, Chamfer Loss: 0.2108\n",
      "Epoch [457/1000]  Loss D: 1.6717, Loss Adv_d: 1.1286 ------ Loss G: 1.6931, Curve Loss: 0.1397, Chamfer Loss: 0.2246\n",
      "Epoch [458/1000]  Loss D: 1.6527, Loss Adv_d: 1.1284 ------ Loss G: 1.6802, Curve Loss: 0.1353, Chamfer Loss: 0.2086\n",
      "Epoch [459/1000]  Loss D: 1.6566, Loss Adv_d: 1.1278 ------ Loss G: 1.6881, Curve Loss: 0.1369, Chamfer Loss: 0.2136\n",
      "Epoch [460/1000]  Loss D: 1.6599, Loss Adv_d: 1.1365 ------ Loss G: 1.6797, Curve Loss: 0.1350, Chamfer Loss: 0.2095\n",
      "Epoch [461/1000]  Loss D: 1.6577, Loss Adv_d: 1.1339 ------ Loss G: 1.6740, Curve Loss: 0.1336, Chamfer Loss: 0.2085\n",
      "Epoch [462/1000]  Loss D: 1.6580, Loss Adv_d: 1.1320 ------ Loss G: 1.6681, Curve Loss: 0.1331, Chamfer Loss: 0.2073\n",
      "Epoch [463/1000]  Loss D: 1.6583, Loss Adv_d: 1.1322 ------ Loss G: 1.6726, Curve Loss: 0.1356, Chamfer Loss: 0.2071\n",
      "Epoch [464/1000]  Loss D: 1.6613, Loss Adv_d: 1.1357 ------ Loss G: 1.6743, Curve Loss: 0.1350, Chamfer Loss: 0.2081\n",
      "Epoch [465/1000]  Loss D: 1.6740, Loss Adv_d: 1.1399 ------ Loss G: 1.6858, Curve Loss: 0.1359, Chamfer Loss: 0.2174\n",
      "Epoch [466/1000]  Loss D: 1.6581, Loss Adv_d: 1.1356 ------ Loss G: 1.6828, Curve Loss: 0.1341, Chamfer Loss: 0.2096\n",
      "Epoch [467/1000]  Loss D: 1.6531, Loss Adv_d: 1.1312 ------ Loss G: 1.6776, Curve Loss: 0.1352, Chamfer Loss: 0.2078\n",
      "Epoch [468/1000]  Loss D: 1.6809, Loss Adv_d: 1.1364 ------ Loss G: 1.6901, Curve Loss: 0.1364, Chamfer Loss: 0.2271\n",
      "Epoch [469/1000]  Loss D: 1.6575, Loss Adv_d: 1.1338 ------ Loss G: 1.6744, Curve Loss: 0.1349, Chamfer Loss: 0.2080\n",
      "Epoch [470/1000]  Loss D: 1.6821, Loss Adv_d: 1.1298 ------ Loss G: 1.7019, Curve Loss: 0.1355, Chamfer Loss: 0.2357\n",
      "Epoch [471/1000]  Loss D: 1.6472, Loss Adv_d: 1.1260 ------ Loss G: 1.6869, Curve Loss: 0.1358, Chamfer Loss: 0.2096\n",
      "Epoch [472/1000]  Loss D: 1.6542, Loss Adv_d: 1.1296 ------ Loss G: 1.6834, Curve Loss: 0.1344, Chamfer Loss: 0.2110\n",
      "Epoch [473/1000]  Loss D: 1.6710, Loss Adv_d: 1.1245 ------ Loss G: 1.6951, Curve Loss: 0.1360, Chamfer Loss: 0.2287\n",
      "Epoch [474/1000]  Loss D: 1.6963, Loss Adv_d: 1.1237 ------ Loss G: 1.7340, Curve Loss: 0.1379, Chamfer Loss: 0.2582\n",
      "Epoch [475/1000]  Loss D: 1.6437, Loss Adv_d: 1.1206 ------ Loss G: 1.6902, Curve Loss: 0.1352, Chamfer Loss: 0.2116\n",
      "Epoch [476/1000]  Loss D: 1.6667, Loss Adv_d: 1.1254 ------ Loss G: 1.7079, Curve Loss: 0.1369, Chamfer Loss: 0.2289\n",
      "Epoch [477/1000]  Loss D: 1.6538, Loss Adv_d: 1.1231 ------ Loss G: 1.6990, Curve Loss: 0.1399, Chamfer Loss: 0.2171\n",
      "Epoch [478/1000]  Loss D: 1.6542, Loss Adv_d: 1.1261 ------ Loss G: 1.6893, Curve Loss: 0.1356, Chamfer Loss: 0.2142\n",
      "Epoch [479/1000]  Loss D: 1.6671, Loss Adv_d: 1.1224 ------ Loss G: 1.7053, Curve Loss: 0.1373, Chamfer Loss: 0.2305\n",
      "Epoch [480/1000]  Loss D: 1.6573, Loss Adv_d: 1.1244 ------ Loss G: 1.6896, Curve Loss: 0.1386, Chamfer Loss: 0.2171\n",
      "Epoch [481/1000]  Loss D: 1.6530, Loss Adv_d: 1.1254 ------ Loss G: 1.6804, Curve Loss: 0.1355, Chamfer Loss: 0.2115\n",
      "Epoch [482/1000]  Loss D: 1.6609, Loss Adv_d: 1.1291 ------ Loss G: 1.6838, Curve Loss: 0.1375, Chamfer Loss: 0.2149\n",
      "Epoch [483/1000]  Loss D: 1.6479, Loss Adv_d: 1.1235 ------ Loss G: 1.6789, Curve Loss: 0.1360, Chamfer Loss: 0.2085\n",
      "Epoch [484/1000]  Loss D: 1.6523, Loss Adv_d: 1.1303 ------ Loss G: 1.6793, Curve Loss: 0.1351, Chamfer Loss: 0.2069\n",
      "Epoch [485/1000]  Loss D: 1.6550, Loss Adv_d: 1.1357 ------ Loss G: 1.6780, Curve Loss: 0.1352, Chamfer Loss: 0.2048\n",
      "Epoch [486/1000]  Loss D: 1.6493, Loss Adv_d: 1.1315 ------ Loss G: 1.6758, Curve Loss: 0.1345, Chamfer Loss: 0.2035\n",
      "Epoch [487/1000]  Loss D: 1.6546, Loss Adv_d: 1.1355 ------ Loss G: 1.6787, Curve Loss: 0.1351, Chamfer Loss: 0.2051\n",
      "Epoch [488/1000]  Loss D: 1.6475, Loss Adv_d: 1.1307 ------ Loss G: 1.6773, Curve Loss: 0.1344, Chamfer Loss: 0.2036\n",
      "Epoch [489/1000]  Loss D: 1.6562, Loss Adv_d: 1.1318 ------ Loss G: 1.6858, Curve Loss: 0.1355, Chamfer Loss: 0.2116\n",
      "Epoch [490/1000]  Loss D: 1.6455, Loss Adv_d: 1.1309 ------ Loss G: 1.6872, Curve Loss: 0.1358, Chamfer Loss: 0.2055\n",
      "Epoch [491/1000]  Loss D: 1.6455, Loss Adv_d: 1.1309 ------ Loss G: 1.6817, Curve Loss: 0.1355, Chamfer Loss: 0.2039\n",
      "Epoch [492/1000]  Loss D: 1.6553, Loss Adv_d: 1.1255 ------ Loss G: 1.6924, Curve Loss: 0.1354, Chamfer Loss: 0.2173\n",
      "Epoch [493/1000]  Loss D: 1.6420, Loss Adv_d: 1.1231 ------ Loss G: 1.6904, Curve Loss: 0.1363, Chamfer Loss: 0.2084\n",
      "Epoch [494/1000]  Loss D: 1.6464, Loss Adv_d: 1.1298 ------ Loss G: 1.6933, Curve Loss: 0.1352, Chamfer Loss: 0.2091\n",
      "Epoch [495/1000]  Loss D: 1.6359, Loss Adv_d: 1.1175 ------ Loss G: 1.6860, Curve Loss: 0.1371, Chamfer Loss: 0.2066\n",
      "Epoch [496/1000]  Loss D: 1.6420, Loss Adv_d: 1.1221 ------ Loss G: 1.6827, Curve Loss: 0.1364, Chamfer Loss: 0.2057\n",
      "Epoch [497/1000]  Loss D: 1.6421, Loss Adv_d: 1.1225 ------ Loss G: 1.6841, Curve Loss: 0.1349, Chamfer Loss: 0.2069\n",
      "Epoch [498/1000]  Loss D: 1.6397, Loss Adv_d: 1.1236 ------ Loss G: 1.6825, Curve Loss: 0.1357, Chamfer Loss: 0.2034\n",
      "Epoch [499/1000]  Loss D: 1.6459, Loss Adv_d: 1.1233 ------ Loss G: 1.6907, Curve Loss: 0.1363, Chamfer Loss: 0.2109\n",
      "Epoch [500/1000]  Loss D: 1.6700, Loss Adv_d: 1.1390 ------ Loss G: 1.7090, Curve Loss: 0.1376, Chamfer Loss: 0.2228\n",
      "Epoch [501/1000]  Loss D: 1.6372, Loss Adv_d: 1.1220 ------ Loss G: 1.6961, Curve Loss: 0.1359, Chamfer Loss: 0.2089\n",
      "Epoch [502/1000]  Loss D: 1.6475, Loss Adv_d: 1.1288 ------ Loss G: 1.6884, Curve Loss: 0.1343, Chamfer Loss: 0.2089\n",
      "Epoch [503/1000]  Loss D: 1.6419, Loss Adv_d: 1.1228 ------ Loss G: 1.6854, Curve Loss: 0.1358, Chamfer Loss: 0.2068\n",
      "Epoch [504/1000]  Loss D: 1.6563, Loss Adv_d: 1.1281 ------ Loss G: 1.6935, Curve Loss: 0.1353, Chamfer Loss: 0.2155\n",
      "Epoch [505/1000]  Loss D: 1.6352, Loss Adv_d: 1.1236 ------ Loss G: 1.6857, Curve Loss: 0.1352, Chamfer Loss: 0.2020\n",
      "Epoch [506/1000]  Loss D: 1.6455, Loss Adv_d: 1.1292 ------ Loss G: 1.6865, Curve Loss: 0.1361, Chamfer Loss: 0.2060\n",
      "Epoch [507/1000]  Loss D: 1.6371, Loss Adv_d: 1.1263 ------ Loss G: 1.6792, Curve Loss: 0.1359, Chamfer Loss: 0.2001\n",
      "Epoch [508/1000]  Loss D: 1.6373, Loss Adv_d: 1.1243 ------ Loss G: 1.6768, Curve Loss: 0.1345, Chamfer Loss: 0.2009\n",
      "Epoch [509/1000]  Loss D: 1.6501, Loss Adv_d: 1.1257 ------ Loss G: 1.6919, Curve Loss: 0.1362, Chamfer Loss: 0.2127\n",
      "Epoch [510/1000]  Loss D: 1.6299, Loss Adv_d: 1.1204 ------ Loss G: 1.6860, Curve Loss: 0.1370, Chamfer Loss: 0.2012\n",
      "Epoch [511/1000]  Loss D: 1.6432, Loss Adv_d: 1.1321 ------ Loss G: 1.6823, Curve Loss: 0.1362, Chamfer Loss: 0.2015\n",
      "Epoch [512/1000]  Loss D: 1.6361, Loss Adv_d: 1.1257 ------ Loss G: 1.6742, Curve Loss: 0.1341, Chamfer Loss: 0.1987\n",
      "Epoch [513/1000]  Loss D: 1.6435, Loss Adv_d: 1.1194 ------ Loss G: 1.6886, Curve Loss: 0.1357, Chamfer Loss: 0.2114\n",
      "Epoch [514/1000]  Loss D: 1.6427, Loss Adv_d: 1.1179 ------ Loss G: 1.7027, Curve Loss: 0.1369, Chamfer Loss: 0.2155\n",
      "Epoch [515/1000]  Loss D: 1.6373, Loss Adv_d: 1.1227 ------ Loss G: 1.6944, Curve Loss: 0.1355, Chamfer Loss: 0.2068\n",
      "Epoch [516/1000]  Loss D: 1.6301, Loss Adv_d: 1.1189 ------ Loss G: 1.6929, Curve Loss: 0.1348, Chamfer Loss: 0.2036\n",
      "Epoch [517/1000]  Loss D: 1.6389, Loss Adv_d: 1.1249 ------ Loss G: 1.6926, Curve Loss: 0.1350, Chamfer Loss: 0.2043\n",
      "Epoch [518/1000]  Loss D: 1.6398, Loss Adv_d: 1.1213 ------ Loss G: 1.6993, Curve Loss: 0.1354, Chamfer Loss: 0.2098\n",
      "Epoch [519/1000]  Loss D: 1.6360, Loss Adv_d: 1.1258 ------ Loss G: 1.6922, Curve Loss: 0.1365, Chamfer Loss: 0.2033\n",
      "Epoch [520/1000]  Loss D: 1.6301, Loss Adv_d: 1.1215 ------ Loss G: 1.6881, Curve Loss: 0.1359, Chamfer Loss: 0.2007\n",
      "Epoch [521/1000]  Loss D: 1.6313, Loss Adv_d: 1.1189 ------ Loss G: 1.6903, Curve Loss: 0.1366, Chamfer Loss: 0.2022\n",
      "Epoch [522/1000]  Loss D: 1.6242, Loss Adv_d: 1.1178 ------ Loss G: 1.6902, Curve Loss: 0.1351, Chamfer Loss: 0.1986\n",
      "Epoch [523/1000]  Loss D: 1.6340, Loss Adv_d: 1.1261 ------ Loss G: 1.6901, Curve Loss: 0.1351, Chamfer Loss: 0.2001\n",
      "Epoch [524/1000]  Loss D: 1.6435, Loss Adv_d: 1.1217 ------ Loss G: 1.7118, Curve Loss: 0.1373, Chamfer Loss: 0.2155\n",
      "Epoch [525/1000]  Loss D: 1.6305, Loss Adv_d: 1.1133 ------ Loss G: 1.7241, Curve Loss: 0.1360, Chamfer Loss: 0.2168\n",
      "Epoch [526/1000]  Loss D: 1.6269, Loss Adv_d: 1.1197 ------ Loss G: 1.7094, Curve Loss: 0.1359, Chamfer Loss: 0.2068\n",
      "Epoch [527/1000]  Loss D: 1.6241, Loss Adv_d: 1.1146 ------ Loss G: 1.6917, Curve Loss: 0.1363, Chamfer Loss: 0.2026\n",
      "Epoch [528/1000]  Loss D: 1.6510, Loss Adv_d: 1.1123 ------ Loss G: 1.7144, Curve Loss: 0.1375, Chamfer Loss: 0.2283\n",
      "Epoch [529/1000]  Loss D: 1.6370, Loss Adv_d: 1.1196 ------ Loss G: 1.6974, Curve Loss: 0.1365, Chamfer Loss: 0.2084\n",
      "Epoch [530/1000]  Loss D: 1.6468, Loss Adv_d: 1.1154 ------ Loss G: 1.7073, Curve Loss: 0.1349, Chamfer Loss: 0.2213\n",
      "Epoch [531/1000]  Loss D: 1.6460, Loss Adv_d: 1.1236 ------ Loss G: 1.7042, Curve Loss: 0.1355, Chamfer Loss: 0.2144\n",
      "Epoch [532/1000]  Loss D: 1.6217, Loss Adv_d: 1.1111 ------ Loss G: 1.7012, Curve Loss: 0.1360, Chamfer Loss: 0.2045\n",
      "Epoch [533/1000]  Loss D: 1.6337, Loss Adv_d: 1.1230 ------ Loss G: 1.7001, Curve Loss: 0.1357, Chamfer Loss: 0.2039\n",
      "Epoch [534/1000]  Loss D: 1.6413, Loss Adv_d: 1.1234 ------ Loss G: 1.7006, Curve Loss: 0.1376, Chamfer Loss: 0.2100\n",
      "Epoch [535/1000]  Loss D: 1.6215, Loss Adv_d: 1.1171 ------ Loss G: 1.6899, Curve Loss: 0.1358, Chamfer Loss: 0.1976\n",
      "Epoch [536/1000]  Loss D: 1.6267, Loss Adv_d: 1.1223 ------ Loss G: 1.6893, Curve Loss: 0.1380, Chamfer Loss: 0.1964\n",
      "Epoch [537/1000]  Loss D: 1.6370, Loss Adv_d: 1.1253 ------ Loss G: 1.6920, Curve Loss: 0.1368, Chamfer Loss: 0.2026\n",
      "Epoch [538/1000]  Loss D: 1.6405, Loss Adv_d: 1.1264 ------ Loss G: 1.6972, Curve Loss: 0.1359, Chamfer Loss: 0.2065\n",
      "Epoch [539/1000]  Loss D: 1.6487, Loss Adv_d: 1.1305 ------ Loss G: 1.7016, Curve Loss: 0.1358, Chamfer Loss: 0.2107\n",
      "Epoch [540/1000]  Loss D: 1.6358, Loss Adv_d: 1.1210 ------ Loss G: 1.7077, Curve Loss: 0.1373, Chamfer Loss: 0.2092\n",
      "Epoch [541/1000]  Loss D: 1.6293, Loss Adv_d: 1.1259 ------ Loss G: 1.6926, Curve Loss: 0.1361, Chamfer Loss: 0.1973\n",
      "Epoch [542/1000]  Loss D: 1.6357, Loss Adv_d: 1.1159 ------ Loss G: 1.7008, Curve Loss: 0.1307, Chamfer Loss: 0.2124\n",
      "Epoch [543/1000]  Loss D: 1.6424, Loss Adv_d: 1.1210 ------ Loss G: 1.7107, Curve Loss: 0.1360, Chamfer Loss: 0.2141\n",
      "Epoch [544/1000]  Loss D: 1.6311, Loss Adv_d: 1.1244 ------ Loss G: 1.7016, Curve Loss: 0.1353, Chamfer Loss: 0.2022\n",
      "Epoch [545/1000]  Loss D: 1.6271, Loss Adv_d: 1.1245 ------ Loss G: 1.6983, Curve Loss: 0.1374, Chamfer Loss: 0.1988\n",
      "Epoch [546/1000]  Loss D: 1.6410, Loss Adv_d: 1.1284 ------ Loss G: 1.6952, Curve Loss: 0.1377, Chamfer Loss: 0.2050\n",
      "Epoch [547/1000]  Loss D: 1.6365, Loss Adv_d: 1.1228 ------ Loss G: 1.6901, Curve Loss: 0.1340, Chamfer Loss: 0.2050\n",
      "Epoch [548/1000]  Loss D: 1.6532, Loss Adv_d: 1.1179 ------ Loss G: 1.7118, Curve Loss: 0.1362, Chamfer Loss: 0.2254\n",
      "Epoch [549/1000]  Loss D: 1.6312, Loss Adv_d: 1.1245 ------ Loss G: 1.6911, Curve Loss: 0.1354, Chamfer Loss: 0.1992\n",
      "Epoch [550/1000]  Loss D: 1.6246, Loss Adv_d: 1.1194 ------ Loss G: 1.6974, Curve Loss: 0.1383, Chamfer Loss: 0.1984\n",
      "Epoch [551/1000]  Loss D: 1.6283, Loss Adv_d: 1.1216 ------ Loss G: 1.6932, Curve Loss: 0.1358, Chamfer Loss: 0.1983\n",
      "Epoch [552/1000]  Loss D: 1.6371, Loss Adv_d: 1.1318 ------ Loss G: 1.6909, Curve Loss: 0.1357, Chamfer Loss: 0.1969\n",
      "Epoch [553/1000]  Loss D: 1.6290, Loss Adv_d: 1.1251 ------ Loss G: 1.6910, Curve Loss: 0.1371, Chamfer Loss: 0.1961\n",
      "Epoch [554/1000]  Loss D: 1.6318, Loss Adv_d: 1.1295 ------ Loss G: 1.6898, Curve Loss: 0.1361, Chamfer Loss: 0.1947\n",
      "Epoch [555/1000]  Loss D: 1.6414, Loss Adv_d: 1.1362 ------ Loss G: 1.6942, Curve Loss: 0.1368, Chamfer Loss: 0.1982\n",
      "Epoch [556/1000]  Loss D: 1.6409, Loss Adv_d: 1.1349 ------ Loss G: 1.6980, Curve Loss: 0.1371, Chamfer Loss: 0.2010\n",
      "Epoch [557/1000]  Loss D: 1.6439, Loss Adv_d: 1.1305 ------ Loss G: 1.7057, Curve Loss: 0.1376, Chamfer Loss: 0.2089\n",
      "Epoch [558/1000]  Loss D: 1.6248, Loss Adv_d: 1.1212 ------ Loss G: 1.6952, Curve Loss: 0.1352, Chamfer Loss: 0.2002\n",
      "Epoch [559/1000]  Loss D: 1.6391, Loss Adv_d: 1.1327 ------ Loss G: 1.6868, Curve Loss: 0.1372, Chamfer Loss: 0.1984\n",
      "Epoch [560/1000]  Loss D: 1.6327, Loss Adv_d: 1.1260 ------ Loss G: 1.6798, Curve Loss: 0.1352, Chamfer Loss: 0.1952\n",
      "Epoch [561/1000]  Loss D: 1.6356, Loss Adv_d: 1.1231 ------ Loss G: 1.6943, Curve Loss: 0.1373, Chamfer Loss: 0.2019\n",
      "Epoch [562/1000]  Loss D: 1.6335, Loss Adv_d: 1.1315 ------ Loss G: 1.6936, Curve Loss: 0.1356, Chamfer Loss: 0.1958\n",
      "Epoch [563/1000]  Loss D: 1.6295, Loss Adv_d: 1.1218 ------ Loss G: 1.7015, Curve Loss: 0.1387, Chamfer Loss: 0.2017\n",
      "Epoch [564/1000]  Loss D: 1.6236, Loss Adv_d: 1.1232 ------ Loss G: 1.7009, Curve Loss: 0.1391, Chamfer Loss: 0.1966\n",
      "Epoch [565/1000]  Loss D: 1.6201, Loss Adv_d: 1.1213 ------ Loss G: 1.6947, Curve Loss: 0.1365, Chamfer Loss: 0.1944\n",
      "Epoch [566/1000]  Loss D: 1.6201, Loss Adv_d: 1.1174 ------ Loss G: 1.6954, Curve Loss: 0.1351, Chamfer Loss: 0.1964\n",
      "Epoch [567/1000]  Loss D: 1.6285, Loss Adv_d: 1.1247 ------ Loss G: 1.7040, Curve Loss: 0.1388, Chamfer Loss: 0.1989\n",
      "Epoch [568/1000]  Loss D: 1.6386, Loss Adv_d: 1.1272 ------ Loss G: 1.7085, Curve Loss: 0.1371, Chamfer Loss: 0.2061\n",
      "Epoch [569/1000]  Loss D: 1.6255, Loss Adv_d: 1.1255 ------ Loss G: 1.7046, Curve Loss: 0.1362, Chamfer Loss: 0.1972\n",
      "Epoch [570/1000]  Loss D: 1.6229, Loss Adv_d: 1.1242 ------ Loss G: 1.7064, Curve Loss: 0.1360, Chamfer Loss: 0.1977\n",
      "Epoch [571/1000]  Loss D: 1.6260, Loss Adv_d: 1.1267 ------ Loss G: 1.6957, Curve Loss: 0.1350, Chamfer Loss: 0.1954\n",
      "Epoch [572/1000]  Loss D: 1.6286, Loss Adv_d: 1.1247 ------ Loss G: 1.6973, Curve Loss: 0.1363, Chamfer Loss: 0.1989\n",
      "Epoch [573/1000]  Loss D: 1.6386, Loss Adv_d: 1.1293 ------ Loss G: 1.7011, Curve Loss: 0.1381, Chamfer Loss: 0.2043\n",
      "Epoch [574/1000]  Loss D: 1.6259, Loss Adv_d: 1.1235 ------ Loss G: 1.6933, Curve Loss: 0.1371, Chamfer Loss: 0.1963\n",
      "Epoch [575/1000]  Loss D: 1.6145, Loss Adv_d: 1.1130 ------ Loss G: 1.6858, Curve Loss: 0.1360, Chamfer Loss: 0.1930\n",
      "Epoch [576/1000]  Loss D: 1.6213, Loss Adv_d: 1.1228 ------ Loss G: 1.6858, Curve Loss: 0.1369, Chamfer Loss: 0.1895\n",
      "Epoch [577/1000]  Loss D: 1.6367, Loss Adv_d: 1.1180 ------ Loss G: 1.7135, Curve Loss: 0.1388, Chamfer Loss: 0.2110\n",
      "Epoch [578/1000]  Loss D: 1.6437, Loss Adv_d: 1.1339 ------ Loss G: 1.7192, Curve Loss: 0.1375, Chamfer Loss: 0.2080\n",
      "Epoch [579/1000]  Loss D: 1.6264, Loss Adv_d: 1.1248 ------ Loss G: 1.7119, Curve Loss: 0.1379, Chamfer Loss: 0.2012\n",
      "Epoch [580/1000]  Loss D: 1.6250, Loss Adv_d: 1.1230 ------ Loss G: 1.6965, Curve Loss: 0.1353, Chamfer Loss: 0.1981\n",
      "Epoch [581/1000]  Loss D: 1.6246, Loss Adv_d: 1.1168 ------ Loss G: 1.6937, Curve Loss: 0.1371, Chamfer Loss: 0.2003\n",
      "Epoch [582/1000]  Loss D: 1.6299, Loss Adv_d: 1.1249 ------ Loss G: 1.6862, Curve Loss: 0.1334, Chamfer Loss: 0.1968\n",
      "Epoch [583/1000]  Loss D: 1.6233, Loss Adv_d: 1.1168 ------ Loss G: 1.6934, Curve Loss: 0.1375, Chamfer Loss: 0.1974\n",
      "Epoch [584/1000]  Loss D: 1.6274, Loss Adv_d: 1.1286 ------ Loss G: 1.6889, Curve Loss: 0.1361, Chamfer Loss: 0.1911\n",
      "Epoch [585/1000]  Loss D: 1.6393, Loss Adv_d: 1.1332 ------ Loss G: 1.7000, Curve Loss: 0.1363, Chamfer Loss: 0.1992\n",
      "Epoch [586/1000]  Loss D: 1.6246, Loss Adv_d: 1.1292 ------ Loss G: 1.7005, Curve Loss: 0.1350, Chamfer Loss: 0.1932\n",
      "Epoch [587/1000]  Loss D: 1.6245, Loss Adv_d: 1.1261 ------ Loss G: 1.7022, Curve Loss: 0.1379, Chamfer Loss: 0.1953\n",
      "Epoch [588/1000]  Loss D: 1.6239, Loss Adv_d: 1.1301 ------ Loss G: 1.6918, Curve Loss: 0.1372, Chamfer Loss: 0.1891\n",
      "Epoch [589/1000]  Loss D: 1.6345, Loss Adv_d: 1.1266 ------ Loss G: 1.7059, Curve Loss: 0.1365, Chamfer Loss: 0.2030\n",
      "Epoch [590/1000]  Loss D: 1.6218, Loss Adv_d: 1.1292 ------ Loss G: 1.6970, Curve Loss: 0.1356, Chamfer Loss: 0.1909\n",
      "Epoch [591/1000]  Loss D: 1.6319, Loss Adv_d: 1.1327 ------ Loss G: 1.6973, Curve Loss: 0.1370, Chamfer Loss: 0.1957\n",
      "Epoch [592/1000]  Loss D: 1.6249, Loss Adv_d: 1.1238 ------ Loss G: 1.6901, Curve Loss: 0.1337, Chamfer Loss: 0.1949\n",
      "Epoch [593/1000]  Loss D: 1.6394, Loss Adv_d: 1.1298 ------ Loss G: 1.7018, Curve Loss: 0.1354, Chamfer Loss: 0.2030\n",
      "Epoch [594/1000]  Loss D: 1.6179, Loss Adv_d: 1.1220 ------ Loss G: 1.6977, Curve Loss: 0.1367, Chamfer Loss: 0.1910\n",
      "Epoch [595/1000]  Loss D: 1.6214, Loss Adv_d: 1.1263 ------ Loss G: 1.6976, Curve Loss: 0.1338, Chamfer Loss: 0.1913\n",
      "Epoch [596/1000]  Loss D: 1.6349, Loss Adv_d: 1.1288 ------ Loss G: 1.7080, Curve Loss: 0.1352, Chamfer Loss: 0.2027\n",
      "Epoch [597/1000]  Loss D: 1.6188, Loss Adv_d: 1.1262 ------ Loss G: 1.7028, Curve Loss: 0.1363, Chamfer Loss: 0.1909\n",
      "Epoch [598/1000]  Loss D: 1.6165, Loss Adv_d: 1.1236 ------ Loss G: 1.7024, Curve Loss: 0.1370, Chamfer Loss: 0.1907\n",
      "Epoch [599/1000]  Loss D: 1.6121, Loss Adv_d: 1.1134 ------ Loss G: 1.7072, Curve Loss: 0.1355, Chamfer Loss: 0.1961\n",
      "Epoch [600/1000]  Loss D: 1.6193, Loss Adv_d: 1.1209 ------ Loss G: 1.7126, Curve Loss: 0.1365, Chamfer Loss: 0.1986\n",
      "Epoch [601/1000]  Loss D: 1.6284, Loss Adv_d: 1.1334 ------ Loss G: 1.7026, Curve Loss: 0.1343, Chamfer Loss: 0.1945\n",
      "Epoch [602/1000]  Loss D: 1.6360, Loss Adv_d: 1.1242 ------ Loss G: 1.7125, Curve Loss: 0.1337, Chamfer Loss: 0.2098\n",
      "Epoch [603/1000]  Loss D: 1.6187, Loss Adv_d: 1.1188 ------ Loss G: 1.7017, Curve Loss: 0.1358, Chamfer Loss: 0.1975\n",
      "Epoch [604/1000]  Loss D: 1.6283, Loss Adv_d: 1.1214 ------ Loss G: 1.7044, Curve Loss: 0.1357, Chamfer Loss: 0.2031\n",
      "Epoch [605/1000]  Loss D: 1.6179, Loss Adv_d: 1.1136 ------ Loss G: 1.6998, Curve Loss: 0.1361, Chamfer Loss: 0.1992\n",
      "Epoch [606/1000]  Loss D: 1.6233, Loss Adv_d: 1.1188 ------ Loss G: 1.7041, Curve Loss: 0.1359, Chamfer Loss: 0.2001\n",
      "Epoch [607/1000]  Loss D: 1.6221, Loss Adv_d: 1.1225 ------ Loss G: 1.6970, Curve Loss: 0.1334, Chamfer Loss: 0.1959\n",
      "Epoch [608/1000]  Loss D: 1.6193, Loss Adv_d: 1.1212 ------ Loss G: 1.6869, Curve Loss: 0.1343, Chamfer Loss: 0.1914\n",
      "Epoch [609/1000]  Loss D: 1.6397, Loss Adv_d: 1.1249 ------ Loss G: 1.7058, Curve Loss: 0.1377, Chamfer Loss: 0.2070\n",
      "Epoch [610/1000]  Loss D: 1.6200, Loss Adv_d: 1.1203 ------ Loss G: 1.7003, Curve Loss: 0.1365, Chamfer Loss: 0.1939\n",
      "Epoch [611/1000]  Loss D: 1.6324, Loss Adv_d: 1.1310 ------ Loss G: 1.7105, Curve Loss: 0.1373, Chamfer Loss: 0.1994\n",
      "Epoch [612/1000]  Loss D: 1.6214, Loss Adv_d: 1.1230 ------ Loss G: 1.7055, Curve Loss: 0.1338, Chamfer Loss: 0.1968\n",
      "Epoch [613/1000]  Loss D: 1.6318, Loss Adv_d: 1.1360 ------ Loss G: 1.6936, Curve Loss: 0.1328, Chamfer Loss: 0.1923\n",
      "Epoch [614/1000]  Loss D: 1.6183, Loss Adv_d: 1.1224 ------ Loss G: 1.6890, Curve Loss: 0.1355, Chamfer Loss: 0.1898\n",
      "Epoch [615/1000]  Loss D: 1.6293, Loss Adv_d: 1.1265 ------ Loss G: 1.6995, Curve Loss: 0.1369, Chamfer Loss: 0.1972\n",
      "Epoch [616/1000]  Loss D: 1.6208, Loss Adv_d: 1.1258 ------ Loss G: 1.6952, Curve Loss: 0.1351, Chamfer Loss: 0.1904\n",
      "Epoch [617/1000]  Loss D: 1.6372, Loss Adv_d: 1.1305 ------ Loss G: 1.7117, Curve Loss: 0.1386, Chamfer Loss: 0.2023\n",
      "Epoch [618/1000]  Loss D: 1.6168, Loss Adv_d: 1.1226 ------ Loss G: 1.7053, Curve Loss: 0.1348, Chamfer Loss: 0.1925\n",
      "Epoch [619/1000]  Loss D: 1.6285, Loss Adv_d: 1.1333 ------ Loss G: 1.7045, Curve Loss: 0.1342, Chamfer Loss: 0.1938\n",
      "Epoch [620/1000]  Loss D: 1.6145, Loss Adv_d: 1.1233 ------ Loss G: 1.6996, Curve Loss: 0.1341, Chamfer Loss: 0.1900\n",
      "Epoch [621/1000]  Loss D: 1.6217, Loss Adv_d: 1.1287 ------ Loss G: 1.6977, Curve Loss: 0.1330, Chamfer Loss: 0.1904\n",
      "Epoch [622/1000]  Loss D: 1.6294, Loss Adv_d: 1.1255 ------ Loss G: 1.7073, Curve Loss: 0.1362, Chamfer Loss: 0.1993\n",
      "Epoch [623/1000]  Loss D: 1.6287, Loss Adv_d: 1.1366 ------ Loss G: 1.6987, Curve Loss: 0.1340, Chamfer Loss: 0.1904\n",
      "Epoch [624/1000]  Loss D: 1.7073, Loss Adv_d: 1.1323 ------ Loss G: 1.7789, Curve Loss: 0.1381, Chamfer Loss: 0.2720\n",
      "Epoch [625/1000]  Loss D: 1.6304, Loss Adv_d: 1.1295 ------ Loss G: 1.7076, Curve Loss: 0.1356, Chamfer Loss: 0.1977\n",
      "Epoch [626/1000]  Loss D: 1.6348, Loss Adv_d: 1.1362 ------ Loss G: 1.7013, Curve Loss: 0.1324, Chamfer Loss: 0.1953\n",
      "Epoch [627/1000]  Loss D: 1.6270, Loss Adv_d: 1.1305 ------ Loss G: 1.6987, Curve Loss: 0.1353, Chamfer Loss: 0.1918\n",
      "Epoch [628/1000]  Loss D: 1.6311, Loss Adv_d: 1.1306 ------ Loss G: 1.7013, Curve Loss: 0.1363, Chamfer Loss: 0.1952\n",
      "Epoch [629/1000]  Loss D: 1.6435, Loss Adv_d: 1.1315 ------ Loss G: 1.7183, Curve Loss: 0.1354, Chamfer Loss: 0.2084\n",
      "Epoch [630/1000]  Loss D: 1.6297, Loss Adv_d: 1.1367 ------ Loss G: 1.7031, Curve Loss: 0.1346, Chamfer Loss: 0.1918\n",
      "Epoch [631/1000]  Loss D: 1.6418, Loss Adv_d: 1.1387 ------ Loss G: 1.7109, Curve Loss: 0.1366, Chamfer Loss: 0.2006\n",
      "Epoch [632/1000]  Loss D: 1.6238, Loss Adv_d: 1.1292 ------ Loss G: 1.7034, Curve Loss: 0.1354, Chamfer Loss: 0.1926\n",
      "Epoch [633/1000]  Loss D: 1.6276, Loss Adv_d: 1.1326 ------ Loss G: 1.6985, Curve Loss: 0.1336, Chamfer Loss: 0.1923\n",
      "Epoch [634/1000]  Loss D: 1.6347, Loss Adv_d: 1.1335 ------ Loss G: 1.7067, Curve Loss: 0.1380, Chamfer Loss: 0.1969\n",
      "Epoch [635/1000]  Loss D: 1.6377, Loss Adv_d: 1.1334 ------ Loss G: 1.7033, Curve Loss: 0.1320, Chamfer Loss: 0.2000\n",
      "Epoch [636/1000]  Loss D: 1.6669, Loss Adv_d: 1.1270 ------ Loss G: 1.7532, Curve Loss: 0.1370, Chamfer Loss: 0.2371\n",
      "Epoch [637/1000]  Loss D: 1.6268, Loss Adv_d: 1.1334 ------ Loss G: 1.7101, Curve Loss: 0.1344, Chamfer Loss: 0.1939\n",
      "Epoch [638/1000]  Loss D: 1.6250, Loss Adv_d: 1.1318 ------ Loss G: 1.7000, Curve Loss: 0.1307, Chamfer Loss: 0.1921\n",
      "Epoch [639/1000]  Loss D: 1.6323, Loss Adv_d: 1.1370 ------ Loss G: 1.6978, Curve Loss: 0.1329, Chamfer Loss: 0.1918\n",
      "Epoch [640/1000]  Loss D: 1.6447, Loss Adv_d: 1.1362 ------ Loss G: 1.7168, Curve Loss: 0.1342, Chamfer Loss: 0.2059\n",
      "Epoch [641/1000]  Loss D: 1.6296, Loss Adv_d: 1.1387 ------ Loss G: 1.7059, Curve Loss: 0.1332, Chamfer Loss: 0.1906\n",
      "Epoch [642/1000]  Loss D: 1.6327, Loss Adv_d: 1.1360 ------ Loss G: 1.7079, Curve Loss: 0.1334, Chamfer Loss: 0.1960\n",
      "Epoch [643/1000]  Loss D: 1.6204, Loss Adv_d: 1.1305 ------ Loss G: 1.7004, Curve Loss: 0.1330, Chamfer Loss: 0.1900\n",
      "Epoch [644/1000]  Loss D: 1.6255, Loss Adv_d: 1.1360 ------ Loss G: 1.6951, Curve Loss: 0.1355, Chamfer Loss: 0.1874\n",
      "Epoch [645/1000]  Loss D: 1.6327, Loss Adv_d: 1.1357 ------ Loss G: 1.7002, Curve Loss: 0.1364, Chamfer Loss: 0.1929\n",
      "Epoch [646/1000]  Loss D: 1.6207, Loss Adv_d: 1.1310 ------ Loss G: 1.6975, Curve Loss: 0.1362, Chamfer Loss: 0.1870\n",
      "Epoch [647/1000]  Loss D: 1.6505, Loss Adv_d: 1.1422 ------ Loss G: 1.7077, Curve Loss: 0.1290, Chamfer Loss: 0.2058\n",
      "Epoch [648/1000]  Loss D: 1.6397, Loss Adv_d: 1.1408 ------ Loss G: 1.7123, Curve Loss: 0.1354, Chamfer Loss: 0.1986\n",
      "Epoch [649/1000]  Loss D: 1.6272, Loss Adv_d: 1.1344 ------ Loss G: 1.7062, Curve Loss: 0.1354, Chamfer Loss: 0.1931\n",
      "Epoch [650/1000]  Loss D: 1.6245, Loss Adv_d: 1.1361 ------ Loss G: 1.6984, Curve Loss: 0.1335, Chamfer Loss: 0.1872\n",
      "Epoch [651/1000]  Loss D: 1.6284, Loss Adv_d: 1.1405 ------ Loss G: 1.6953, Curve Loss: 0.1317, Chamfer Loss: 0.1860\n",
      "Epoch [652/1000]  Loss D: 1.6164, Loss Adv_d: 1.1296 ------ Loss G: 1.6946, Curve Loss: 0.1320, Chamfer Loss: 0.1842\n",
      "Epoch [653/1000]  Loss D: 1.6223, Loss Adv_d: 1.1340 ------ Loss G: 1.6965, Curve Loss: 0.1331, Chamfer Loss: 0.1866\n",
      "Epoch [654/1000]  Loss D: 1.6260, Loss Adv_d: 1.1378 ------ Loss G: 1.7025, Curve Loss: 0.1333, Chamfer Loss: 0.1884\n",
      "Epoch [655/1000]  Loss D: 1.7292, Loss Adv_d: 1.1318 ------ Loss G: 1.8154, Curve Loss: 0.1399, Chamfer Loss: 0.2966\n",
      "Epoch [656/1000]  Loss D: 1.6161, Loss Adv_d: 1.1315 ------ Loss G: 1.7035, Curve Loss: 0.1327, Chamfer Loss: 0.1866\n",
      "Epoch [657/1000]  Loss D: 1.6509, Loss Adv_d: 1.1333 ------ Loss G: 1.7286, Curve Loss: 0.1367, Chamfer Loss: 0.2153\n",
      "Epoch [658/1000]  Loss D: 1.6283, Loss Adv_d: 1.1339 ------ Loss G: 1.7145, Curve Loss: 0.1331, Chamfer Loss: 0.1958\n",
      "Epoch [659/1000]  Loss D: 1.6481, Loss Adv_d: 1.1356 ------ Loss G: 1.7347, Curve Loss: 0.1360, Chamfer Loss: 0.2141\n",
      "Epoch [660/1000]  Loss D: 1.6254, Loss Adv_d: 1.1306 ------ Loss G: 1.7142, Curve Loss: 0.1311, Chamfer Loss: 0.1981\n",
      "Epoch [661/1000]  Loss D: 1.6240, Loss Adv_d: 1.1304 ------ Loss G: 1.6993, Curve Loss: 0.1299, Chamfer Loss: 0.1930\n",
      "Epoch [662/1000]  Loss D: 1.6209, Loss Adv_d: 1.1288 ------ Loss G: 1.6928, Curve Loss: 0.1315, Chamfer Loss: 0.1889\n",
      "Epoch [663/1000]  Loss D: 1.6490, Loss Adv_d: 1.1274 ------ Loss G: 1.7285, Curve Loss: 0.1377, Chamfer Loss: 0.2172\n",
      "Epoch [664/1000]  Loss D: 1.6572, Loss Adv_d: 1.1314 ------ Loss G: 1.7440, Curve Loss: 0.1374, Chamfer Loss: 0.2263\n",
      "Epoch [665/1000]  Loss D: 1.6545, Loss Adv_d: 1.1283 ------ Loss G: 1.7502, Curve Loss: 0.1364, Chamfer Loss: 0.2292\n",
      "Epoch [666/1000]  Loss D: 1.6129, Loss Adv_d: 1.1208 ------ Loss G: 1.7233, Curve Loss: 0.1332, Chamfer Loss: 0.1975\n",
      "Epoch [667/1000]  Loss D: 1.6215, Loss Adv_d: 1.1293 ------ Loss G: 1.7104, Curve Loss: 0.1329, Chamfer Loss: 0.1943\n",
      "Epoch [668/1000]  Loss D: 1.6154, Loss Adv_d: 1.1242 ------ Loss G: 1.7041, Curve Loss: 0.1329, Chamfer Loss: 0.1911\n",
      "Epoch [669/1000]  Loss D: 1.6382, Loss Adv_d: 1.1435 ------ Loss G: 1.7013, Curve Loss: 0.1313, Chamfer Loss: 0.1935\n",
      "Epoch [670/1000]  Loss D: 1.6420, Loss Adv_d: 1.1370 ------ Loss G: 1.7204, Curve Loss: 0.1384, Chamfer Loss: 0.2037\n",
      "Epoch [671/1000]  Loss D: 1.6300, Loss Adv_d: 1.1310 ------ Loss G: 1.7109, Curve Loss: 0.1349, Chamfer Loss: 0.1970\n",
      "Epoch [672/1000]  Loss D: 1.6312, Loss Adv_d: 1.1440 ------ Loss G: 1.7058, Curve Loss: 0.1327, Chamfer Loss: 0.1877\n",
      "Epoch [673/1000]  Loss D: 1.6192, Loss Adv_d: 1.1336 ------ Loss G: 1.7078, Curve Loss: 0.1288, Chamfer Loss: 0.1883\n",
      "Epoch [674/1000]  Loss D: 1.6530, Loss Adv_d: 1.1411 ------ Loss G: 1.7373, Curve Loss: 0.1353, Chamfer Loss: 0.2143\n",
      "Epoch [675/1000]  Loss D: 1.6310, Loss Adv_d: 1.1329 ------ Loss G: 1.7351, Curve Loss: 0.1312, Chamfer Loss: 0.2064\n",
      "Epoch [676/1000]  Loss D: 1.6162, Loss Adv_d: 1.1290 ------ Loss G: 1.7163, Curve Loss: 0.1336, Chamfer Loss: 0.1928\n",
      "Epoch [677/1000]  Loss D: 1.6388, Loss Adv_d: 1.1370 ------ Loss G: 1.7172, Curve Loss: 0.1366, Chamfer Loss: 0.2030\n",
      "Epoch [678/1000]  Loss D: 1.6204, Loss Adv_d: 1.1293 ------ Loss G: 1.7067, Curve Loss: 0.1341, Chamfer Loss: 0.1918\n",
      "Epoch [679/1000]  Loss D: 1.6123, Loss Adv_d: 1.1240 ------ Loss G: 1.7079, Curve Loss: 0.1299, Chamfer Loss: 0.1886\n",
      "Epoch [680/1000]  Loss D: 1.6241, Loss Adv_d: 1.1317 ------ Loss G: 1.7185, Curve Loss: 0.1335, Chamfer Loss: 0.1950\n",
      "Epoch [681/1000]  Loss D: 1.6526, Loss Adv_d: 1.1395 ------ Loss G: 1.7403, Curve Loss: 0.1368, Chamfer Loss: 0.2159\n",
      "Epoch [682/1000]  Loss D: 1.6329, Loss Adv_d: 1.1400 ------ Loss G: 1.7194, Curve Loss: 0.1310, Chamfer Loss: 0.1978\n",
      "Epoch [683/1000]  Loss D: 1.6361, Loss Adv_d: 1.1419 ------ Loss G: 1.7165, Curve Loss: 0.1358, Chamfer Loss: 0.1979\n",
      "Epoch [684/1000]  Loss D: 1.6225, Loss Adv_d: 1.1211 ------ Loss G: 1.7157, Curve Loss: 0.1348, Chamfer Loss: 0.2011\n",
      "Epoch [685/1000]  Loss D: 1.6229, Loss Adv_d: 1.1324 ------ Loss G: 1.7072, Curve Loss: 0.1333, Chamfer Loss: 0.1899\n",
      "Epoch [686/1000]  Loss D: 1.6170, Loss Adv_d: 1.1300 ------ Loss G: 1.7141, Curve Loss: 0.1324, Chamfer Loss: 0.1884\n",
      "Epoch [687/1000]  Loss D: 1.6155, Loss Adv_d: 1.1339 ------ Loss G: 1.7117, Curve Loss: 0.1306, Chamfer Loss: 0.1857\n",
      "Epoch [688/1000]  Loss D: 1.6432, Loss Adv_d: 1.1419 ------ Loss G: 1.7296, Curve Loss: 0.1349, Chamfer Loss: 0.2054\n",
      "Epoch [689/1000]  Loss D: 1.6310, Loss Adv_d: 1.1444 ------ Loss G: 1.7122, Curve Loss: 0.1338, Chamfer Loss: 0.1903\n",
      "Epoch [690/1000]  Loss D: 1.6257, Loss Adv_d: 1.1275 ------ Loss G: 1.7244, Curve Loss: 0.1354, Chamfer Loss: 0.2017\n",
      "Epoch [691/1000]  Loss D: 1.6168, Loss Adv_d: 1.1299 ------ Loss G: 1.7189, Curve Loss: 0.1321, Chamfer Loss: 0.1932\n",
      "Epoch [692/1000]  Loss D: 1.6233, Loss Adv_d: 1.1304 ------ Loss G: 1.7188, Curve Loss: 0.1309, Chamfer Loss: 0.1964\n",
      "Epoch [693/1000]  Loss D: 1.6219, Loss Adv_d: 1.1305 ------ Loss G: 1.7202, Curve Loss: 0.1353, Chamfer Loss: 0.1949\n",
      "Epoch [694/1000]  Loss D: 1.6208, Loss Adv_d: 1.1255 ------ Loss G: 1.7205, Curve Loss: 0.1345, Chamfer Loss: 0.1979\n",
      "Epoch [695/1000]  Loss D: 1.6124, Loss Adv_d: 1.1282 ------ Loss G: 1.7087, Curve Loss: 0.1326, Chamfer Loss: 0.1878\n",
      "Epoch [696/1000]  Loss D: 1.6205, Loss Adv_d: 1.1336 ------ Loss G: 1.7024, Curve Loss: 0.1320, Chamfer Loss: 0.1880\n",
      "Epoch [697/1000]  Loss D: 1.6391, Loss Adv_d: 1.1364 ------ Loss G: 1.7247, Curve Loss: 0.1366, Chamfer Loss: 0.2032\n",
      "Epoch [698/1000]  Loss D: 1.6152, Loss Adv_d: 1.1256 ------ Loss G: 1.7221, Curve Loss: 0.1349, Chamfer Loss: 0.1932\n",
      "Epoch [699/1000]  Loss D: 1.6128, Loss Adv_d: 1.1271 ------ Loss G: 1.7225, Curve Loss: 0.1321, Chamfer Loss: 0.1909\n",
      "Epoch [700/1000]  Loss D: 1.6134, Loss Adv_d: 1.1299 ------ Loss G: 1.7193, Curve Loss: 0.1337, Chamfer Loss: 0.1880\n",
      "Epoch [701/1000]  Loss D: 1.6050, Loss Adv_d: 1.1230 ------ Loss G: 1.7163, Curve Loss: 0.1338, Chamfer Loss: 0.1866\n",
      "Epoch [702/1000]  Loss D: 1.6587, Loss Adv_d: 1.1328 ------ Loss G: 1.7653, Curve Loss: 0.1375, Chamfer Loss: 0.2311\n",
      "Epoch [703/1000]  Loss D: 1.6247, Loss Adv_d: 1.1438 ------ Loss G: 1.7171, Curve Loss: 0.1319, Chamfer Loss: 0.1876\n",
      "Epoch [704/1000]  Loss D: 1.6077, Loss Adv_d: 1.1260 ------ Loss G: 1.7197, Curve Loss: 0.1334, Chamfer Loss: 0.1870\n",
      "Epoch [705/1000]  Loss D: 1.6179, Loss Adv_d: 1.1373 ------ Loss G: 1.7151, Curve Loss: 0.1329, Chamfer Loss: 0.1861\n",
      "Epoch [706/1000]  Loss D: 1.6191, Loss Adv_d: 1.1329 ------ Loss G: 1.7225, Curve Loss: 0.1345, Chamfer Loss: 0.1912\n",
      "Epoch [707/1000]  Loss D: 1.6082, Loss Adv_d: 1.1249 ------ Loss G: 1.7257, Curve Loss: 0.1343, Chamfer Loss: 0.1909\n",
      "Epoch [708/1000]  Loss D: 1.6083, Loss Adv_d: 1.1269 ------ Loss G: 1.7197, Curve Loss: 0.1329, Chamfer Loss: 0.1888\n",
      "Epoch [709/1000]  Loss D: 1.6001, Loss Adv_d: 1.1184 ------ Loss G: 1.7084, Curve Loss: 0.1325, Chamfer Loss: 0.1861\n",
      "Epoch [710/1000]  Loss D: 1.6232, Loss Adv_d: 1.1384 ------ Loss G: 1.7065, Curve Loss: 0.1311, Chamfer Loss: 0.1865\n",
      "Epoch [711/1000]  Loss D: 1.6102, Loss Adv_d: 1.1252 ------ Loss G: 1.7136, Curve Loss: 0.1330, Chamfer Loss: 0.1880\n",
      "Epoch [712/1000]  Loss D: 1.6228, Loss Adv_d: 1.1192 ------ Loss G: 1.7453, Curve Loss: 0.1364, Chamfer Loss: 0.2084\n",
      "Epoch [713/1000]  Loss D: 1.6184, Loss Adv_d: 1.1194 ------ Loss G: 1.7391, Curve Loss: 0.1346, Chamfer Loss: 0.2063\n",
      "Epoch [714/1000]  Loss D: 1.6129, Loss Adv_d: 1.1282 ------ Loss G: 1.7170, Curve Loss: 0.1350, Chamfer Loss: 0.1905\n",
      "Epoch [715/1000]  Loss D: 1.6007, Loss Adv_d: 1.1140 ------ Loss G: 1.7190, Curve Loss: 0.1334, Chamfer Loss: 0.1910\n",
      "Epoch [716/1000]  Loss D: 1.6073, Loss Adv_d: 1.1240 ------ Loss G: 1.7153, Curve Loss: 0.1323, Chamfer Loss: 0.1865\n",
      "Epoch [717/1000]  Loss D: 1.6079, Loss Adv_d: 1.1191 ------ Loss G: 1.7237, Curve Loss: 0.1314, Chamfer Loss: 0.1930\n",
      "Epoch [718/1000]  Loss D: 1.6350, Loss Adv_d: 1.1298 ------ Loss G: 1.7518, Curve Loss: 0.1352, Chamfer Loss: 0.2136\n",
      "Epoch [719/1000]  Loss D: 1.6080, Loss Adv_d: 1.1282 ------ Loss G: 1.7069, Curve Loss: 0.1319, Chamfer Loss: 0.1857\n",
      "Epoch [720/1000]  Loss D: 1.6058, Loss Adv_d: 1.1211 ------ Loss G: 1.7092, Curve Loss: 0.1330, Chamfer Loss: 0.1886\n",
      "Epoch [721/1000]  Loss D: 1.6306, Loss Adv_d: 1.1318 ------ Loss G: 1.7246, Curve Loss: 0.1349, Chamfer Loss: 0.2014\n",
      "Epoch [722/1000]  Loss D: 1.5908, Loss Adv_d: 1.1147 ------ Loss G: 1.7128, Curve Loss: 0.1330, Chamfer Loss: 0.1822\n",
      "Epoch [723/1000]  Loss D: 1.5992, Loss Adv_d: 1.1203 ------ Loss G: 1.7105, Curve Loss: 0.1307, Chamfer Loss: 0.1852\n",
      "Epoch [724/1000]  Loss D: 1.6015, Loss Adv_d: 1.1109 ------ Loss G: 1.7258, Curve Loss: 0.1353, Chamfer Loss: 0.1950\n",
      "Epoch [725/1000]  Loss D: 1.6093, Loss Adv_d: 1.1277 ------ Loss G: 1.7219, Curve Loss: 0.1350, Chamfer Loss: 0.1877\n",
      "Epoch [726/1000]  Loss D: 1.6423, Loss Adv_d: 1.1310 ------ Loss G: 1.7545, Curve Loss: 0.1390, Chamfer Loss: 0.2170\n",
      "Epoch [727/1000]  Loss D: 1.6126, Loss Adv_d: 1.1220 ------ Loss G: 1.7357, Curve Loss: 0.1354, Chamfer Loss: 0.1974\n",
      "Epoch [728/1000]  Loss D: 1.6055, Loss Adv_d: 1.1179 ------ Loss G: 1.7400, Curve Loss: 0.1352, Chamfer Loss: 0.1964\n",
      "Epoch [729/1000]  Loss D: 1.5993, Loss Adv_d: 1.1198 ------ Loss G: 1.7325, Curve Loss: 0.1333, Chamfer Loss: 0.1907\n",
      "Epoch [730/1000]  Loss D: 1.6129, Loss Adv_d: 1.1324 ------ Loss G: 1.7218, Curve Loss: 0.1342, Chamfer Loss: 0.1885\n",
      "Epoch [731/1000]  Loss D: 1.6101, Loss Adv_d: 1.1306 ------ Loss G: 1.7121, Curve Loss: 0.1322, Chamfer Loss: 0.1852\n",
      "Epoch [732/1000]  Loss D: 1.6019, Loss Adv_d: 1.1203 ------ Loss G: 1.7152, Curve Loss: 0.1315, Chamfer Loss: 0.1859\n",
      "Epoch [733/1000]  Loss D: 1.6213, Loss Adv_d: 1.1325 ------ Loss G: 1.7240, Curve Loss: 0.1338, Chamfer Loss: 0.1939\n",
      "Epoch [734/1000]  Loss D: 1.5989, Loss Adv_d: 1.1186 ------ Loss G: 1.7172, Curve Loss: 0.1330, Chamfer Loss: 0.1861\n",
      "Epoch [735/1000]  Loss D: 1.6087, Loss Adv_d: 1.1268 ------ Loss G: 1.7196, Curve Loss: 0.1348, Chamfer Loss: 0.1872\n",
      "Epoch [736/1000]  Loss D: 1.6039, Loss Adv_d: 1.1262 ------ Loss G: 1.7150, Curve Loss: 0.1330, Chamfer Loss: 0.1840\n",
      "Epoch [737/1000]  Loss D: 1.6041, Loss Adv_d: 1.1263 ------ Loss G: 1.7123, Curve Loss: 0.1320, Chamfer Loss: 0.1833\n",
      "Epoch [738/1000]  Loss D: 1.5938, Loss Adv_d: 1.1184 ------ Loss G: 1.7115, Curve Loss: 0.1327, Chamfer Loss: 0.1815\n",
      "Epoch [739/1000]  Loss D: 1.6017, Loss Adv_d: 1.1250 ------ Loss G: 1.7181, Curve Loss: 0.1357, Chamfer Loss: 0.1819\n",
      "Epoch [740/1000]  Loss D: 1.6055, Loss Adv_d: 1.1210 ------ Loss G: 1.7340, Curve Loss: 0.1344, Chamfer Loss: 0.1932\n",
      "Epoch [741/1000]  Loss D: 1.5996, Loss Adv_d: 1.1200 ------ Loss G: 1.7275, Curve Loss: 0.1324, Chamfer Loss: 0.1899\n",
      "Epoch [742/1000]  Loss D: 1.6245, Loss Adv_d: 1.1053 ------ Loss G: 1.7644, Curve Loss: 0.1373, Chamfer Loss: 0.2277\n",
      "Epoch [743/1000]  Loss D: 1.6097, Loss Adv_d: 1.1060 ------ Loss G: 1.7434, Curve Loss: 0.1359, Chamfer Loss: 0.2113\n",
      "Epoch [744/1000]  Loss D: 1.6013, Loss Adv_d: 1.1080 ------ Loss G: 1.7334, Curve Loss: 0.1294, Chamfer Loss: 0.2013\n",
      "Epoch [745/1000]  Loss D: 1.6198, Loss Adv_d: 1.1162 ------ Loss G: 1.7487, Curve Loss: 0.1356, Chamfer Loss: 0.2094\n",
      "Epoch [746/1000]  Loss D: 1.6129, Loss Adv_d: 1.1110 ------ Loss G: 1.7475, Curve Loss: 0.1366, Chamfer Loss: 0.2073\n",
      "Epoch [747/1000]  Loss D: 1.5945, Loss Adv_d: 1.1104 ------ Loss G: 1.7304, Curve Loss: 0.1330, Chamfer Loss: 0.1919\n",
      "Epoch [748/1000]  Loss D: 1.5997, Loss Adv_d: 1.1121 ------ Loss G: 1.7334, Curve Loss: 0.1347, Chamfer Loss: 0.1946\n",
      "Epoch [749/1000]  Loss D: 1.6172, Loss Adv_d: 1.1320 ------ Loss G: 1.7301, Curve Loss: 0.1339, Chamfer Loss: 0.1927\n",
      "Epoch [750/1000]  Loss D: 1.6075, Loss Adv_d: 1.1198 ------ Loss G: 1.7323, Curve Loss: 0.1338, Chamfer Loss: 0.1956\n",
      "Epoch [751/1000]  Loss D: 1.5976, Loss Adv_d: 1.1175 ------ Loss G: 1.7239, Curve Loss: 0.1322, Chamfer Loss: 0.1880\n",
      "Epoch [752/1000]  Loss D: 1.5950, Loss Adv_d: 1.1138 ------ Loss G: 1.7270, Curve Loss: 0.1348, Chamfer Loss: 0.1884\n",
      "Epoch [753/1000]  Loss D: 1.6056, Loss Adv_d: 1.1271 ------ Loss G: 1.7226, Curve Loss: 0.1337, Chamfer Loss: 0.1852\n",
      "Epoch [754/1000]  Loss D: 1.6107, Loss Adv_d: 1.1321 ------ Loss G: 1.7194, Curve Loss: 0.1334, Chamfer Loss: 0.1863\n",
      "Epoch [755/1000]  Loss D: 1.6055, Loss Adv_d: 1.1218 ------ Loss G: 1.7230, Curve Loss: 0.1325, Chamfer Loss: 0.1909\n",
      "Epoch [756/1000]  Loss D: 1.6003, Loss Adv_d: 1.1095 ------ Loss G: 1.7325, Curve Loss: 0.1270, Chamfer Loss: 0.1980\n",
      "Epoch [757/1000]  Loss D: 1.6320, Loss Adv_d: 1.1162 ------ Loss G: 1.7779, Curve Loss: 0.1377, Chamfer Loss: 0.2268\n",
      "Epoch [758/1000]  Loss D: 1.6066, Loss Adv_d: 1.1245 ------ Loss G: 1.7224, Curve Loss: 0.1312, Chamfer Loss: 0.1904\n",
      "Epoch [759/1000]  Loss D: 1.5929, Loss Adv_d: 1.1103 ------ Loss G: 1.7216, Curve Loss: 0.1316, Chamfer Loss: 0.1890\n",
      "Epoch [760/1000]  Loss D: 1.5964, Loss Adv_d: 1.1158 ------ Loss G: 1.7198, Curve Loss: 0.1309, Chamfer Loss: 0.1864\n",
      "Epoch [761/1000]  Loss D: 1.6097, Loss Adv_d: 1.1219 ------ Loss G: 1.7278, Curve Loss: 0.1292, Chamfer Loss: 0.1953\n",
      "Epoch [762/1000]  Loss D: 1.5952, Loss Adv_d: 1.1201 ------ Loss G: 1.7261, Curve Loss: 0.1333, Chamfer Loss: 0.1844\n",
      "Epoch [763/1000]  Loss D: 1.6157, Loss Adv_d: 1.1191 ------ Loss G: 1.7428, Curve Loss: 0.1357, Chamfer Loss: 0.2046\n",
      "Epoch [764/1000]  Loss D: 1.5971, Loss Adv_d: 1.1111 ------ Loss G: 1.7341, Curve Loss: 0.1303, Chamfer Loss: 0.1956\n",
      "Epoch [765/1000]  Loss D: 1.6137, Loss Adv_d: 1.1152 ------ Loss G: 1.7488, Curve Loss: 0.1345, Chamfer Loss: 0.2077\n",
      "Epoch [766/1000]  Loss D: 1.6065, Loss Adv_d: 1.1130 ------ Loss G: 1.7383, Curve Loss: 0.1354, Chamfer Loss: 0.2003\n",
      "Epoch [767/1000]  Loss D: 1.5846, Loss Adv_d: 1.1055 ------ Loss G: 1.7248, Curve Loss: 0.1322, Chamfer Loss: 0.1873\n",
      "Epoch [768/1000]  Loss D: 1.6084, Loss Adv_d: 1.1143 ------ Loss G: 1.7379, Curve Loss: 0.1358, Chamfer Loss: 0.2016\n",
      "Epoch [769/1000]  Loss D: 1.5960, Loss Adv_d: 1.1134 ------ Loss G: 1.7226, Curve Loss: 0.1326, Chamfer Loss: 0.1888\n",
      "Epoch [770/1000]  Loss D: 1.5997, Loss Adv_d: 1.1140 ------ Loss G: 1.7264, Curve Loss: 0.1330, Chamfer Loss: 0.1920\n",
      "Epoch [771/1000]  Loss D: 1.5972, Loss Adv_d: 1.1103 ------ Loss G: 1.7338, Curve Loss: 0.1337, Chamfer Loss: 0.1940\n",
      "Epoch [772/1000]  Loss D: 1.5984, Loss Adv_d: 1.1150 ------ Loss G: 1.7359, Curve Loss: 0.1289, Chamfer Loss: 0.1944\n",
      "Epoch [773/1000]  Loss D: 1.6117, Loss Adv_d: 1.1190 ------ Loss G: 1.7473, Curve Loss: 0.1368, Chamfer Loss: 0.2033\n",
      "Epoch [774/1000]  Loss D: 1.5958, Loss Adv_d: 1.1173 ------ Loss G: 1.7248, Curve Loss: 0.1337, Chamfer Loss: 0.1860\n",
      "Epoch [775/1000]  Loss D: 1.6072, Loss Adv_d: 1.1210 ------ Loss G: 1.7321, Curve Loss: 0.1350, Chamfer Loss: 0.1945\n",
      "Epoch [776/1000]  Loss D: 1.6070, Loss Adv_d: 1.1232 ------ Loss G: 1.7189, Curve Loss: 0.1290, Chamfer Loss: 0.1913\n",
      "Epoch [777/1000]  Loss D: 1.5870, Loss Adv_d: 1.1095 ------ Loss G: 1.7246, Curve Loss: 0.1322, Chamfer Loss: 0.1853\n",
      "Epoch [778/1000]  Loss D: 1.5949, Loss Adv_d: 1.1175 ------ Loss G: 1.7215, Curve Loss: 0.1332, Chamfer Loss: 0.1844\n",
      "Epoch [779/1000]  Loss D: 1.6044, Loss Adv_d: 1.1246 ------ Loss G: 1.7203, Curve Loss: 0.1348, Chamfer Loss: 0.1854\n",
      "Epoch [780/1000]  Loss D: 1.5999, Loss Adv_d: 1.1226 ------ Loss G: 1.7221, Curve Loss: 0.1341, Chamfer Loss: 0.1837\n",
      "Epoch [781/1000]  Loss D: 1.5952, Loss Adv_d: 1.1180 ------ Loss G: 1.7272, Curve Loss: 0.1348, Chamfer Loss: 0.1852\n",
      "Epoch [782/1000]  Loss D: 1.5850, Loss Adv_d: 1.1137 ------ Loss G: 1.7220, Curve Loss: 0.1319, Chamfer Loss: 0.1815\n",
      "Epoch [783/1000]  Loss D: 1.6046, Loss Adv_d: 1.1122 ------ Loss G: 1.7469, Curve Loss: 0.1350, Chamfer Loss: 0.2011\n",
      "Epoch [784/1000]  Loss D: 1.6077, Loss Adv_d: 1.1190 ------ Loss G: 1.7428, Curve Loss: 0.1284, Chamfer Loss: 0.2012\n",
      "Epoch [785/1000]  Loss D: 1.5932, Loss Adv_d: 1.1110 ------ Loss G: 1.7298, Curve Loss: 0.1337, Chamfer Loss: 0.1917\n",
      "Epoch [786/1000]  Loss D: 1.6004, Loss Adv_d: 1.1087 ------ Loss G: 1.7386, Curve Loss: 0.1333, Chamfer Loss: 0.2007\n",
      "Epoch [787/1000]  Loss D: 1.6548, Loss Adv_d: 1.1140 ------ Loss G: 1.7933, Curve Loss: 0.1362, Chamfer Loss: 0.2510\n",
      "Epoch [788/1000]  Loss D: 1.5931, Loss Adv_d: 1.1094 ------ Loss G: 1.7278, Curve Loss: 0.1353, Chamfer Loss: 0.1922\n",
      "Epoch [789/1000]  Loss D: 1.6009, Loss Adv_d: 1.1139 ------ Loss G: 1.7276, Curve Loss: 0.1336, Chamfer Loss: 0.1936\n",
      "Epoch [790/1000]  Loss D: 1.5969, Loss Adv_d: 1.1116 ------ Loss G: 1.7191, Curve Loss: 0.1320, Chamfer Loss: 0.1899\n",
      "Epoch [791/1000]  Loss D: 1.6043, Loss Adv_d: 1.1204 ------ Loss G: 1.7215, Curve Loss: 0.1307, Chamfer Loss: 0.1894\n",
      "Epoch [792/1000]  Loss D: 1.6011, Loss Adv_d: 1.1223 ------ Loss G: 1.7282, Curve Loss: 0.1347, Chamfer Loss: 0.1866\n",
      "Epoch [793/1000]  Loss D: 1.6078, Loss Adv_d: 1.1193 ------ Loss G: 1.7408, Curve Loss: 0.1351, Chamfer Loss: 0.1962\n",
      "Epoch [794/1000]  Loss D: 1.5890, Loss Adv_d: 1.1059 ------ Loss G: 1.7463, Curve Loss: 0.1352, Chamfer Loss: 0.1942\n",
      "Epoch [795/1000]  Loss D: 1.5971, Loss Adv_d: 1.1212 ------ Loss G: 1.7421, Curve Loss: 0.1312, Chamfer Loss: 0.1902\n",
      "Epoch [796/1000]  Loss D: 1.5934, Loss Adv_d: 1.1192 ------ Loss G: 1.7288, Curve Loss: 0.1324, Chamfer Loss: 0.1864\n",
      "Epoch [797/1000]  Loss D: 1.5930, Loss Adv_d: 1.1113 ------ Loss G: 1.7337, Curve Loss: 0.1359, Chamfer Loss: 0.1921\n",
      "Epoch [798/1000]  Loss D: 1.6041, Loss Adv_d: 1.1235 ------ Loss G: 1.7238, Curve Loss: 0.1345, Chamfer Loss: 0.1882\n",
      "Epoch [799/1000]  Loss D: 1.5850, Loss Adv_d: 1.1069 ------ Loss G: 1.7252, Curve Loss: 0.1340, Chamfer Loss: 0.1853\n",
      "Epoch [800/1000]  Loss D: 1.5931, Loss Adv_d: 1.1154 ------ Loss G: 1.7256, Curve Loss: 0.1319, Chamfer Loss: 0.1858\n",
      "Epoch [801/1000]  Loss D: 1.5924, Loss Adv_d: 1.1105 ------ Loss G: 1.7378, Curve Loss: 0.1342, Chamfer Loss: 0.1916\n",
      "Epoch [802/1000]  Loss D: 1.5889, Loss Adv_d: 1.1117 ------ Loss G: 1.7344, Curve Loss: 0.1344, Chamfer Loss: 0.1904\n",
      "Epoch [803/1000]  Loss D: 1.5895, Loss Adv_d: 1.1130 ------ Loss G: 1.7232, Curve Loss: 0.1335, Chamfer Loss: 0.1859\n",
      "Epoch [804/1000]  Loss D: 1.5894, Loss Adv_d: 1.1116 ------ Loss G: 1.7183, Curve Loss: 0.1323, Chamfer Loss: 0.1840\n",
      "Epoch [805/1000]  Loss D: 1.5924, Loss Adv_d: 1.1181 ------ Loss G: 1.7228, Curve Loss: 0.1313, Chamfer Loss: 0.1825\n",
      "Epoch [806/1000]  Loss D: 1.6018, Loss Adv_d: 1.1041 ------ Loss G: 1.7508, Curve Loss: 0.1357, Chamfer Loss: 0.2074\n",
      "Epoch [807/1000]  Loss D: 1.5805, Loss Adv_d: 1.1027 ------ Loss G: 1.7265, Curve Loss: 0.1305, Chamfer Loss: 0.1875\n",
      "Epoch [808/1000]  Loss D: 1.5678, Loss Adv_d: 1.0923 ------ Loss G: 1.7287, Curve Loss: 0.1346, Chamfer Loss: 0.1856\n",
      "Epoch [809/1000]  Loss D: 1.5772, Loss Adv_d: 1.0970 ------ Loss G: 1.7338, Curve Loss: 0.1349, Chamfer Loss: 0.1887\n",
      "Epoch [810/1000]  Loss D: 1.6061, Loss Adv_d: 1.1148 ------ Loss G: 1.7510, Curve Loss: 0.1340, Chamfer Loss: 0.2029\n",
      "Epoch [811/1000]  Loss D: 1.5900, Loss Adv_d: 1.0976 ------ Loss G: 1.7589, Curve Loss: 0.1340, Chamfer Loss: 0.2068\n",
      "Epoch [812/1000]  Loss D: 1.5987, Loss Adv_d: 1.1085 ------ Loss G: 1.7461, Curve Loss: 0.1305, Chamfer Loss: 0.2038\n",
      "Epoch [813/1000]  Loss D: 1.5782, Loss Adv_d: 1.0868 ------ Loss G: 1.7428, Curve Loss: 0.1293, Chamfer Loss: 0.2015\n",
      "Epoch [814/1000]  Loss D: 1.5706, Loss Adv_d: 1.0931 ------ Loss G: 1.7410, Curve Loss: 0.1314, Chamfer Loss: 0.1892\n",
      "Epoch [815/1000]  Loss D: 1.5631, Loss Adv_d: 1.0894 ------ Loss G: 1.7376, Curve Loss: 0.1331, Chamfer Loss: 0.1839\n",
      "Epoch [816/1000]  Loss D: 1.5701, Loss Adv_d: 1.0957 ------ Loss G: 1.7298, Curve Loss: 0.1321, Chamfer Loss: 0.1841\n",
      "Epoch [817/1000]  Loss D: 1.5735, Loss Adv_d: 1.0989 ------ Loss G: 1.7288, Curve Loss: 0.1318, Chamfer Loss: 0.1844\n",
      "Epoch [818/1000]  Loss D: 1.5787, Loss Adv_d: 1.1035 ------ Loss G: 1.7324, Curve Loss: 0.1336, Chamfer Loss: 0.1856\n",
      "Epoch [819/1000]  Loss D: 1.5870, Loss Adv_d: 1.0984 ------ Loss G: 1.7507, Curve Loss: 0.1330, Chamfer Loss: 0.2000\n",
      "Epoch [820/1000]  Loss D: 1.6073, Loss Adv_d: 1.1087 ------ Loss G: 1.7628, Curve Loss: 0.1342, Chamfer Loss: 0.2124\n",
      "Epoch [821/1000]  Loss D: 1.5684, Loss Adv_d: 1.0806 ------ Loss G: 1.7618, Curve Loss: 0.1343, Chamfer Loss: 0.2026\n",
      "Epoch [822/1000]  Loss D: 1.6042, Loss Adv_d: 1.1053 ------ Loss G: 1.7718, Curve Loss: 0.1357, Chamfer Loss: 0.2145\n",
      "Epoch [823/1000]  Loss D: 1.5783, Loss Adv_d: 1.1057 ------ Loss G: 1.7344, Curve Loss: 0.1301, Chamfer Loss: 0.1883\n",
      "Epoch [824/1000]  Loss D: 1.5716, Loss Adv_d: 1.0896 ------ Loss G: 1.7323, Curve Loss: 0.1278, Chamfer Loss: 0.1936\n",
      "Epoch [825/1000]  Loss D: 1.5906, Loss Adv_d: 1.0906 ------ Loss G: 1.7545, Curve Loss: 0.1360, Chamfer Loss: 0.2083\n",
      "Epoch [826/1000]  Loss D: 1.5671, Loss Adv_d: 1.0915 ------ Loss G: 1.7324, Curve Loss: 0.1335, Chamfer Loss: 0.1855\n",
      "Epoch [827/1000]  Loss D: 1.5857, Loss Adv_d: 1.0989 ------ Loss G: 1.7535, Curve Loss: 0.1346, Chamfer Loss: 0.1991\n",
      "Epoch [828/1000]  Loss D: 1.5727, Loss Adv_d: 1.1008 ------ Loss G: 1.7425, Curve Loss: 0.1327, Chamfer Loss: 0.1867\n",
      "Epoch [829/1000]  Loss D: 1.5652, Loss Adv_d: 1.0855 ------ Loss G: 1.7509, Curve Loss: 0.1351, Chamfer Loss: 0.1938\n",
      "Epoch [830/1000]  Loss D: 1.5693, Loss Adv_d: 1.0951 ------ Loss G: 1.7424, Curve Loss: 0.1334, Chamfer Loss: 0.1883\n",
      "Epoch [831/1000]  Loss D: 1.5653, Loss Adv_d: 1.0928 ------ Loss G: 1.7348, Curve Loss: 0.1333, Chamfer Loss: 0.1859\n",
      "Epoch [832/1000]  Loss D: 1.5803, Loss Adv_d: 1.0966 ------ Loss G: 1.7468, Curve Loss: 0.1349, Chamfer Loss: 0.1955\n",
      "Epoch [833/1000]  Loss D: 1.5700, Loss Adv_d: 1.0979 ------ Loss G: 1.7377, Curve Loss: 0.1311, Chamfer Loss: 0.1861\n",
      "Epoch [834/1000]  Loss D: 1.5772, Loss Adv_d: 1.1030 ------ Loss G: 1.7386, Curve Loss: 0.1335, Chamfer Loss: 0.1866\n",
      "Epoch [835/1000]  Loss D: 1.5642, Loss Adv_d: 1.0910 ------ Loss G: 1.7404, Curve Loss: 0.1321, Chamfer Loss: 0.1864\n",
      "Epoch [836/1000]  Loss D: 1.5639, Loss Adv_d: 1.0913 ------ Loss G: 1.7402, Curve Loss: 0.1315, Chamfer Loss: 0.1855\n",
      "Epoch [837/1000]  Loss D: 1.5558, Loss Adv_d: 1.0845 ------ Loss G: 1.7399, Curve Loss: 0.1330, Chamfer Loss: 0.1847\n",
      "Epoch [838/1000]  Loss D: 1.5688, Loss Adv_d: 1.0982 ------ Loss G: 1.7427, Curve Loss: 0.1335, Chamfer Loss: 0.1848\n",
      "Epoch [839/1000]  Loss D: 1.5553, Loss Adv_d: 1.0854 ------ Loss G: 1.7395, Curve Loss: 0.1322, Chamfer Loss: 0.1839\n",
      "Epoch [840/1000]  Loss D: 1.5523, Loss Adv_d: 1.0819 ------ Loss G: 1.7442, Curve Loss: 0.1318, Chamfer Loss: 0.1852\n",
      "Epoch [841/1000]  Loss D: 1.5541, Loss Adv_d: 1.0816 ------ Loss G: 1.7477, Curve Loss: 0.1310, Chamfer Loss: 0.1892\n",
      "Epoch [842/1000]  Loss D: 1.5479, Loss Adv_d: 1.0788 ------ Loss G: 1.7500, Curve Loss: 0.1325, Chamfer Loss: 0.1861\n",
      "Epoch [843/1000]  Loss D: 1.5476, Loss Adv_d: 1.0815 ------ Loss G: 1.7424, Curve Loss: 0.1326, Chamfer Loss: 0.1832\n",
      "Epoch [844/1000]  Loss D: 1.5511, Loss Adv_d: 1.0834 ------ Loss G: 1.7323, Curve Loss: 0.1324, Chamfer Loss: 0.1818\n",
      "Epoch [845/1000]  Loss D: 1.5604, Loss Adv_d: 1.0904 ------ Loss G: 1.7333, Curve Loss: 0.1320, Chamfer Loss: 0.1819\n",
      "Epoch [846/1000]  Loss D: 1.5347, Loss Adv_d: 1.0675 ------ Loss G: 1.7412, Curve Loss: 0.1338, Chamfer Loss: 0.1802\n",
      "Epoch [847/1000]  Loss D: 1.5446, Loss Adv_d: 1.0810 ------ Loss G: 1.7492, Curve Loss: 0.1327, Chamfer Loss: 0.1795\n",
      "Epoch [848/1000]  Loss D: 1.5498, Loss Adv_d: 1.0865 ------ Loss G: 1.7525, Curve Loss: 0.1323, Chamfer Loss: 0.1821\n",
      "Epoch [849/1000]  Loss D: 1.5651, Loss Adv_d: 1.0750 ------ Loss G: 1.7862, Curve Loss: 0.1366, Chamfer Loss: 0.2121\n",
      "Epoch [850/1000]  Loss D: 1.5518, Loss Adv_d: 1.0812 ------ Loss G: 1.7445, Curve Loss: 0.1290, Chamfer Loss: 0.1934\n",
      "Epoch [851/1000]  Loss D: 1.5468, Loss Adv_d: 1.0716 ------ Loss G: 1.7361, Curve Loss: 0.1326, Chamfer Loss: 0.1893\n",
      "Epoch [852/1000]  Loss D: 1.5537, Loss Adv_d: 1.0768 ------ Loss G: 1.7342, Curve Loss: 0.1307, Chamfer Loss: 0.1861\n",
      "Epoch [853/1000]  Loss D: 1.5394, Loss Adv_d: 1.0665 ------ Loss G: 1.7487, Curve Loss: 0.1350, Chamfer Loss: 0.1843\n",
      "Epoch [854/1000]  Loss D: 1.5720, Loss Adv_d: 1.0919 ------ Loss G: 1.7672, Curve Loss: 0.1349, Chamfer Loss: 0.1972\n",
      "Epoch [855/1000]  Loss D: 1.5426, Loss Adv_d: 1.0747 ------ Loss G: 1.7614, Curve Loss: 0.1300, Chamfer Loss: 0.1911\n",
      "Epoch [856/1000]  Loss D: 1.5538, Loss Adv_d: 1.0749 ------ Loss G: 1.7574, Curve Loss: 0.1301, Chamfer Loss: 0.1970\n",
      "Epoch [857/1000]  Loss D: 1.5715, Loss Adv_d: 1.0687 ------ Loss G: 1.7832, Curve Loss: 0.1378, Chamfer Loss: 0.2176\n",
      "Epoch [858/1000]  Loss D: 1.5585, Loss Adv_d: 1.0726 ------ Loss G: 1.7629, Curve Loss: 0.1350, Chamfer Loss: 0.2001\n",
      "Epoch [859/1000]  Loss D: 1.5686, Loss Adv_d: 1.0732 ------ Loss G: 1.7738, Curve Loss: 0.1246, Chamfer Loss: 0.2138\n",
      "Epoch [860/1000]  Loss D: 1.5578, Loss Adv_d: 1.0759 ------ Loss G: 1.7716, Curve Loss: 0.1342, Chamfer Loss: 0.2024\n",
      "Epoch [861/1000]  Loss D: 1.5432, Loss Adv_d: 1.0674 ------ Loss G: 1.7637, Curve Loss: 0.1339, Chamfer Loss: 0.1960\n",
      "Epoch [862/1000]  Loss D: 1.5491, Loss Adv_d: 1.0621 ------ Loss G: 1.7501, Curve Loss: 0.1335, Chamfer Loss: 0.1999\n",
      "Epoch [863/1000]  Loss D: 1.5388, Loss Adv_d: 1.0568 ------ Loss G: 1.7552, Curve Loss: 0.1353, Chamfer Loss: 0.1934\n",
      "Epoch [864/1000]  Loss D: 1.5478, Loss Adv_d: 1.0733 ------ Loss G: 1.7594, Curve Loss: 0.1341, Chamfer Loss: 0.1904\n",
      "Epoch [865/1000]  Loss D: 1.5354, Loss Adv_d: 1.0633 ------ Loss G: 1.7635, Curve Loss: 0.1324, Chamfer Loss: 0.1891\n",
      "Epoch [866/1000]  Loss D: 1.5352, Loss Adv_d: 1.0657 ------ Loss G: 1.7622, Curve Loss: 0.1322, Chamfer Loss: 0.1885\n",
      "Epoch [867/1000]  Loss D: 1.5531, Loss Adv_d: 1.0812 ------ Loss G: 1.7630, Curve Loss: 0.1341, Chamfer Loss: 0.1921\n",
      "Epoch [868/1000]  Loss D: 1.5447, Loss Adv_d: 1.0797 ------ Loss G: 1.7540, Curve Loss: 0.1317, Chamfer Loss: 0.1855\n",
      "Epoch [869/1000]  Loss D: 1.5481, Loss Adv_d: 1.0784 ------ Loss G: 1.7503, Curve Loss: 0.1293, Chamfer Loss: 0.1893\n",
      "Epoch [870/1000]  Loss D: 1.5515, Loss Adv_d: 1.0800 ------ Loss G: 1.7446, Curve Loss: 0.1297, Chamfer Loss: 0.1881\n",
      "Epoch [871/1000]  Loss D: 1.5485, Loss Adv_d: 1.0780 ------ Loss G: 1.7438, Curve Loss: 0.1313, Chamfer Loss: 0.1861\n",
      "Epoch [872/1000]  Loss D: 1.5559, Loss Adv_d: 1.0826 ------ Loss G: 1.7481, Curve Loss: 0.1319, Chamfer Loss: 0.1891\n",
      "Epoch [873/1000]  Loss D: 1.5520, Loss Adv_d: 1.0740 ------ Loss G: 1.7684, Curve Loss: 0.1349, Chamfer Loss: 0.1957\n",
      "Epoch [874/1000]  Loss D: 1.5786, Loss Adv_d: 1.0825 ------ Loss G: 1.7871, Curve Loss: 0.1340, Chamfer Loss: 0.2173\n",
      "Epoch [875/1000]  Loss D: 1.5491, Loss Adv_d: 1.0752 ------ Loss G: 1.7628, Curve Loss: 0.1340, Chamfer Loss: 0.1961\n",
      "Epoch [876/1000]  Loss D: 1.5400, Loss Adv_d: 1.0695 ------ Loss G: 1.7511, Curve Loss: 0.1349, Chamfer Loss: 0.1887\n",
      "Epoch [877/1000]  Loss D: 1.5507, Loss Adv_d: 1.0587 ------ Loss G: 1.7733, Curve Loss: 0.1365, Chamfer Loss: 0.2066\n",
      "Epoch [878/1000]  Loss D: 1.5391, Loss Adv_d: 1.0620 ------ Loss G: 1.7669, Curve Loss: 0.1331, Chamfer Loss: 0.1960\n",
      "Epoch [879/1000]  Loss D: 1.5356, Loss Adv_d: 1.0584 ------ Loss G: 1.7591, Curve Loss: 0.1310, Chamfer Loss: 0.1954\n",
      "Epoch [880/1000]  Loss D: 1.5479, Loss Adv_d: 1.0708 ------ Loss G: 1.7512, Curve Loss: 0.1292, Chamfer Loss: 0.1931\n",
      "Epoch [881/1000]  Loss D: 1.5392, Loss Adv_d: 1.0658 ------ Loss G: 1.7587, Curve Loss: 0.1343, Chamfer Loss: 0.1893\n",
      "Epoch [882/1000]  Loss D: 1.5342, Loss Adv_d: 1.0630 ------ Loss G: 1.7607, Curve Loss: 0.1321, Chamfer Loss: 0.1888\n",
      "Epoch [883/1000]  Loss D: 1.5445, Loss Adv_d: 1.0772 ------ Loss G: 1.7561, Curve Loss: 0.1319, Chamfer Loss: 0.1871\n",
      "Epoch [884/1000]  Loss D: 1.5699, Loss Adv_d: 1.0788 ------ Loss G: 1.7800, Curve Loss: 0.1341, Chamfer Loss: 0.2097\n",
      "Epoch [885/1000]  Loss D: 1.5456, Loss Adv_d: 1.0648 ------ Loss G: 1.7745, Curve Loss: 0.1278, Chamfer Loss: 0.2042\n",
      "Epoch [886/1000]  Loss D: 1.5407, Loss Adv_d: 1.0713 ------ Loss G: 1.7575, Curve Loss: 0.1300, Chamfer Loss: 0.1890\n",
      "Epoch [887/1000]  Loss D: 1.5394, Loss Adv_d: 1.0613 ------ Loss G: 1.7682, Curve Loss: 0.1339, Chamfer Loss: 0.1965\n",
      "Epoch [888/1000]  Loss D: 1.5852, Loss Adv_d: 1.0622 ------ Loss G: 1.8216, Curve Loss: 0.1358, Chamfer Loss: 0.2421\n",
      "Epoch [889/1000]  Loss D: 1.5277, Loss Adv_d: 1.0645 ------ Loss G: 1.7664, Curve Loss: 0.1316, Chamfer Loss: 0.1876\n",
      "Epoch [890/1000]  Loss D: 1.5301, Loss Adv_d: 1.0654 ------ Loss G: 1.7514, Curve Loss: 0.1317, Chamfer Loss: 0.1867\n",
      "Epoch [891/1000]  Loss D: 1.5364, Loss Adv_d: 1.0581 ------ Loss G: 1.7607, Curve Loss: 0.1350, Chamfer Loss: 0.1954\n",
      "Epoch [892/1000]  Loss D: 1.5254, Loss Adv_d: 1.0568 ------ Loss G: 1.7515, Curve Loss: 0.1322, Chamfer Loss: 0.1860\n",
      "Epoch [893/1000]  Loss D: 1.5422, Loss Adv_d: 1.0742 ------ Loss G: 1.7570, Curve Loss: 0.1305, Chamfer Loss: 0.1865\n",
      "Epoch [894/1000]  Loss D: 1.5373, Loss Adv_d: 1.0702 ------ Loss G: 1.7604, Curve Loss: 0.1330, Chamfer Loss: 0.1871\n",
      "Epoch [895/1000]  Loss D: 1.5411, Loss Adv_d: 1.0705 ------ Loss G: 1.7608, Curve Loss: 0.1336, Chamfer Loss: 0.1915\n",
      "Epoch [896/1000]  Loss D: 1.5636, Loss Adv_d: 1.0896 ------ Loss G: 1.7587, Curve Loss: 0.1282, Chamfer Loss: 0.1953\n",
      "Epoch [897/1000]  Loss D: 1.5245, Loss Adv_d: 1.0554 ------ Loss G: 1.7615, Curve Loss: 0.1318, Chamfer Loss: 0.1875\n",
      "Epoch [898/1000]  Loss D: 1.5390, Loss Adv_d: 1.0668 ------ Loss G: 1.7628, Curve Loss: 0.1319, Chamfer Loss: 0.1927\n",
      "Epoch [899/1000]  Loss D: 1.5348, Loss Adv_d: 1.0676 ------ Loss G: 1.7565, Curve Loss: 0.1324, Chamfer Loss: 0.1883\n",
      "Epoch [900/1000]  Loss D: 1.5383, Loss Adv_d: 1.0693 ------ Loss G: 1.7530, Curve Loss: 0.1323, Chamfer Loss: 0.1870\n",
      "Epoch [901/1000]  Loss D: 1.5311, Loss Adv_d: 1.0549 ------ Loss G: 1.7578, Curve Loss: 0.1322, Chamfer Loss: 0.1940\n",
      "Epoch [902/1000]  Loss D: 1.5166, Loss Adv_d: 1.0503 ------ Loss G: 1.7553, Curve Loss: 0.1307, Chamfer Loss: 0.1859\n",
      "Epoch [903/1000]  Loss D: 1.5377, Loss Adv_d: 1.0579 ------ Loss G: 1.7716, Curve Loss: 0.1326, Chamfer Loss: 0.1992\n",
      "Epoch [904/1000]  Loss D: 1.5205, Loss Adv_d: 1.0548 ------ Loss G: 1.7628, Curve Loss: 0.1315, Chamfer Loss: 0.1876\n",
      "Epoch [905/1000]  Loss D: 1.5210, Loss Adv_d: 1.0534 ------ Loss G: 1.7623, Curve Loss: 0.1321, Chamfer Loss: 0.1880\n",
      "Epoch [906/1000]  Loss D: 1.5343, Loss Adv_d: 1.0640 ------ Loss G: 1.7620, Curve Loss: 0.1325, Chamfer Loss: 0.1902\n",
      "Epoch [907/1000]  Loss D: 1.5138, Loss Adv_d: 1.0524 ------ Loss G: 1.7677, Curve Loss: 0.1336, Chamfer Loss: 0.1836\n",
      "Epoch [908/1000]  Loss D: 1.5132, Loss Adv_d: 1.0405 ------ Loss G: 1.7873, Curve Loss: 0.1343, Chamfer Loss: 0.1965\n",
      "Epoch [909/1000]  Loss D: 1.5172, Loss Adv_d: 1.0553 ------ Loss G: 1.7664, Curve Loss: 0.1313, Chamfer Loss: 0.1911\n",
      "Epoch [910/1000]  Loss D: 1.5174, Loss Adv_d: 1.0486 ------ Loss G: 1.7560, Curve Loss: 0.1328, Chamfer Loss: 0.1887\n",
      "Epoch [911/1000]  Loss D: 1.5137, Loss Adv_d: 1.0451 ------ Loss G: 1.7612, Curve Loss: 0.1314, Chamfer Loss: 0.1857\n",
      "Epoch [912/1000]  Loss D: 1.5225, Loss Adv_d: 1.0580 ------ Loss G: 1.7650, Curve Loss: 0.1303, Chamfer Loss: 0.1868\n",
      "Epoch [913/1000]  Loss D: 1.5119, Loss Adv_d: 1.0522 ------ Loss G: 1.7617, Curve Loss: 0.1290, Chamfer Loss: 0.1843\n",
      "Epoch [914/1000]  Loss D: 1.5284, Loss Adv_d: 1.0590 ------ Loss G: 1.7656, Curve Loss: 0.1332, Chamfer Loss: 0.1915\n",
      "Epoch [915/1000]  Loss D: 1.5445, Loss Adv_d: 1.0560 ------ Loss G: 1.7899, Curve Loss: 0.1358, Chamfer Loss: 0.2107\n",
      "Epoch [916/1000]  Loss D: 1.5321, Loss Adv_d: 1.0579 ------ Loss G: 1.7875, Curve Loss: 0.1331, Chamfer Loss: 0.1997\n",
      "Epoch [917/1000]  Loss D: 1.5182, Loss Adv_d: 1.0488 ------ Loss G: 1.7749, Curve Loss: 0.1325, Chamfer Loss: 0.1952\n",
      "Epoch [918/1000]  Loss D: 1.5187, Loss Adv_d: 1.0539 ------ Loss G: 1.7579, Curve Loss: 0.1291, Chamfer Loss: 0.1889\n",
      "Epoch [919/1000]  Loss D: 1.5006, Loss Adv_d: 1.0351 ------ Loss G: 1.7540, Curve Loss: 0.1298, Chamfer Loss: 0.1851\n",
      "Epoch [920/1000]  Loss D: 1.5235, Loss Adv_d: 1.0577 ------ Loss G: 1.7557, Curve Loss: 0.1318, Chamfer Loss: 0.1851\n",
      "Epoch [921/1000]  Loss D: 1.5366, Loss Adv_d: 1.0447 ------ Loss G: 1.7919, Curve Loss: 0.1315, Chamfer Loss: 0.2120\n",
      "Epoch [922/1000]  Loss D: 1.5144, Loss Adv_d: 1.0579 ------ Loss G: 1.7695, Curve Loss: 0.1321, Chamfer Loss: 0.1840\n",
      "Epoch [923/1000]  Loss D: 1.5150, Loss Adv_d: 1.0548 ------ Loss G: 1.7690, Curve Loss: 0.1322, Chamfer Loss: 0.1849\n",
      "Epoch [924/1000]  Loss D: 1.5104, Loss Adv_d: 1.0454 ------ Loss G: 1.7747, Curve Loss: 0.1317, Chamfer Loss: 0.1887\n",
      "Epoch [925/1000]  Loss D: 1.5233, Loss Adv_d: 1.0493 ------ Loss G: 1.7885, Curve Loss: 0.1280, Chamfer Loss: 0.2004\n",
      "Epoch [926/1000]  Loss D: 1.5167, Loss Adv_d: 1.0557 ------ Loss G: 1.7764, Curve Loss: 0.1327, Chamfer Loss: 0.1886\n",
      "Epoch [927/1000]  Loss D: 1.5053, Loss Adv_d: 1.0418 ------ Loss G: 1.7651, Curve Loss: 0.1290, Chamfer Loss: 0.1891\n",
      "Epoch [928/1000]  Loss D: 1.5035, Loss Adv_d: 1.0416 ------ Loss G: 1.7565, Curve Loss: 0.1292, Chamfer Loss: 0.1848\n",
      "Epoch [929/1000]  Loss D: 1.5132, Loss Adv_d: 1.0432 ------ Loss G: 1.7666, Curve Loss: 0.1337, Chamfer Loss: 0.1904\n",
      "Epoch [930/1000]  Loss D: 1.5051, Loss Adv_d: 1.0416 ------ Loss G: 1.7687, Curve Loss: 0.1294, Chamfer Loss: 0.1863\n",
      "Epoch [931/1000]  Loss D: 1.5163, Loss Adv_d: 1.0462 ------ Loss G: 1.7849, Curve Loss: 0.1336, Chamfer Loss: 0.1945\n",
      "Epoch [932/1000]  Loss D: 1.4948, Loss Adv_d: 1.0341 ------ Loss G: 1.7773, Curve Loss: 0.1295, Chamfer Loss: 0.1890\n",
      "Epoch [933/1000]  Loss D: 1.5219, Loss Adv_d: 1.0580 ------ Loss G: 1.7679, Curve Loss: 0.1302, Chamfer Loss: 0.1884\n",
      "Epoch [934/1000]  Loss D: 1.5095, Loss Adv_d: 1.0456 ------ Loss G: 1.7700, Curve Loss: 0.1316, Chamfer Loss: 0.1876\n",
      "Epoch [935/1000]  Loss D: 1.5148, Loss Adv_d: 1.0418 ------ Loss G: 1.7818, Curve Loss: 0.1334, Chamfer Loss: 0.1964\n",
      "Epoch [936/1000]  Loss D: 1.5000, Loss Adv_d: 1.0452 ------ Loss G: 1.7659, Curve Loss: 0.1299, Chamfer Loss: 0.1818\n",
      "Epoch [937/1000]  Loss D: 1.5087, Loss Adv_d: 1.0511 ------ Loss G: 1.7637, Curve Loss: 0.1302, Chamfer Loss: 0.1831\n",
      "Epoch [938/1000]  Loss D: 1.5137, Loss Adv_d: 1.0522 ------ Loss G: 1.7613, Curve Loss: 0.1298, Chamfer Loss: 0.1846\n",
      "Epoch [939/1000]  Loss D: 1.5105, Loss Adv_d: 1.0488 ------ Loss G: 1.7649, Curve Loss: 0.1317, Chamfer Loss: 0.1847\n",
      "Epoch [940/1000]  Loss D: 1.4960, Loss Adv_d: 1.0366 ------ Loss G: 1.7668, Curve Loss: 0.1308, Chamfer Loss: 0.1845\n",
      "Epoch [941/1000]  Loss D: 1.4905, Loss Adv_d: 1.0271 ------ Loss G: 1.7711, Curve Loss: 0.1292, Chamfer Loss: 0.1868\n",
      "Epoch [942/1000]  Loss D: 1.5559, Loss Adv_d: 1.0571 ------ Loss G: 1.8209, Curve Loss: 0.1366, Chamfer Loss: 0.2260\n",
      "Epoch [943/1000]  Loss D: 1.5244, Loss Adv_d: 1.0394 ------ Loss G: 1.7987, Curve Loss: 0.1347, Chamfer Loss: 0.2100\n",
      "Epoch [944/1000]  Loss D: 1.5141, Loss Adv_d: 1.0482 ------ Loss G: 1.7865, Curve Loss: 0.1326, Chamfer Loss: 0.1942\n",
      "Epoch [945/1000]  Loss D: 1.5049, Loss Adv_d: 1.0348 ------ Loss G: 1.7909, Curve Loss: 0.1357, Chamfer Loss: 0.1980\n",
      "Epoch [946/1000]  Loss D: 1.5156, Loss Adv_d: 1.0524 ------ Loss G: 1.7701, Curve Loss: 0.1319, Chamfer Loss: 0.1904\n",
      "Epoch [947/1000]  Loss D: 1.5071, Loss Adv_d: 1.0383 ------ Loss G: 1.7659, Curve Loss: 0.1314, Chamfer Loss: 0.1908\n",
      "Epoch [948/1000]  Loss D: 1.4947, Loss Adv_d: 1.0247 ------ Loss G: 1.7775, Curve Loss: 0.1338, Chamfer Loss: 0.1896\n",
      "Epoch [949/1000]  Loss D: 1.5054, Loss Adv_d: 1.0411 ------ Loss G: 1.7817, Curve Loss: 0.1288, Chamfer Loss: 0.1911\n",
      "Epoch [950/1000]  Loss D: 1.5087, Loss Adv_d: 1.0450 ------ Loss G: 1.7766, Curve Loss: 0.1318, Chamfer Loss: 0.1888\n",
      "Epoch [951/1000]  Loss D: 1.5488, Loss Adv_d: 1.0557 ------ Loss G: 1.8069, Curve Loss: 0.1348, Chamfer Loss: 0.2191\n",
      "Epoch [952/1000]  Loss D: 1.5205, Loss Adv_d: 1.0456 ------ Loss G: 1.7829, Curve Loss: 0.1331, Chamfer Loss: 0.2020\n",
      "Epoch [953/1000]  Loss D: 1.5136, Loss Adv_d: 1.0477 ------ Loss G: 1.7704, Curve Loss: 0.1330, Chamfer Loss: 0.1919\n",
      "Epoch [954/1000]  Loss D: 1.4990, Loss Adv_d: 1.0308 ------ Loss G: 1.7723, Curve Loss: 0.1320, Chamfer Loss: 0.1894\n",
      "Epoch [955/1000]  Loss D: 1.4964, Loss Adv_d: 1.0299 ------ Loss G: 1.7787, Curve Loss: 0.1310, Chamfer Loss: 0.1899\n",
      "Epoch [956/1000]  Loss D: 1.5169, Loss Adv_d: 1.0476 ------ Loss G: 1.7838, Curve Loss: 0.1333, Chamfer Loss: 0.1957\n",
      "Epoch [957/1000]  Loss D: 1.5122, Loss Adv_d: 1.0497 ------ Loss G: 1.7716, Curve Loss: 0.1317, Chamfer Loss: 0.1889\n",
      "Epoch [958/1000]  Loss D: 1.5094, Loss Adv_d: 1.0426 ------ Loss G: 1.7688, Curve Loss: 0.1319, Chamfer Loss: 0.1920\n",
      "Epoch [959/1000]  Loss D: 1.5080, Loss Adv_d: 1.0471 ------ Loss G: 1.7594, Curve Loss: 0.1320, Chamfer Loss: 0.1856\n",
      "Epoch [960/1000]  Loss D: 1.4830, Loss Adv_d: 1.0186 ------ Loss G: 1.7707, Curve Loss: 0.1329, Chamfer Loss: 0.1855\n",
      "Epoch [961/1000]  Loss D: 1.4987, Loss Adv_d: 1.0315 ------ Loss G: 1.7851, Curve Loss: 0.1309, Chamfer Loss: 0.1911\n",
      "Epoch [962/1000]  Loss D: 1.5068, Loss Adv_d: 1.0418 ------ Loss G: 1.7862, Curve Loss: 0.1294, Chamfer Loss: 0.1920\n",
      "Epoch [963/1000]  Loss D: 1.5025, Loss Adv_d: 1.0412 ------ Loss G: 1.7818, Curve Loss: 0.1313, Chamfer Loss: 0.1889\n",
      "Epoch [964/1000]  Loss D: 1.5181, Loss Adv_d: 1.0486 ------ Loss G: 1.7876, Curve Loss: 0.1330, Chamfer Loss: 0.1972\n",
      "Epoch [965/1000]  Loss D: 1.4863, Loss Adv_d: 1.0256 ------ Loss G: 1.7841, Curve Loss: 0.1325, Chamfer Loss: 0.1881\n",
      "Epoch [966/1000]  Loss D: 1.5089, Loss Adv_d: 1.0429 ------ Loss G: 1.7830, Curve Loss: 0.1337, Chamfer Loss: 0.1943\n",
      "Epoch [967/1000]  Loss D: 1.5263, Loss Adv_d: 1.0341 ------ Loss G: 1.8179, Curve Loss: 0.1357, Chamfer Loss: 0.2180\n",
      "Epoch [968/1000]  Loss D: 1.4878, Loss Adv_d: 1.0245 ------ Loss G: 1.8018, Curve Loss: 0.1338, Chamfer Loss: 0.1939\n",
      "Epoch [969/1000]  Loss D: 1.5012, Loss Adv_d: 1.0390 ------ Loss G: 1.7873, Curve Loss: 0.1289, Chamfer Loss: 0.1955\n",
      "Epoch [970/1000]  Loss D: 1.4900, Loss Adv_d: 1.0217 ------ Loss G: 1.7804, Curve Loss: 0.1356, Chamfer Loss: 0.1940\n",
      "Epoch [971/1000]  Loss D: 1.5000, Loss Adv_d: 1.0242 ------ Loss G: 1.7832, Curve Loss: 0.1277, Chamfer Loss: 0.1991\n",
      "Epoch [972/1000]  Loss D: 1.5060, Loss Adv_d: 1.0398 ------ Loss G: 1.7881, Curve Loss: 0.1340, Chamfer Loss: 0.1925\n",
      "Epoch [973/1000]  Loss D: 1.5027, Loss Adv_d: 1.0375 ------ Loss G: 1.7792, Curve Loss: 0.1349, Chamfer Loss: 0.1914\n",
      "Epoch [974/1000]  Loss D: 1.5461, Loss Adv_d: 1.0439 ------ Loss G: 1.8189, Curve Loss: 0.1357, Chamfer Loss: 0.2272\n",
      "Epoch [975/1000]  Loss D: 1.4893, Loss Adv_d: 1.0256 ------ Loss G: 1.7983, Curve Loss: 0.1312, Chamfer Loss: 0.1913\n",
      "Epoch [976/1000]  Loss D: 1.4834, Loss Adv_d: 1.0261 ------ Loss G: 1.7947, Curve Loss: 0.1316, Chamfer Loss: 0.1889\n",
      "Epoch [977/1000]  Loss D: 1.5153, Loss Adv_d: 1.0441 ------ Loss G: 1.7936, Curve Loss: 0.1338, Chamfer Loss: 0.2005\n",
      "Epoch [978/1000]  Loss D: 1.4862, Loss Adv_d: 1.0194 ------ Loss G: 1.7900, Curve Loss: 0.1335, Chamfer Loss: 0.1959\n",
      "Epoch [979/1000]  Loss D: 1.5025, Loss Adv_d: 1.0324 ------ Loss G: 1.7805, Curve Loss: 0.1294, Chamfer Loss: 0.1970\n",
      "Epoch [980/1000]  Loss D: 1.5003, Loss Adv_d: 1.0292 ------ Loss G: 1.7833, Curve Loss: 0.1339, Chamfer Loss: 0.1944\n",
      "Epoch [981/1000]  Loss D: 1.5273, Loss Adv_d: 1.0521 ------ Loss G: 1.7911, Curve Loss: 0.1361, Chamfer Loss: 0.1991\n",
      "Epoch [982/1000]  Loss D: 1.5090, Loss Adv_d: 1.0371 ------ Loss G: 1.7989, Curve Loss: 0.1343, Chamfer Loss: 0.1998\n",
      "Epoch [983/1000]  Loss D: 1.4997, Loss Adv_d: 1.0344 ------ Loss G: 1.7882, Curve Loss: 0.1335, Chamfer Loss: 0.1921\n",
      "Epoch [984/1000]  Loss D: 1.4864, Loss Adv_d: 1.0216 ------ Loss G: 1.7888, Curve Loss: 0.1351, Chamfer Loss: 0.1913\n",
      "Epoch [985/1000]  Loss D: 1.4987, Loss Adv_d: 1.0345 ------ Loss G: 1.7869, Curve Loss: 0.1352, Chamfer Loss: 0.1913\n",
      "Epoch [986/1000]  Loss D: 1.4959, Loss Adv_d: 1.0350 ------ Loss G: 1.7817, Curve Loss: 0.1341, Chamfer Loss: 0.1888\n",
      "Epoch [987/1000]  Loss D: 1.4893, Loss Adv_d: 1.0262 ------ Loss G: 1.7839, Curve Loss: 0.1317, Chamfer Loss: 0.1886\n",
      "Epoch [988/1000]  Loss D: 1.5176, Loss Adv_d: 1.0564 ------ Loss G: 1.7701, Curve Loss: 0.1299, Chamfer Loss: 0.1889\n",
      "Epoch [989/1000]  Loss D: 1.5128, Loss Adv_d: 1.0195 ------ Loss G: 1.8113, Curve Loss: 0.1364, Chamfer Loss: 0.2165\n",
      "Epoch [990/1000]  Loss D: 1.4910, Loss Adv_d: 1.0248 ------ Loss G: 1.7957, Curve Loss: 0.1335, Chamfer Loss: 0.1964\n",
      "Epoch [991/1000]  Loss D: 1.4911, Loss Adv_d: 1.0128 ------ Loss G: 1.8020, Curve Loss: 0.1341, Chamfer Loss: 0.2053\n",
      "Epoch [992/1000]  Loss D: 1.4768, Loss Adv_d: 1.0158 ------ Loss G: 1.7890, Curve Loss: 0.1333, Chamfer Loss: 0.1881\n",
      "Epoch [993/1000]  Loss D: 1.4924, Loss Adv_d: 1.0320 ------ Loss G: 1.7950, Curve Loss: 0.1296, Chamfer Loss: 0.1896\n",
      "Epoch [994/1000]  Loss D: 1.4972, Loss Adv_d: 1.0368 ------ Loss G: 1.7976, Curve Loss: 0.1356, Chamfer Loss: 0.1921\n",
      "Epoch [995/1000]  Loss D: 1.4984, Loss Adv_d: 1.0301 ------ Loss G: 1.7905, Curve Loss: 0.1331, Chamfer Loss: 0.1959\n",
      "Epoch [996/1000]  Loss D: 1.4964, Loss Adv_d: 1.0292 ------ Loss G: 1.7855, Curve Loss: 0.1329, Chamfer Loss: 0.1952\n",
      "Epoch [997/1000]  Loss D: 1.4793, Loss Adv_d: 1.0136 ------ Loss G: 1.7845, Curve Loss: 0.1306, Chamfer Loss: 0.1911\n",
      "Epoch [998/1000]  Loss D: 1.4737, Loss Adv_d: 1.0079 ------ Loss G: 1.7938, Curve Loss: 0.1293, Chamfer Loss: 0.1929\n",
      "Epoch [999/1000]  Loss D: 1.5083, Loss Adv_d: 1.0356 ------ Loss G: 1.8047, Curve Loss: 0.1345, Chamfer Loss: 0.2022\n",
      "Epoch [1000/1000]  Loss D: 1.4870, Loss Adv_d: 1.0275 ------ Loss G: 1.7846, Curve Loss: 0.1297, Chamfer Loss: 0.1901\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128   # Dimension des latenten Vektors\n",
    "num_epochs = 1000# Anzahl der Trainings-Epochen\n",
    "batch_size = 23 # Größe des Batches\n",
    "N = 1024\n",
    "lr_g = 1e-4\n",
    "lr_d = 1e-5\n",
    "feature_dim = 512\n",
    "num_verts = 850\n",
    "num_faces = 1700\n",
    "\n",
    "\n",
    "# num_vertices sollte sich so wenig wie möglich von realen Objekten unterscheiden\n",
    "#num_vertices = vetices in Sphere, für Testing\n",
    "# Initialisierung von Generator und Diskriminator\n",
    "cfg = {\n",
    "        'structural_descriptor': {\n",
    "            'num_kernel': 64,\n",
    "            'sigma': 0.2\n",
    "        },\n",
    "        'mesh_convolution': {\n",
    "            'aggregation_method': 'Max'\n",
    "        },\n",
    "        'num_vertices': num_verts # Number of vertices in the input mesh\n",
    "    }\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = MeshGenerator(cfg)\n",
    "discriminator = MeshDiscriminator(cfg)\n",
    "\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "# Optimizer für Generator und Diskriminator\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "\n",
    "meshDataset = MeshDataset(root =\"/newModelData/goodTopo\", max_faces=num_faces, max_vertices=num_verts)\n",
    "meshDataloader = DataLoader(dataset=meshDataset, batch_size=batch_size,shuffle=\"true\", collate_fn=collate_fn1)\n",
    "# Beispiel für reale Daten (Dummy)\n",
    "\n",
    "shapes_dict = parse_shapes_list(\"ShapesList.txt\")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "\n",
    "# Trainingsloop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #for i, real_meshes in enumerate(dataloader):\n",
    "    centers, corners, normals, neighbor_index, vertices, file_numbers, curve_score = next(iter(meshDataloader))    \n",
    "\n",
    "    centers = centers.to(dtype=torch.float32)\n",
    "    corners = corners.to(dtype=torch.float32)\n",
    "    normals = normals.to(dtype=torch.float32)\n",
    "\n",
    "    # -----------------\n",
    "    # Trainieren des Diskriminators\n",
    "    # -----------------\n",
    "    optimizer_D.zero_grad()\n",
    "   \n",
    " \n",
    "\n",
    "    vertices = vertices.to(device) \n",
    "    real_pred = discriminator(vertices)\n",
    "    real_labels = torch.ones_like((real_pred)).to(device)  # Label 1 für reale Daten\n",
    "    real_loss = F.binary_cross_entropy(real_pred, real_labels).to(device)\n",
    "    \n",
    "    # Schritt 2: Generierte Daten durch den Diskriminator\n",
    "    \n",
    "    generated_verts = generator(centers, corners, normals, neighbor_index, curve_score)  # Generiertes Mesh\n",
    "    generated_verts = generated_verts.to(device) \n",
    "    fake_pred = discriminator(generated_verts)\n",
    "    fake_labels = torch.zeros_like(fake_pred).to(device)  # Label 0 für generierte Daten\n",
    "    fake_loss = F.binary_cross_entropy(fake_pred, fake_labels).to(device)\n",
    "    chamfer_loss = chamfer_distance1(generated_verts, vertices)\n",
    "    chamfer_loss_d = fake_loss + chamfer_loss \n",
    "\n",
    "   # print(chamfer_loss_d, fake_loss)\n",
    "\n",
    "    # Diskriminator-Loss berechnen und Schritt machen\n",
    "    adv_d = real_loss + fake_loss\n",
    "    d_loss = real_loss + fake_loss + chamfer_loss_d \n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    # -----------------\n",
    "    # Trainieren des Generators\n",
    "    # -----------------\n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    generated_verts = generator(centers, corners, normals, neighbor_index, curve_score).to(device)   \n",
    "    generated_meshes = face_generator(generated_verts)\n",
    "\n",
    "    real_meshes_cd = face_generator(vertices)\n",
    "     \n",
    "    # Diskriminator-Output für das generierte Mesh\n",
    "    generated_verts = generated_verts.to(device) \n",
    "    fake_pred = discriminator(generated_verts)\n",
    "    \n",
    "    adv_loss = F.binary_cross_entropy(fake_pred, torch.ones_like(fake_pred)).to(device)\n",
    "    \n",
    "    fake_point_clouds = sample_points_from_meshes(generated_meshes[\"mesh\"], num_samples=1024).to(device)\n",
    "    real_point_clouds = sample_points_from_meshes(real_meshes_cd[\"mesh\"],num_samples=1024).to(device)\n",
    "\n",
    "    curve_loss = curvature_density_loss(generated_verts, centers, curve_score)\n",
    "    chamfer_loss = chamfer_distance1(generated_verts,vertices)  \n",
    "\n",
    "    g_loss = adv_loss + chamfer_loss + curve_loss\n",
    " \n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss D: {d_loss.item():.4f}, Loss Adv_d: {adv_d.item():.4f} ------ Loss G: {g_loss.item():.4f}, Curve Loss: {curve_loss.item():.4f}, Chamfer Loss: {chamfer_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n",
      "Exporting Point Cloud for Shape: None (File Number: 0)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vertices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
